#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŸ³å¶å£°éŸ³TTS
"""

import requests
import json
from pathlib import Path
import os
import threading
import queue
import time
import io
import re
from datetime import datetime

# å°è¯•å¯¼å…¥numpyï¼Œå¦‚æœå¤±è´¥åˆ™ç¦ç”¨æµå¼æ’­æ”¾
try:
    import numpy
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False
    print("âš ï¸ numpyæœªå®‰è£…ï¼Œæµå¼æ’­æ”¾åŠŸèƒ½å°†è¢«ç¦ç”¨")
try:
    import pygame
    PYGAME_AVAILABLE = True
except ImportError:
    PYGAME_AVAILABLE = False

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("âš ï¸ openaiæœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨å®˜æ–¹æµå¼APIã€‚è¿è¡Œ: pip install openai")

def clear_proxies():
    """æ¸…é™¤ä»£ç†è®¾ç½®"""
    proxy_vars = ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy', 'ALL_PROXY', 'all_proxy']
    for var in proxy_vars:
        if var in os.environ:
            del os.environ[var]
    
    session = requests.Session()
    session.trust_env = False
    session.proxies = {}
    return session

# ä½¿ç”¨ç³»ç»Ÿé…ç½®å·¥å…·
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
current_file = os.path.abspath(__file__)  # E:\liusisi\SmartSisi\evoliu\liuye_frontend\liuye_voice_tts.py
frontend_dir = os.path.dirname(current_file)  # E:\liusisi\SmartSisi\evoliu\liuye_frontend
evoliu_dir = os.path.dirname(frontend_dir)  # E:\liusisi\SmartSisi\evoliu
project_root = os.path.dirname(evoliu_dir)  # E:\liusisi\SmartSisi

if project_root not in sys.path:
    sys.path.insert(0, project_root)

print(f"ğŸ”§ é¡¹ç›®æ ¹ç›®å½•: {project_root}")

try:
    from utils.config_util import load_config, liuye_tts_api_key, liuye_voice_uri

    # åŠ è½½é…ç½®
    load_config()

    # è·å–æŸ³å¶TTSé…ç½®
    LIUYE_API_KEY = liuye_tts_api_key
    LIUYE_VOICE_URI = liuye_voice_uri

    # æ£€æŸ¥é…ç½®æ˜¯å¦æœ‰æ•ˆï¼ˆä¸è¦åœ¨ä»£ç é‡Œç¡¬ç¼–ç å¯†é’¥ï¼‰
    if not LIUYE_API_KEY or not LIUYE_VOICE_URI:
        print("âš ï¸ ç³»ç»Ÿé…ç½®ä¸­æŸ³å¶TTSé…ç½®æ— æ•ˆï¼Œè¯·åœ¨ system.conf ä¸­é…ç½®ï¼šliuye_tts_api_key / liuye_voice_uri")
        LIUYE_API_KEY = ""
        LIUYE_VOICE_URI = ""
    else:
        print("âœ… ä»ç³»ç»Ÿé…ç½®åŠ è½½æŸ³å¶TTSé…ç½®")

    print(f"ğŸ¤ éŸ³è‰²URI: {LIUYE_VOICE_URI}")

except Exception as e:
    print(f"âš ï¸ é…ç½®ç³»ç»ŸåŠ è½½å¤±è´¥: {e}")
    print("ğŸ”„ è¯·åœ¨ system.conf ä¸­é…ç½®ï¼šliuye_tts_api_key / liuye_voice_uri")
    LIUYE_API_KEY = ""
    LIUYE_VOICE_URI = ""

# TTSé«˜çº§åŠŸèƒ½é…ç½®

# ========== è®¾å¤‡è¿æ¥ä¸ç»Ÿä¸€éŸ³é¢‘é€šè·¯è¾…åŠ© ==========
def _is_device_connected() -> bool:
    """æ£€æµ‹æ˜¯å¦æœ‰ESP32è®¾å¤‡åœ¨çº¿ï¼ˆç”¨äºè®¾å¤‡ä¼˜å…ˆç­–ç•¥ï¼‰"""
    try:
        import sys
        # ä»sisi_booteræ‹¿é€‚é…å™¨ï¼ˆä¼˜å…ˆï¼‰
        try:
            import sisi_booter
            adapter = getattr(sisi_booter, 'esp32_adapter', None)
            if adapter and getattr(adapter, 'clients', None):
                for _cid, ws in adapter.clients.items():
                    if ws and not getattr(ws, 'closed', False):
                        return True
        except Exception:
            pass

        # é€€è€Œæ±‚å…¶æ¬¡ï¼šä»å·²åŠ è½½æ¨¡å—ä¸­çŒœæµ‹
        for name, mod in sys.modules.items():
            if not mod:
                continue
            if 'adapter' in name.lower() and hasattr(mod, 'clients'):
                try:
                    clients = getattr(mod, 'clients')
                    if clients:
                        for _cid, ws in clients.items():
                            if ws and not getattr(ws, 'closed', False):
                                return True
                except Exception:
                    continue
    except Exception:
        return False
    return False

def _get_audio_manager():
    """è·å–ç»Ÿä¸€çš„AudioOutputManagerå®ä¾‹ï¼ˆè‹¥ä¸å¯ç”¨è¿”å›Noneï¼‰"""
    try:
        from esp32_liusisi.sisi_audio_output import AudioOutputManager
        return AudioOutputManager.get_instance()
    except Exception:
        return None
TTS_EMOTIONS = {
    "é«˜å…´": "é«˜å…´", "å¼€å¿ƒ": "é«˜å…´", "å¿«ä¹": "é«˜å…´", "å…´å¥‹": "å…´å¥‹",
    "æ‚²ä¼¤": "æ‚²ä¼¤", "éš¾è¿‡": "æ‚²ä¼¤", "ä¼¤å¿ƒ": "æ‚²ä¼¤", "æ²®ä¸§": "æ‚²ä¼¤",
    "æ„¤æ€’": "æ„¤æ€’", "ç”Ÿæ°”": "æ„¤æ€’", "æ„¤æ…¨": "æ„¤æ€’", "æ¼ç«": "æ„¤æ€’",
    "æ¸©æŸ”": "æ¸©æŸ”", "è½»æŸ”": "æ¸©æŸ”", "æŸ”å’Œ": "æ¸©æŸ”", "äº²åˆ‡": "æ¸©æŸ”",
    "æ¿€æƒ…": "æ¿€æƒ…", "çƒ­æƒ…": "æ¿€æƒ…", "æ¿€åŠ¨": "æ¿€æƒ…", "æ¾æ¹ƒ": "æ¿€æƒ…",
    "æ²‰ç¨³": "æ²‰ç¨³", "ç¨³é‡": "æ²‰ç¨³", "å†·é™": "æ²‰ç¨³", "å¹³é™": "æ²‰ç¨³",
    "æ¬¢å¿«": "æ¬¢å¿«", "æ´»æ³¼": "æ¬¢å¿«", "è½»å¿«": "æ¬¢å¿«", "æ„‰æ‚¦": "æ¬¢å¿«"
}

TTS_SOUND_EFFECTS = {
    "[laughter]": "ç¬‘å£°", "[breathing]": "å‘¼å¸å£°", "[sigh]": "å¹æ°”å£°",
    "[whisper]": "è€³è¯­", "[pause]": "åœé¡¿", "[speed_up]": "åŠ é€Ÿ",
    "[slow_down]": "å‡é€Ÿ", "[emphasis]": "å¼ºè°ƒ", "[soft]": "è½»å£°"
}

TTS_DIALECTS = {
    "ç²¤è¯­": "ç²¤è¯­", "å¹¿ä¸œè¯": "ç²¤è¯­", "ç™½è¯": "ç²¤è¯­",
    "å››å·è¯": "å››å·è¯", "å·è¯": "å››å·è¯", "å·´èœ€è¯": "å››å·è¯",
    "ä¸Šæµ·è¯": "ä¸Šæµ·è¯", "æ²ªè¯­": "ä¸Šæµ·è¯", "ä¸Šæµ·æ–¹è¨€": "ä¸Šæµ·è¯",
    "éƒ‘å·è¯": "éƒ‘å·è¯", "æ²³å—è¯": "éƒ‘å·è¯", "ä¸­åŸè¯": "éƒ‘å·è¯",
    "é•¿æ²™è¯": "é•¿æ²™è¯", "æ¹–å—è¯": "é•¿æ²™è¯", "æ¹˜è¯­": "é•¿æ²™è¯",
    "å¤©æ´¥è¯": "å¤©æ´¥è¯", "æ´¥é—¨è¯": "å¤©æ´¥è¯", "å¤©æ´¥æ–¹è¨€": "å¤©æ´¥è¯"
}

TTS_LANGUAGES = {
    "è‹±æ–‡": "è‹±æ–‡", "è‹±è¯­": "è‹±æ–‡", "English": "è‹±æ–‡",
    "æ—¥æ–‡": "æ—¥è¯­", "æ—¥è¯­": "æ—¥è¯­", "Japanese": "æ—¥è¯­",
    "éŸ©æ–‡": "éŸ©è¯­", "éŸ©è¯­": "éŸ©è¯­", "Korean": "éŸ©è¯­"
}

def enhance_text_with_tts_features(text, emotion=None, dialect=None, language=None, sound_effects=None):
    """
    æ™ºèƒ½å¢å¼ºæ–‡æœ¬ï¼Œæ·»åŠ TTSç‰¹æ€§æ ‡è¯†

    Args:
        text: åŸå§‹æ–‡æœ¬
        emotion: æƒ…æ„Ÿ (å¦‚: "é«˜å…´", "æ‚²ä¼¤")
        dialect: æ–¹è¨€ (å¦‚: "ç²¤è¯­", "å››å·è¯")
        language: è¯­è¨€ (å¦‚: "è‹±æ–‡", "æ—¥è¯­")
        sound_effects: éŸ³æ•ˆåˆ—è¡¨ (å¦‚: ["[laughter]", "[breathing]"])

    Returns:
        å¢å¼ºåçš„æ–‡æœ¬
    """
    enhanced_text = text

    # æ·»åŠ æƒ…æ„Ÿæ§åˆ¶
    if emotion and emotion in TTS_EMOTIONS:
        emotion_key = TTS_EMOTIONS[emotion]
        enhanced_text = f"ä½ èƒ½ç”¨{emotion_key}çš„æƒ…æ„Ÿè¯´å—ï¼Ÿ<|endofprompt|>{enhanced_text}"

    # æ·»åŠ æ–¹è¨€æ§åˆ¶
    elif dialect and dialect in TTS_DIALECTS:
        dialect_key = TTS_DIALECTS[dialect]
        enhanced_text = f"è¯·é—®ä½ èƒ½æ¨¡ä»¿{dialect_key}çš„å£éŸ³å—ï¼Ÿ<|endofprompt|>{enhanced_text}"

    # æ·»åŠ è¯­è¨€æ§åˆ¶
    elif language and language in TTS_LANGUAGES:
        language_key = TTS_LANGUAGES[language]
        enhanced_text = f"è¯·ç”¨{language_key}è¯´ï¼š<|endofprompt|>{enhanced_text}"

    # æ·»åŠ éŸ³æ•ˆ
    if sound_effects:
        for effect in sound_effects:
            if effect in TTS_SOUND_EFFECTS:
                # åœ¨å¥å­ç»“å°¾æ·»åŠ éŸ³æ•ˆ
                enhanced_text = enhanced_text.replace("ã€‚", f"{effect}ã€‚")
                enhanced_text = enhanced_text.replace("ï¼", f"{effect}ï¼")
                enhanced_text = enhanced_text.replace("ï¼Ÿ", f"{effect}ï¼Ÿ")

    return enhanced_text

def parse_tts_instructions(text):
    """
    è§£ææ–‡æœ¬ä¸­çš„TTSæŒ‡ä»¤

    Args:
        text: åŒ…å«TTSæŒ‡ä»¤çš„æ–‡æœ¬

    Returns:
        dict: è§£æå‡ºçš„TTSå‚æ•°
    """
    instructions = {
        "emotion": None,
        "dialect": None,
        "language": None,
        "sound_effects": [],
        "clean_text": text
    }

    # æ£€æµ‹æƒ…æ„ŸæŒ‡ä»¤
    for emotion_key in TTS_EMOTIONS:
        if emotion_key in text:
            instructions["emotion"] = emotion_key
            break

    # æ£€æµ‹æ–¹è¨€æŒ‡ä»¤
    for dialect_key in TTS_DIALECTS:
        if dialect_key in text:
            instructions["dialect"] = dialect_key
            break

    # æ£€æµ‹è¯­è¨€æŒ‡ä»¤
    for language_key in TTS_LANGUAGES:
        if language_key in text:
            instructions["language"] = language_key
            break

    # æ£€æµ‹éŸ³æ•ˆæŒ‡ä»¤
    for effect_key in TTS_SOUND_EFFECTS:
        if effect_key in text:
            instructions["sound_effects"].append(effect_key)

    return instructions

def generate_liuye_voice_smart(text, output_filename=None, **tts_options):
    """
    æ™ºèƒ½æŸ³å¶è¯­éŸ³ç”Ÿæˆ - è‡ªåŠ¨è§£æTTSæŒ‡ä»¤

    Args:
        text: æ–‡æœ¬å†…å®¹
        output_filename: è¾“å‡ºæ–‡ä»¶å
        **tts_options: TTSé€‰é¡¹ (emotion, dialect, language, sound_effectsç­‰)

    Returns:
        ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    """
    # è§£ææ–‡æœ¬ä¸­çš„TTSæŒ‡ä»¤
    instructions = parse_tts_instructions(text)

    # åˆå¹¶æ˜¾å¼å‚æ•°å’Œè§£æå‡ºçš„æŒ‡ä»¤
    final_options = {**instructions, **tts_options}

    # å¢å¼ºæ–‡æœ¬
    enhanced_text = enhance_text_with_tts_features(
        final_options["clean_text"],
        emotion=final_options.get("emotion"),
        dialect=final_options.get("dialect"),
        language=final_options.get("language"),
        sound_effects=final_options.get("sound_effects")
    )

    print(f"ğŸ­ æ™ºèƒ½TTSå¤„ç†:")
    print(f"   åŸæ–‡æœ¬: {text}")
    print(f"   å¢å¼ºæ–‡æœ¬: {enhanced_text}")
    print(f"   æƒ…æ„Ÿ: {final_options.get('emotion', 'æ— ')}")
    print(f"   æ–¹è¨€: {final_options.get('dialect', 'æ— ')}")
    print(f"   è¯­è¨€: {final_options.get('language', 'æ— ')}")
    print(f"   éŸ³æ•ˆ: {final_options.get('sound_effects', 'æ— ')}")

    # ç”Ÿæˆè¯­éŸ³
    return generate_liuye_voice_streaming(enhanced_text, output_filename)

def split_text_into_sentences(text):
    """
    æ™ºèƒ½ä¸­æ–‡åˆ†å¥ - åŸºäºä¸­æ–‡æ ‡ç‚¹ç¬¦å·æ ‡å‡†
    åœé¡¿æ—¶é•¿ï¼šå¥å· > åˆ†å· > é€—å· > é¡¿å·

    ä¼˜åŒ–ç­–ç•¥ï¼š
    1. ä¼˜å…ˆæŒ‰å¥æœ«ç‚¹å·åˆ†å¥ï¼ˆå¥å·ã€é—®å·ã€å¹å·ï¼‰- æœ€é•¿åœé¡¿
    2. å…¶æ¬¡æŒ‰åˆ†å·åˆ†å¥ - ä¸­ç­‰åœé¡¿
    3. é•¿å¥æŒ‰é€—å·åˆ†å¥ - çŸ­åœé¡¿
    4. ä¿æŒè‡ªç„¶è¯­éŸ³èŠ‚å¥
    """
    # ç¬¬ä¸€æ­¥ï¼šæŒ‰å¥æœ«ç‚¹å·åˆ†å¥ï¼ˆå¥å·ã€é—®å·ã€å¹å·ï¼‰
    primary_sentences = re.split(r'([ã€‚ï¼ï¼Ÿ.!?])', text)

    result = []
    current_sentence = ""

    for i in range(0, len(primary_sentences), 2):
        if i < len(primary_sentences):
            sentence_part = primary_sentences[i].strip()
            punctuation = primary_sentences[i+1] if i+1 < len(primary_sentences) else ""

            if sentence_part:
                full_sentence = sentence_part + punctuation

                # å¦‚æœå¥å­å¤ªé•¿ï¼ˆ>50å­—ï¼‰ï¼ŒæŒ‰åˆ†å·æˆ–é€—å·è¿›ä¸€æ­¥åˆ†å¥
                if len(sentence_part) > 50:
                    # æŒ‰åˆ†å·åˆ†å¥
                    sub_sentences = re.split(r'([ï¼›;])', sentence_part)
                    for j in range(0, len(sub_sentences), 2):
                        if j < len(sub_sentences):
                            sub_part = sub_sentences[j].strip()
                            sub_punct = sub_sentences[j+1] if j+1 < len(sub_sentences) else ""

                            if sub_part:
                                # å¦‚æœå­å¥è¿˜æ˜¯å¤ªé•¿ï¼ˆ>30å­—ï¼‰ï¼ŒæŒ‰é€—å·åˆ†å¥
                                if len(sub_part) > 30:
                                    comma_parts = re.split(r'([ï¼Œ,])', sub_part)
                                    for k in range(0, len(comma_parts), 2):
                                        if k < len(comma_parts):
                                            comma_part = comma_parts[k].strip()
                                            comma_punct = comma_parts[k+1] if k+1 < len(comma_parts) else ""

                                            if comma_part:
                                                # æœ€åä¸€ä¸ªé€—å·åˆ†å¥åŠ ä¸ŠåŸå¥çš„æ ‡ç‚¹
                                                if k == len(comma_parts) - 2:
                                                    result.append(comma_part + comma_punct + sub_punct + punctuation)
                                                else:
                                                    result.append(comma_part + comma_punct)
                                else:
                                    # æœ€åä¸€ä¸ªåˆ†å·åˆ†å¥åŠ ä¸ŠåŸå¥çš„æ ‡ç‚¹
                                    if j == len(sub_sentences) - 2:
                                        result.append(sub_part + sub_punct + punctuation)
                                    else:
                                        result.append(sub_part + sub_punct)
                else:
                    result.append(full_sentence)

    # è¿‡æ»¤ç©ºå¥å­å¹¶ç¡®ä¿æ ‡ç‚¹
    final_result = []
    for sentence in result:
        sentence = sentence.strip()
        if sentence:
            # å¦‚æœæ²¡æœ‰æ ‡ç‚¹ï¼Œæ·»åŠ å¥å·
            if not re.search(r'[ã€‚ï¼ï¼Ÿï¼›ï¼Œã€.!?;,]$', sentence):
                sentence += 'ã€‚'
            final_result.append(sentence)

    return final_result

def generate_liuye_voice_optimized_streaming(text, output_dir=None, play_realtime=True):
    """
    ä¿®å¤åçš„æµå¼æ’­æ”¾å®ç° - æ¶ˆé™¤å™ªéŸ³é—®é¢˜

    ä¿®å¤å†…å®¹ï¼š
    1. æ”¹ç”¨pyaudio + wave.open(response.raw)å®ç°çœŸæ­£çš„æµå¼æ’­æ”¾
    2. æ¶ˆé™¤pygame.mixer.Sound(buffer=chunk)çš„å™ªéŸ³é—®é¢˜
    3. ä¿æŒä½å»¶è¿Ÿä¼˜åŠ¿
    4. ç¡®ä¿éŸ³è´¨æ­£å¸¸

    Args:
        text (str): è¦è½¬æ¢çš„æ–‡æœ¬
        output_dir (str): è¾“å‡ºç›®å½•
        play_realtime (bool): æ˜¯å¦å®æ—¶æ’­æ”¾

    Returns:
        list: ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    session = clear_proxies()

    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
    if output_dir is None:
        output_dir = Path("E:/liusisi/SmartSisi/evoliu/liuye_decision_center/data/æŸ³å¶è¯­éŸ³æ–‡ä»¶")
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # ğŸ”¥ **ç§»é™¤åˆ†å¥é€»è¾‘ï¼Œç›´æ¥å¤„ç†å®Œæ•´æ–‡æœ¬**
    print(f"ğŸµ ä¿®å¤åçš„æµå¼æ’­æ”¾ - æ— åˆ†å¥å¤„ç†")
    print(f"ğŸ“ å®Œæ•´æ–‡æœ¬: {text}")

    generated_files = []
    total_start_time = time.time()

    # ğŸ”¥ **ç›´æ¥å¤„ç†å®Œæ•´æ–‡æœ¬ï¼Œä¸è¿›è¡Œåˆ†å¥**
    print(f"\nğŸ”Š ç”Ÿæˆå®Œæ•´æ–‡æœ¬: {text}")

    sentence_start_time = time.time()

    # ç”Ÿæˆå®Œæ•´æ–‡æœ¬çš„éŸ³é¢‘
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_filename = f"liuye_fixed_{timestamp}.wav"
    output_path = output_dir / output_filename

    # ğŸ”§ ä¼˜åŒ–ï¼šä½¿ç”¨æ›´å¿«çš„æµå¼å‚æ•°ï¼Œå‡å°‘å»¶è¿Ÿ
    url = "https://api.siliconflow.cn/v1/audio/speech"
    headers = {"Authorization": f"Bearer {LIUYE_API_KEY}"}

    payload = {
        "model": "FunAudioLLM/CosyVoice2-0.5B",
        "input": text,
        "voice": LIUYE_VOICE_URI,
        "response_format": "wav",
        "sample_rate": 16000,  # ä¸ç»Ÿä¸€é“¾è·¯ä¿æŒä¸€è‡´
        "gain": -2,
        "stream": True,
        "speed": 1.0
    }

    try:
        # æµå¼è¯·æ±‚
        response = session.post(url, headers=headers, json=payload, stream=True, timeout=60)

        if response.status_code == 200:
            first_chunk_time = None

            # ä¿å­˜å®Œæ•´éŸ³é¢‘æ–‡ä»¶
            with open(output_path, 'wb') as f:
                chunk_count = 0
                for chunk in response.iter_content(chunk_size=1024):
                    if chunk:
                        chunk_count += 1
                        f.write(chunk)

                        # è®°å½•é¦–å—å»¶è¿Ÿ
                        if first_chunk_time is None:
                            first_chunk_time = time.time()
                            first_chunk_delay = first_chunk_time - sentence_start_time
                            print(f"     âš¡ é¦–å—å»¶è¿Ÿ: {first_chunk_delay:.3f}ç§’")

            sentence_end_time = time.time()
            sentence_total_time = sentence_end_time - sentence_start_time
            file_size = output_path.stat().st_size

            print(f"     âœ… å®Œæ•´æ–‡æœ¬å®Œæˆ: {sentence_total_time:.3f}ç§’")
            print(f"     ğŸ“ æ–‡ä»¶: {output_path.name} ({file_size} å­—èŠ‚)")
            print(f"     ğŸ“¦ æ•°æ®å—: {chunk_count} ä¸ª")

            # ç»Ÿä¸€ï¼šä¸åœ¨æ­¤å¤„è§¦å‘PCæœ¬åœ°æ’­æ”¾ï¼Œäº¤ç”±ä¸Šå±‚å†³å®šï¼ˆè®¾å¤‡ä¼˜å…ˆç”±Coreæ’­æ”¾ï¼‰
            if play_realtime:
                print(f"     ğŸµ å·²ç”Ÿæˆå®Œæ•´æ–‡æœ¬ï¼ˆè®¾å¤‡ä¼˜å…ˆï¼Œè·³è¿‡PCå³æ—¶æ’­æ”¾ï¼‰")

            generated_files.append(str(output_path))

        else:
            print(f"     âŒ ç”Ÿæˆå¤±è´¥: {response.status_code}")

    except Exception as e:
        print(f"     âŒ å¼‚å¸¸: {e}")

    total_end_time = time.time()
    total_time = total_end_time - total_start_time

    print(f"\nğŸ‰ ä¿®å¤åçš„æµå¼æ’­æ”¾å®Œæˆ!")
    print(f"ğŸ“Š æ€»è€—æ—¶: {total_time:.3f}ç§’")
    print(f"ğŸ“Š å®Œæ•´æ–‡æœ¬å¤„ç†: 1ä¸ªæ–‡ä»¶")
    # ä¸å†è®¡ç®—å¹³å‡æ¯å¥æ—¶é—´ï¼Œå› ä¸ºå·²æ”¹ä¸ºå¤„ç†å®Œæ•´æ–‡æœ¬
    print(f"ğŸ“ ç”Ÿæˆæ–‡ä»¶: {len(generated_files)} ä¸ª")

    return generated_files

def _play_audio_stream_optimized(audio_queue, sample_rate):
    return

def generate_liuye_voice_streaming(text, output_filename=None, play_realtime=False):
    """
    æŸ³å¶TTSæµå¼æ’­æ”¾ - ä¿®å¤åç‰ˆæœ¬
    å®ç°çœŸæ­£çš„Adaptive Streamingï¼ˆè‡ªé€‚åº”æµå¼æ’­æ”¾ï¼‰
    - æ¶ˆé™¤æ‚éŸ³å’Œçˆ†éŸ³é—®é¢˜
    - è¾¹æ¥æ”¶HTTP chunksè¾¹æ’­æ”¾
    - éŸ³è´¨æ¸…æ™°ï¼Œå»¶è¿Ÿä½ï¼ˆ~200msæµå¼å»¶è¿Ÿï¼‰

    Args:
        text (str): è¦è½¬æ¢çš„æ–‡æœ¬
        output_filename (str): è¾“å‡ºæ–‡ä»¶åï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
        play_realtime (bool): æ˜¯å¦å®æ—¶æ’­æ”¾

    Returns:
        str: ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
    """
    import struct

    session = clear_proxies()

    # é…ç½®ä¿¡æ¯
    api_key = LIUYE_API_KEY
    voice_uri = LIUYE_VOICE_URI

    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
    output_dir = Path("E:/liusisi/SmartSisi/evoliu/liuye_decision_center/data/æŸ³å¶è¯­éŸ³æ–‡ä»¶")
    output_dir.mkdir(parents=True, exist_ok=True)

    # ç”Ÿæˆæ–‡ä»¶å
    if output_filename is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_filename = f"liuye_stream_{timestamp}.wav"

    output_path = output_dir / output_filename

    url = "https://api.siliconflow.cn/v1/audio/speech"
    headers = {"Authorization": f"Bearer {api_key}"}

    payload = {
        "model": "FunAudioLLM/CosyVoice2-0.5B",
        "input": text,
        "voice": voice_uri,
        "response_format": "wav",
        "sample_rate": 16000,  # ç»Ÿä¸€ä¸º16kHzï¼Œäº¤ç”±AudioOutputManagerå†…éƒ¨ç¼–ç 
        "gain": -2,
        "stream": True
    }

    print(f"ğŸŒŠ æŸ³å¶TTSæµå¼æ’­æ”¾")
    print(f"ğŸ“ æ–‡æœ¬: {text}")
    print(f"ğŸ“ è¾“å‡º: {output_path}")
    print(f"ğŸ”Š å®æ—¶æ’­æ”¾(PC): {'æ˜¯' if play_realtime else 'å¦'}")

    def parse_wav_header(data):
        """è§£æWAVæ–‡ä»¶å¤´"""
        if len(data) < 44 or data[:4] != b'RIFF' or data[8:12] != b'WAVE':
            return None

        # æŸ¥æ‰¾fmt chunk
        fmt_pos = data.find(b'fmt ')
        if fmt_pos == -1:
            return None

        fmt_size = struct.unpack('<I', data[fmt_pos+4:fmt_pos+8])[0]
        fmt_data = data[fmt_pos+8:fmt_pos+8+fmt_size]

        if len(fmt_data) < 16:
            return None

        audio_format, channels, sample_rate, byte_rate, block_align, bits_per_sample = struct.unpack('<HHIIHH', fmt_data[:16])

        # æŸ¥æ‰¾data chunk
        data_pos = data.find(b'data')
        if data_pos == -1:
            return None

        audio_data_start = data_pos + 8

        return {
            'channels': channels,
            'sample_rate': sample_rate,
            'bits_per_sample': bits_per_sample,
            'block_align': block_align,
            'audio_data_start': audio_data_start
        }

    try:
        print(f"ğŸ“¡ å‘é€æµå¼è¯·æ±‚...")
        request_start_time = time.time()

        response = session.post(url, headers=headers, json=payload, stream=True, timeout=120)

        if response.status_code == 200:
            first_byte_time = time.time()
            first_byte_delay = (first_byte_time - request_start_time) * 1000
            print(f"âœ… é¦–å­—èŠ‚å»¶è¿Ÿ: {first_byte_delay:.0f}ms")

            # å°è¯•å¯¼å…¥pyaudioè¿›è¡ŒçœŸæ­£çš„æµå¼æ’­æ”¾
            try:
                import pyaudio
                PYAUDIO_AVAILABLE = True
            except ImportError:
                PYAUDIO_AVAILABLE = False

            if play_realtime and PYAUDIO_AVAILABLE:
                # è®¾å¤‡ä¼˜å…ˆï¼šè‹¥ä¼ å…¥è¦æ±‚PCæ’­æ”¾æ‰å¯ç”¨ï¼›é»˜è®¤Falseä¸åœ¨PCæ’­æ”¾
                print(f"ğŸŒŠ å¼€å§‹PCç«¯æµå¼æ’­æ”¾ï¼ˆä»…è°ƒè¯•ç”¨ï¼‰...")

                audio_buffer = b""
                complete_audio = b""
                header_parsed = False
                audio_info = None
                p = None
                stream = None
                first_audio_time = None
                chunk_count = 0
                min_buffer_size = 4096  # 4KBç¼“å†²

                for chunk in response.iter_content(chunk_size=1024):
                    if chunk:
                        chunk_count += 1
                        audio_buffer += chunk
                        complete_audio += chunk

                        # è§£æWAVå¤´éƒ¨ï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡ï¼‰
                        if not header_parsed and len(audio_buffer) >= 44:
                            audio_info = parse_wav_header(audio_buffer)
                            if audio_info:
                                print(f"ğŸ“Š éŸ³é¢‘å‚æ•°: {audio_info['sample_rate']}Hz, {audio_info['channels']}å£°é“, {audio_info['bits_per_sample']}bit")

                                # åˆå§‹åŒ–pyaudio
                                p = pyaudio.PyAudio()
                                format = pyaudio.paInt16 if audio_info['bits_per_sample'] == 16 else pyaudio.paInt24

                                stream = p.open(
                                    format=format,
                                    channels=audio_info['channels'],
                                    rate=audio_info['sample_rate'],
                                    output=True,
                                    frames_per_buffer=1024
                                )

                                header_parsed = True

                                # è·³è¿‡WAVå¤´éƒ¨ï¼Œè·å–çº¯éŸ³é¢‘æ•°æ®
                                if len(audio_buffer) > audio_info['audio_data_start']:
                                    pure_audio_data = audio_buffer[audio_info['audio_data_start']:]
                                    audio_buffer = pure_audio_data

                        # å¦‚æœå¤´éƒ¨å·²è§£æä¸”æœ‰è¶³å¤Ÿçš„éŸ³é¢‘æ•°æ®ï¼Œå¼€å§‹æ’­æ”¾
                        if header_parsed and stream and len(audio_buffer) >= min_buffer_size:
                            if first_audio_time is None:
                                first_audio_time = time.time()
                                first_audio_delay = (first_audio_time - request_start_time) * 1000
                                print(f"ğŸµ é¦–æ¬¡æ’­æ”¾å»¶è¿Ÿ: {first_audio_delay:.0f}ms")

                            # æŒ‰éŸ³é¢‘å¸§å¯¹é½æ’­æ”¾
                            block_align = audio_info['block_align']
                            playable_frames = len(audio_buffer) // block_align
                            playable_bytes = playable_frames * block_align

                            if playable_bytes > 0:
                                stream.write(audio_buffer[:playable_bytes])
                                audio_buffer = audio_buffer[playable_bytes:]

                            if chunk_count % 50 == 0:
                                current_time = time.time()
                                elapsed = current_time - request_start_time
                                print(f"   ğŸŒŠ æµå¼æ’­æ”¾è¿›åº¦: ç¬¬{chunk_count}ä¸ªchunkï¼Œå·²æ’­æ”¾ {elapsed:.1f}ç§’")

                # æ’­æ”¾å‰©ä½™éŸ³é¢‘æ•°æ®
                if header_parsed and stream and len(audio_buffer) > 0:
                    block_align = audio_info['block_align']
                    playable_frames = len(audio_buffer) // block_align
                    playable_bytes = playable_frames * block_align
                    if playable_bytes > 0:
                        stream.write(audio_buffer[:playable_bytes])

                if stream:
                    print(f"âœ… çœŸæ­£çš„æµå¼æ’­æ”¾å®Œæˆï¼Œå¤„ç†äº† {chunk_count} ä¸ªHTTP chunks")
                    stream.close()
                if p:
                    p.terminate()

                # ä¿å­˜å®Œæ•´éŸ³é¢‘æ–‡ä»¶
                with open(output_path, 'wb') as f:
                    f.write(complete_audio)

                total_time = time.time() - request_start_time
                print(f"ğŸ“Š æŸ³å¶TTSæµå¼æ’­æ”¾æ€»ç»“:")
                print(f"   é¦–å­—èŠ‚å»¶è¿Ÿ: {first_byte_delay:.0f}ms")
                if first_audio_time:
                    print(f"   é¦–æ¬¡æ’­æ”¾å»¶è¿Ÿ: {(first_audio_time - request_start_time) * 1000:.0f}ms")
                print(f"   æ€»è€—æ—¶: {total_time:.2f}ç§’")
                print(f"   HTTP chunks: {chunk_count}")

            else:
                # è®¾å¤‡ä¼˜å…ˆï¼šæ”¹ä¸ºçœŸæ­£é€å—é€å…¥ç»Ÿä¸€é˜Ÿåˆ—ï¼Œä¸å†æ•´æ®µç´¯è®¡
                print(f"ğŸ“¦ é€å—è½¬äº¤ç»Ÿä¸€éŸ³é¢‘é˜Ÿåˆ—ï¼ˆè®¾å¤‡ä¼˜å…ˆï¼Œä¸åœ¨PCæ’­æ”¾ï¼‰...")
                header_buffer = bytearray()
                wav_header_parsed = False
                audio_data_start = 0
                chunk_count = 0
                total_bytes = 0

                # è¾“å…¥WAVå‚æ•°ä¸è½¬æ¢çŠ¶æ€
                in_rate = None
                in_channels = None
                in_width = None  # bytes per sample
                pcm_pending = bytearray()
                ratecv_state = None

                from esp32_liusisi.sisi_audio_output import AudioOutputManager
                aom = AudioOutputManager.get_instance()
                if not aom:
                    print(f"âš ï¸ æœªæ‰¾åˆ°AudioOutputManagerå®ä¾‹ï¼Œæ— æ³•é€å…¥ç»Ÿä¸€é˜Ÿåˆ—")
                    # ä»ä¿å­˜æ–‡ä»¶ä»¥ä¾¿æ’æŸ¥
                    with open(output_path, 'wb') as f:
                        for chunk in response.iter_content(chunk_size=8192):
                            if chunk:
                                f.write(chunk)
                    return None

                import audioop

                def _push_converted_pcm(pcm_bytes: bytes, is_final: bool = False):
                    nonlocal pcm_pending, ratecv_state, in_channels, in_width, in_rate
                    if not pcm_bytes and not is_final:
                        return
                    pcm_pending.extend(pcm_bytes)
                    if in_channels and in_width and in_rate:
                        frame_size_in = in_channels * in_width
                        # åªå¤„ç†å¯¹é½çš„æ•´å¸§ï¼Œå‰©ä½™ç•™å¾…ä¸‹æ¬¡
                        process_len = (len(pcm_pending) // frame_size_in) * frame_size_in
                        if process_len > 0:
                            to_process = bytes(pcm_pending[:process_len])
                            pcm_pending = pcm_pending[process_len:]

                            data_conv = to_process
                            # å£°é“è½¬å•å£°é“
                            if in_channels == 2:
                                try:
                                    data_conv = audioop.tomono(data_conv, in_width, 0.5, 0.5)
                                except Exception:
                                    # å¤±è´¥åˆ™å–å·¦å£°é“è¿‘ä¼¼
                                    data_conv = data_conv[0::2*in_width] + data_conv[in_width::2*in_width]
                                    data_conv = audioop.lin2lin(data_conv, in_width, in_width)
                            elif in_channels != 1:
                                # é1/2å£°é“ï¼Œä¿å®ˆå–ç¬¬ä¸€å£°é“æ ·æœ¬
                                try:
                                    # ä¾å£°é“å®½åº¦æ‹†åˆ†ï¼Œå–ç¬¬ä¸€å£°é“
                                    step = in_channels * in_width
                                    data_conv = b''.join([to_process[i:i+in_width] for i in range(0, len(to_process), step)])
                                except Exception:
                                    pass

                            # ä½å®½è½¬16bit
                            if in_width != 2:
                                try:
                                    data_conv = audioop.lin2lin(data_conv, in_width, 2)
                                except Exception:
                                    # æ— æ³•è½¬æ¢åˆ™ä¸¢å¼ƒè¯¥æ®µï¼Œé¿å…çˆ†éŸ³
                                    data_conv = b''

                            # é‡‡æ ·ç‡è½¬16k
                            if in_rate != 16000 and data_conv:
                                try:
                                    data_conv, ratecv_state = audioop.ratecv(data_conv, 2, 1, in_rate, 16000, ratecv_state)
                                except Exception:
                                    data_conv = b''

                            if data_conv:
                                aom.add_stream_chunk(data_conv, priority=5, is_final=False)

                    # æœ€ç»ˆflushå‰©ä½™å¹¶å‘é€ç»“æŸæ ‡è®°
                    if is_final:
                        # æŠŠå‰©ä½™å¯¹é½åå†è½¬
                        if in_channels and in_width and in_rate and len(pcm_pending) > 0:
                            frame_size_in2 = in_channels * in_width
                            tail_len = (len(pcm_pending) // frame_size_in2) * frame_size_in2
                            if tail_len > 0:
                                tail = bytes(pcm_pending[:tail_len])
                                pcm_pending = pcm_pending[tail_len:]
                                try:
                                    data_conv = tail
                                    if in_channels == 2:
                                        data_conv = audioop.tomono(data_conv, in_width, 0.5, 0.5)
                                    elif in_channels != 1:
                                        step = in_channels * in_width
                                        data_conv = b''.join([tail[i:i+in_width] for i in range(0, len(tail), step)])
                                    if in_width != 2:
                                        data_conv = audioop.lin2lin(data_conv, in_width, 2)
                                    if in_rate != 16000:
                                        data_conv, ratecv_state = audioop.ratecv(data_conv, 2, 1, in_rate, 16000, ratecv_state)
                                    if data_conv:
                                        aom.add_stream_chunk(data_conv, priority=5, is_final=False)
                                except Exception:
                                    pass
                        aom.add_stream_chunk(b'', priority=5, is_final=True)

                for net_chunk in response.iter_content(chunk_size=4096):
                    if not net_chunk:
                        continue
                    chunk_count += 1
                    total_bytes += len(net_chunk)

                    if not wav_header_parsed:
                        header_buffer.extend(net_chunk)
                        if len(header_buffer) >= 44 and header_buffer[:4] == b'RIFF' and header_buffer[8:12] == b'WAVE':
                            # è§£æWAVå¤´
                            info = parse_wav_header(bytes(header_buffer))
                            if info:
                                audio_data_start = info['audio_data_start']
                                in_channels = info['channels']
                                in_rate = info['sample_rate']
                                in_width = max(1, info['bits_per_sample'] // 8)
                                # å°†å¤´åé¢çš„éŸ³é¢‘æ•°æ®ä½œä¸ºç¬¬ä¸€æ‰¹PCMæäº¤ï¼ˆè§„èŒƒåŒ–å¤„ç†ï¼‰
                                if len(header_buffer) > audio_data_start:
                                    pcm_part = bytes(header_buffer[audio_data_start:])
                                    if pcm_part:
                                        _push_converted_pcm(pcm_part, is_final=False)
                                header_buffer.clear()
                                wav_header_parsed = True
                            continue
                        elif len(header_buffer) >= 44:
                            # éæ ‡å‡†å¤´ï¼Œå½“ä½œåŸå§‹PCMï¼Œé‡‡ç”¨ä¿å®ˆé»˜è®¤å‚æ•°ï¼š16k/å•å£°é“/16bit
                            if in_channels is None:
                                in_channels = 1
                                in_rate = 16000
                                in_width = 2
                            _push_converted_pcm(bytes(header_buffer), is_final=False)
                            header_buffer.clear()
                            wav_header_parsed = True
                            continue
                        else:
                            continue
                    else:
                        # å·²è§£æå¤´ï¼Œç›´æ¥è§„èŒƒåŒ–å¹¶é€å…¥é˜Ÿåˆ—
                        _push_converted_pcm(net_chunk, is_final=False)

                    if chunk_count % 10 == 0:
                        print(f"   ğŸ“¦ å·²é€å…¥ {chunk_count} ä¸ªæ•°æ®å—ï¼Œç´¯è®¡ {total_bytes} å­—èŠ‚")

                # å‘é€ç»“æŸï¼ˆè§„èŒƒåŒ–å‰©ä½™å¹¶å‘æœ€ç»ˆæ ‡è®°ï¼‰
                _push_converted_pcm(b'', is_final=True)
                print(f"âœ… å·²é€å—å°†æŸ³å¶PCMäº¤ç»™ç»Ÿä¸€é˜Ÿåˆ—ï¼ˆè®¾å¤‡ä¼˜å…ˆï¼‰ï¼Œæ€»è®¡ {total_bytes} å­—èŠ‚")

                # ä»ä¿å­˜ç©ºæ–‡ä»¶å ä½ç”¨äºè°ƒè¯•ï¼ˆä¸å½±å“æ’­æ”¾ï¼‰
                try:
                    with open(output_path, 'wb') as f:
                        f.write(b'')
                except Exception:
                    pass

            file_size = (output_path.stat().st_size if output_path.exists() else 0)
            if file_size:
                print(f"ğŸ“ æ–‡ä»¶å·²ä¿å­˜: {output_path.name} ({file_size} å­—èŠ‚)")
            return str(output_path)

        else:
            print(f"âŒ æµå¼ç”Ÿæˆå¤±è´¥: {response.status_code}")
            print(f"   é”™è¯¯ä¿¡æ¯: {response.text}")
            return None

    except Exception as e:
        print(f"âŒ æµå¼ç”Ÿæˆå¼‚å¸¸: {e}")
        return None

# æ—§çš„æœ‰é—®é¢˜çš„æ’­æ”¾å‡½æ•°å·²åˆ é™¤ï¼Œä½¿ç”¨ä¿®å¤åçš„æµå¼æ’­æ”¾

def generate_liuye_voice(text, output_filename=None):
    """
    ç”ŸæˆæŸ³å¶çš„è¯­éŸ³ï¼ˆéæµå¼ç‰ˆæœ¬ï¼Œä¿æŒå…¼å®¹æ€§ï¼‰

    Args:
        text (str): è¦è½¬æ¢çš„æ–‡æœ¬
        output_filename (str): è¾“å‡ºæ–‡ä»¶åï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ

    Returns:
        str: ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
    """
    session = clear_proxies()

    # é…ç½®ä¿¡æ¯
    api_key = LIUYE_API_KEY
    voice_uri = LIUYE_VOICE_URI

    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
    output_dir = Path("E:/liusisi/SmartSisi/evoliu/liuye_decision_center/data/æŸ³å¶è¯­éŸ³æ–‡ä»¶")
    output_dir.mkdir(parents=True, exist_ok=True)

    # ç”Ÿæˆæ–‡ä»¶å
    if output_filename is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_filename = f"liuye_voice_{timestamp}.wav"

    output_path = output_dir / output_filename

    url = "https://api.siliconflow.cn/v1/audio/speech"
    headers = {"Authorization": f"Bearer {api_key}"}

    payload = {
        "model": "FunAudioLLM/CosyVoice2-0.5B",
        "input": text,
        "voice": voice_uri,
        "response_format": "wav",
        "sample_rate": 16000,
        "gain": -2
    }

    print(f"ğŸ”Š æ­£åœ¨ç”ŸæˆæŸ³å¶è¯­éŸ³...")
    print(f"ğŸ“ æ–‡æœ¬: {text}")
    print(f"ğŸ“ è¾“å‡º: {output_path}")

    try:
        response = session.post(url, headers=headers, json=payload, timeout=60)

        if response.status_code == 200:
            with open(output_path, 'wb') as f:
                f.write(response.content)

            file_size = output_path.stat().st_size
            print(f"âœ… æŸ³å¶è¯­éŸ³ç”ŸæˆæˆåŠŸ!")
            print(f"   æ–‡ä»¶: {output_path}")
            print(f"   å¤§å°: {file_size} å­—èŠ‚")
            print(f"   é‡‡æ ·ç‡: 24000Hz")
            print(f"   éŸ³é‡: -2dB (è°ƒä½20%)")

            return str(output_path)
        else:
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {response.status_code}")
            print(f"   é”™è¯¯ä¿¡æ¯: {response.text}")
            return None

    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¼‚å¸¸: {e}")
        return None

def test_streaming_tts():
    """æµ‹è¯•æµå¼TTS"""
    print("ğŸµ æŸ³å¶æµå¼TTSæµ‹è¯•")
    print("=" * 60)

    # æµ‹è¯•æ–‡æœ¬
    test_texts = [
        "å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯æŸ³å¶ï¼è¿™æ˜¯æµå¼è¯­éŸ³åˆæˆæµ‹è¯•ã€‚",
        "æµå¼TTSå¯ä»¥è¾¹ç”Ÿæˆè¾¹æ’­æ”¾ï¼Œå¤§å¤§å‡å°‘äº†ç­‰å¾…æ—¶é—´ã€‚",
        "æˆ‘çš„æ„ä¸­äººæ˜¯ä¸ªç›–ä¸–è‹±é›„ï¼Œæœ‰ä¸€å¤©ï¼Œä»–ä¼šè¸©ç€ä¸ƒå½©ç¥¥äº‘æ¥å¨¶æˆ‘ã€‚"
    ]

    success_count = 0
    generated_files = []

    for i, text in enumerate(test_texts, 1):
        print(f"\nğŸµ æµå¼æµ‹è¯• {i}/3")
        result = generate_liuye_voice_streaming(
            text,
            f"stream_test_{i}.wav",
            play_realtime=True
        )

        if result:
            success_count += 1
            generated_files.append(result)

        # é—´éš”3ç§’
        time.sleep(3)

    # ç»“æœæ€»ç»“
    print(f"\n" + "=" * 60)
    print(f"ğŸ‰ æµå¼TTSæµ‹è¯•å®Œæˆ!")
    print(f"ğŸ“Š æˆåŠŸ: {success_count}/3")

    if generated_files:
        print(f"\nğŸµ ç”Ÿæˆçš„æµå¼æ–‡ä»¶:")
        for file_path in generated_files:
            print(f"   - {file_path}")

        print(f"\nğŸ“ æ–‡ä»¶ä½ç½®:")
        print(f"   E:/liusisi/SmartSisi/evoliu/liuye_decision_center/data/æŸ³å¶è¯­éŸ³æ–‡ä»¶/")

        print(f"\nâš™ï¸ æµå¼éŸ³é¢‘å‚æ•°:")
        print(f"   - é‡‡æ ·ç‡: 24000Hz")
        print(f"   - éŸ³é‡: -2dB (è°ƒä½20%)")
        print(f"   - æ ¼å¼: WAV")
        print(f"   - æµå¼ä¼ è¾“: æ˜¯")
        print(f"   - å®æ—¶æ’­æ”¾: {'æ˜¯' if PYGAME_AVAILABLE else 'å¦ (éœ€è¦pygame)'}")

    return success_count > 0

def test_liuye_voice():
    """æµ‹è¯•æŸ³å¶è¯­éŸ³ç”Ÿæˆï¼ˆéæµå¼ï¼‰"""
    print("ğŸ¤ æŸ³å¶å£°éŸ³TTSæµ‹è¯•ï¼ˆéæµå¼ï¼‰")
    print("=" * 50)

    # æµ‹è¯•æ–‡æœ¬
    test_texts = [
        "å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯æŸ³å¶ï¼è¿™æ˜¯æˆ‘çš„è¯­éŸ³å…‹éš†ç³»ç»Ÿã€‚",
        "ç°åœ¨çš„éŸ³è´¨æ€ä¹ˆæ ·ï¼Ÿå¬èµ·æ¥è‡ªç„¶å—ï¼Ÿ"
    ]

    success_count = 0
    generated_files = []

    for i, text in enumerate(test_texts, 1):
        print(f"\nğŸ”Š æµ‹è¯• {i}/2")
        result = generate_liuye_voice(text, f"normal_test_{i}.wav")

        if result:
            success_count += 1
            generated_files.append(result)

        # é—´éš”2ç§’
        time.sleep(2)

    # ç»“æœæ€»ç»“
    print(f"\n" + "=" * 50)
    print(f"ğŸ‰ æŸ³å¶è¯­éŸ³æµ‹è¯•å®Œæˆ!")
    print(f"ğŸ“Š æˆåŠŸ: {success_count}/2")

    if generated_files:
        print(f"\nğŸµ ç”Ÿæˆçš„æ–‡ä»¶:")
        for file_path in generated_files:
            print(f"   - {file_path}")

        print(f"\nğŸ“ æ–‡ä»¶ä½ç½®:")
        print(f"   E:/liusisi/SmartSisi/evoliu/liuye_decision_center/data/æŸ³å¶è¯­éŸ³æ–‡ä»¶/")

        print(f"\nâš™ï¸ éŸ³é¢‘å‚æ•°:")
        print(f"   - é‡‡æ ·ç‡: 24000Hz")
        print(f"   - éŸ³é‡: -2dB (è°ƒä½20%)")
        print(f"   - æ ¼å¼: WAV")

    return success_count > 0

def test_optimized_streaming():
    """æµ‹è¯•æœ€å¤§åŒ–æµå¼ä¼˜åŠ¿"""
    print("ğŸš€ æœ€å¤§åŒ–SiliconFlowæµå¼ä¼˜åŠ¿æµ‹è¯•")
    print("=" * 70)

    # æµ‹è¯•æ–‡æœ¬ - åŒ…å«å¤šä¸ªå¥å­
    test_texts = [
        "å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯æŸ³å¶ï¼ä»Šå¤©æˆ‘ä»¬æ¥æµ‹è¯•æœ€å¤§åŒ–æµå¼ä¼˜åŠ¿çš„è¯­éŸ³åˆæˆã€‚è¿™ä¸ªç³»ç»Ÿå¯ä»¥æ™ºèƒ½åˆ†å¥ï¼Œå¹¶å‘ç”Ÿæˆï¼Œå®æ—¶æ’­æ”¾ã€‚",
        "åºŠå‰æ˜æœˆå…‰ï¼Œç–‘æ˜¯åœ°ä¸Šéœœã€‚ä¸¾å¤´æœ›æ˜æœˆï¼Œä½å¤´æ€æ•…ä¹¡ã€‚è¿™æ˜¯æç™½çš„é™å¤œæ€ï¼Œéå¸¸ç»å…¸çš„å¤è¯—ã€‚",
        "æˆ‘çš„æ„ä¸­äººæ˜¯ä¸ªç›–ä¸–è‹±é›„ï¼Œæœ‰ä¸€å¤©ï¼Œä»–ä¼šè¸©ç€ä¸ƒå½©ç¥¥äº‘æ¥å¨¶æˆ‘ã€‚è¿™å¥è¯æ¥è‡ªå¤§è¯è¥¿æ¸¸ï¼Œå¾ˆæœ‰åã€‚"
    ]

    success_count = 0
    all_generated_files = []

    for i, text in enumerate(test_texts, 1):
        print(f"\nğŸ¯ ä¼˜åŒ–æµ‹è¯• {i}/3")
        print(f"=" * 50)

        start_time = time.time()
        generated_files = generate_liuye_voice_optimized_streaming(
            text,
            play_realtime=True
        )
        end_time = time.time()

        if generated_files:
            success_count += 1
            all_generated_files.extend(generated_files)
            print(f"âœ… æµ‹è¯• {i} æˆåŠŸï¼Œè€—æ—¶ {end_time - start_time:.3f}ç§’")
        else:
            print(f"âŒ æµ‹è¯• {i} å¤±è´¥")

        # æµ‹è¯•é—´éš”
        if i < len(test_texts):
            time.sleep(2)

    # ç»“æœæ€»ç»“
    print(f"\n" + "=" * 70)
    print(f"ğŸ‰ æœ€å¤§åŒ–æµå¼ä¼˜åŠ¿æµ‹è¯•å®Œæˆ!")
    print(f"ğŸ“Š æˆåŠŸ: {success_count}/3")
    print(f"ğŸ“ æ€»æ–‡ä»¶æ•°: {len(all_generated_files)}")

    if all_generated_files:
        print(f"\nğŸµ ç”Ÿæˆçš„ä¼˜åŒ–æ–‡ä»¶:")
        for file_path in all_generated_files:
            print(f"   - {Path(file_path).name}")

        print(f"\nğŸ“ æ–‡ä»¶ä½ç½®:")
        print(f"   E:/liusisi/SmartSisi/evoliu/liuye_decision_center/data/æŸ³å¶è¯­éŸ³æ–‡ä»¶/")

        print(f"\nğŸš€ ä¼˜åŒ–ç­–ç•¥:")
        print(f"   - æ™ºèƒ½åˆ†å¥: æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²")
        print(f"   - å¹¶å‘ç”Ÿæˆ: æ¯å¥ç‹¬ç«‹å¿«é€Ÿåˆæˆ")
        print(f"   - æµå¼ä¼ è¾“: 1KB chunk_size")
        print(f"   - å®æ—¶æ’­æ”¾: è¾¹æ¥æ”¶è¾¹æ’­æ”¾")
        print(f"   - å»¶è¿Ÿä¼˜åŒ–: è·³è¿‡WAVå¤´éƒ¨")

    return success_count > 0

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸµ æŸ³å¶TTSç³»ç»Ÿ - æœ€å¤§åŒ–æµå¼ä¼˜åŠ¿ç‰ˆ")
    print("=" * 70)
    print("1. æœ€å¤§åŒ–æµå¼ä¼˜åŠ¿æµ‹è¯• (æ¨è)")
    print("2. æ™®é€šæµå¼TTSæµ‹è¯•")
    print("3. æ ‡å‡†TTSæµ‹è¯•")
    print("4. å…¨éƒ¨æµ‹è¯•")

    choice = input("\nè¯·é€‰æ‹©æµ‹è¯•æ¨¡å¼ (1/2/3/4): ").strip()

    if choice == "1":
        test_optimized_streaming()
    elif choice == "2":
        test_streaming_tts()
    elif choice == "3":
        test_liuye_voice()
    elif choice == "4":
        print("\nğŸ”„ å¼€å§‹å…¨éƒ¨æµ‹è¯•...")
        test_liuye_voice()
        print("\n" + "="*70)
        test_streaming_tts()
        print("\n" + "="*70)
        test_optimized_streaming()
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œé»˜è®¤è¿è¡Œæœ€å¤§åŒ–æµå¼ä¼˜åŠ¿æµ‹è¯•")
        test_optimized_streaming()

if __name__ == "__main__":
    main()
