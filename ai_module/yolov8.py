import os
import time
import requests
import cv2
import numpy as np
import base64
import threading
import json
from utils import util, config_util as cfg
import random
from core.interact import Interact
from .baidu_api_manager import BaiduAPIManager
from .observation_config import (
    OBSERVATION_TRIGGERS, 
    ATTRIBUTE_MAPPINGS, 
    ATMOSPHERE_CONFIG, 
    PERSON_FEATURES,
    LANGUAGE_STRUCTURE
)
from .templates import DIALOGUE_TEMPLATES, TIME_PERIOD_TEMPLATES, COMMAND_TEMPLATES
from .opening_config import OpeningManager
from core import wsa_server
import math

class YOLOv8:
    """
    äººä½“åˆ†ææ¨¡å— - ä½¿ç”¨ç™¾åº¦äººä½“åˆ†æAPI
    """
    _instance = None
    _instance_lock = threading.Lock()
    
    def __new__(cls):
        with cls._instance_lock:
            if cls._instance is None:
                cls._instance = super(YOLOv8, cls).__new__(cls)
                # åˆå§‹åŒ–å®ä¾‹å±æ€§
                cls._instance.camera_lock = threading.Lock()
                cls._instance.cache_lock = threading.Lock()
                cls._instance.status = False
                cls._instance.last_img = None
                cls._instance.last_detection_time = 0
                cls._instance.cap = None
                cls._instance.api_manager = None
                cls._instance.opening_manager = OpeningManager()
            return cls._instance

    def __init__(self):
        """åˆå§‹åŒ–"""
        from core import wsa_server
        try:
            util.log(1, "[åˆå§‹åŒ–] ğŸ‘ï¸ å¼€å§‹åˆå§‹åŒ–LIUSISIçš„EYES... ğŸ‘ï¸")
            
            # å¯¼å…¥é…ç½®(ç¡®ä¿åœ¨ä½¿ç”¨å‰å¯¼å…¥)
            from ai_module.observation_config import ATTRIBUTE_MAPPINGS
            from ai_module.templates import DIALOGUE_TEMPLATES
            
            # è®¾ç½®ç±»å±æ€§
            self.ATTRIBUTE_MAPPINGS = ATTRIBUTE_MAPPINGS
            self.DIALOGUE_TEMPLATES = DIALOGUE_TEMPLATES
            
            # æ·»åŠ æ‰‹åŠ¿æ˜ å°„
            self.ATTRIBUTE_MAPPINGS["gesture"] = {
                "wave": "æŒ¥æ‰‹",
                "point": "æŒ‡ç‚¹",
                "pray": "ç¥ˆç¥·",
                "hold": "æŒç‰©",
                "clap": "é¼“æŒ",
                "unknown": "æœªçŸ¥æ‰‹åŠ¿"
            }
            
            # åˆå§‹åŒ–é”å’ŒçŠ¶æ€
            self.camera_lock = threading.Lock()
            self.cache_lock = threading.Lock()
            self.status = False
            self.last_img = None
            self.last_detection_time = 0
            self.cap = None
            
            # åˆå§‹åŒ–APIç®¡ç†å™¨å’Œå¼€åœºç™½ç®¡ç†å™¨
            self.api_manager = BaiduAPIManager.get_instance()
            self.opening_manager = OpeningManager()
            
            # æ·»åŠ APIé”
            self.api_lock = threading.Lock()
            self.access_token = None
            self.last_token_time = 0
            self.context_memory = {}
            self.last_observation = None
            self.last_features = None
            self.cache = {}
            self._last_camera_time = 0
            
            # æ·»åŠ å‘½ä»¤å¤„ç†é”å’Œå‘½ä»¤å†å²è®°å½•
            self.command_lock = threading.Lock()
            self.last_command_type = None
            self.last_command_time = 0
            self.command_cooldown = 5.0  # å‘½ä»¤å†·å´æ—¶é—´ï¼Œ5ç§’å†…ä¸é‡å¤å¤„ç†ç›¸åŒå‘½ä»¤
            
            util.log(1, "[åˆå§‹åŒ–] âœ¨ LIUSISIçš„EYESåˆå§‹åŒ–æˆåŠŸ âœ¨")
            
        except Exception as e:
            util.log(1, f"[é”™è¯¯] YOLOv8åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise

    @classmethod
    def new_instance(cls):
        """è·å–YOLOv8å•ä¾‹"""
        instance = cls()
        instance.status = True  # è®¾ç½®åˆå§‹çŠ¶æ€ä¸ºå¯ç”¨
        return instance

    def get_status(self):
        """è·å–çŠ¶æ€"""
        with self.camera_lock:
            return self.status and self.cap is not None and self.cap.isOpened()

    def initialize(self):
        """åˆå§‹åŒ–æ‘„åƒå¤´å’ŒAPIæœåŠ¡"""
        with self.camera_lock:
            try:
                # å¦‚æœçŠ¶æ€è¢«ç¦ç”¨ï¼Œç›´æ¥è¿”å› False
                if not self.status:
                    return False
                    
                util.log(1, "ğŸ‘ï¸ å¼€å§‹åˆå§‹åŒ–LIUSISIçš„EYES... ğŸ‘ï¸")
                
                # æ£€æŸ¥APIé…ç½®
                cfg.load_config()
                if not cfg.baidu_body_app_id or not cfg.baidu_body_api_key or not cfg.baidu_body_secret_key:
                    util.log(1, "[x] ç™¾åº¦äººä½“åˆ†æAPIé…ç½®ç¼ºå¤±ï¼Œè¯·æ£€æŸ¥system.conf")
                    return False
                util.log(1, "APIé…ç½®éªŒè¯é€šè¿‡")
                    
                # åˆå§‹åŒ–æ‘„åƒå¤´
                util.log(1, "æ­£åœ¨åˆå§‹åŒ–æ‘„åƒå¤´...")
                if self.cap is not None and self.cap.isOpened():
                    util.log(1, "å…³é—­å·²å­˜åœ¨çš„æ‘„åƒå¤´è¿æ¥")
                    self.cap.release()
                    self.cap = None
                
                # å°è¯•ä¸åŒçš„æ‘„åƒå¤´åˆå§‹åŒ–æ–¹å¼
                backends = [
                    (cv2.CAP_DSHOW, "DirectShow"),
                    (0, "é»˜è®¤"),
                    (cv2.CAP_MSMF, "Media Foundation"),
                    (cv2.CAP_ANY, "è‡ªåŠ¨é€‰æ‹©")
                ]
                
                success = False
                for backend, backend_name in backends:
                    util.log(1, f"å°è¯•ä½¿ç”¨ {backend_name} åç«¯æ‰“å¼€æ‘„åƒå¤´...")
                    if self._try_camera_backend(backend, backend_name):
                        success = True
                        break
                
                if not success or not self.cap or not self.cap.isOpened():
                    util.log(1, "[x] æ‰€æœ‰åç«¯éƒ½æ— æ³•æ‰“å¼€æ‘„åƒå¤´ï¼Œè¯·æ£€æŸ¥:")
                    util.log(1, "1. æ‘„åƒå¤´æ˜¯å¦æ­£ç¡®è¿æ¥")
                    util.log(1, "2. æ‘„åƒå¤´IDæ˜¯å¦æ­£ç¡®")
                    util.log(1, "3. å…¶ä»–ç¨‹åºæ˜¯å¦å ç”¨æ‘„åƒå¤´")
                    return False
                
                # éªŒè¯API access token
                util.log(1, "æ­£åœ¨éªŒè¯ç™¾åº¦API access token...")
                if not self.api_manager.get_access_token():
                    util.log(1, "[x] éªŒè¯ç™¾åº¦APIå¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥é…ç½®")
                    self.close()
                    return False
                
                util.log(1, "ç™¾åº¦APIéªŒè¯æˆåŠŸ")
                self.status = True
                util.log(1, "âœ¨ LIUSISIçš„EYESåˆå§‹åŒ–å®Œæˆ âœ¨")
                return True
                
            except Exception as e:
                util.log(1, f"[x] åˆå§‹åŒ–è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {str(e)}")
                import traceback
                util.log(1, traceback.format_exc())
                self.close()
                self.status = False
                return False

    def close(self):
        """å…³é—­æ‘„åƒå¤´å’Œæ¸…ç†èµ„æº"""
        with self.camera_lock:
            try:
                if hasattr(self, 'cap') and self.cap is not None:
                    self.cap.release()
                    self.cap = None
                    self.status = False  # æ›´æ–°çŠ¶æ€
                    util.log(1, "æ‘„åƒå¤´å·²å…³é—­")
            except Exception as e:
                util.log(1, f"å…³é—­æ‘„åƒå¤´æ—¶å‡ºé”™: {str(e)}")
            finally:
                self.status = False  # ç¡®ä¿çŠ¶æ€è¢«æ›´æ–°

    def _map_attribute(self, category, value):
        """æ˜ å°„å±æ€§å€¼åˆ°ä¸­æ–‡æè¿°"""
        if not value:
            return self.ATTRIBUTE_MAPPINGS[category].get("unknown")
        return self.ATTRIBUTE_MAPPINGS[category].get(value.lower(), value)

    def _extract_attributes(self, person):
        """æå–äººç‰©å±æ€§"""
        if not person:
            return None
        
        try:
            attrs = person.get("attributes", {})
            if not attrs:
                return None
            
            # åŸºæœ¬å±æ€§
            basic_attrs = {
                "gender": attrs.get("gender", {}).get("name", "æœªçŸ¥"),
                "age": attrs.get("age", {}).get("name", "æœªçŸ¥"),
                "face_mask": attrs.get("face_mask", {}).get("name", "no") == "yes",
                "glasses": attrs.get("glasses", {}).get("name", "no") == "yes",
                "hat": attrs.get("headwear", {}).get("name", "no") == "yes",
                "bag": attrs.get("bag", {}).get("name", "no") == "yes",
                "smoking": attrs.get("smoke", {}).get("name", "no") == "yes",  # æŠ½çƒŸ
                "calling": attrs.get("cellphone", {}).get("name", "no") == "yes"  # æ‰‹æœºä½¿ç”¨
            }
            
            # ä¸Šè¡£å±æ€§
            upper_wear = {
                "type": attrs.get("upper_wear", {}).get("name", "æœªçŸ¥"),
                "color": attrs.get("upper_color", {}).get("name", "æœªçŸ¥"),
                "texture": attrs.get("upper_wear_texture", {}).get("name", "æœªçŸ¥"),
                "sleeve_length": attrs.get("upper_wear_sleeve_length", {}).get("name", "æœªçŸ¥")
            }
            
            # ä¸‹è£…å±æ€§
            lower_wear = {
                "type": attrs.get("lower_wear", {}).get("name", "æœªçŸ¥"),
                "color": attrs.get("lower_color", {}).get("name", "æœªçŸ¥"),
                "length": attrs.get("lower_wear_length", {}).get("name", "æœªçŸ¥")
            }
            
            # é‹å­å±æ€§
            shoes = {
                "type": attrs.get("shoes", {}).get("name", "æœªçŸ¥"),
                "color": attrs.get("shoes_color", {}).get("name", "æœªçŸ¥")
            }
            
            # è¡Œä¸ºå±æ€§
            behaviors = {
                "smoking": attrs.get("smoke", {}).get("name", "no") == "yes",
                "calling": attrs.get("cellphone", {}).get("name", "no") == "yes",
                "carrying": attrs.get("carrying_item", {}).get("name", "no") == "yes",
                "umbrella": attrs.get("umbrella", {}).get("name", "no") == "yes"
            }
            
            # å§¿æ€å±æ€§
            pose = {
                "orientation": attrs.get("orientation", {}).get("name", "æœªçŸ¥"),
                "standing": attrs.get("is_standing", {}).get("name", "no") == "yes",
                "sitting": attrs.get("is_sitting", {}).get("name", "no") == "yes",
                "lying": attrs.get("is_lying", {}).get("name", "no") == "yes"
            }
            
            # å¤´å‘å±æ€§
            hair = {
                "length": attrs.get("hair_length", {}).get("name", "æœªçŸ¥"),
                "style": attrs.get("hair_style", {}).get("name", "æœªçŸ¥"),
                "color": attrs.get("hair_color", {}).get("name", "æœªçŸ¥")
            }
            
            # ç»„åˆæ‰€æœ‰å±æ€§
            return {
                "basic": basic_attrs,
                "upper_wear": upper_wear,
                "lower_wear": lower_wear,
                "shoes": shoes,
                "behaviors": behaviors,
                "pose": pose,
                "hair": hair,
                "distance": "unknown"
            }
            
        except Exception as e:
            util.log(1, f"å±æ€§æå–å¤±è´¥: {str(e)}")
            return None

    def _extract_gestures(self, gesture_result):
        """æå–æ‰‹åŠ¿ä¿¡æ¯"""
        gestures = []
        if "result" in gesture_result:
            for gesture in gesture_result["result"]:
                if isinstance(gesture, dict):
                    gesture_type = gesture.get("classname", "unknown")
                    gestures.append({
                        "type": self._map_attribute("gesture", gesture_type),
                        "probability": gesture.get("probability", 0)
                    })
        return gestures

    def _extract_keypoints(self, keypoint_result):
        """æå–å…³é”®ç‚¹ä¿¡æ¯"""
        keypoints = {}
        if "body_parts" in keypoint_result:
            for part_name, part_info in keypoint_result["body_parts"].items():
                if isinstance(part_info, dict):
                    keypoints[part_name] = {
                        "x": float(part_info.get("x", 0)),
                        "y": float(part_info.get("y", 0)),
                        "score": float(part_info.get("score", 0))
                    }
        return keypoints

    def _analyze_actions(self, body_parts):
        """åˆ†æäººç‰©åŠ¨ä½œ"""
        try:
            actions = []
            
            if not body_parts:
                return actions
            
            # åˆ†æç«™/åå§¿æ€
            hip = body_parts.get("hip", {})
            knee = body_parts.get("right_knee", {}) or body_parts.get("left_knee", {})
            if hip and knee:
                hip_y = float(hip.get("y", 0))
                knee_y = float(knee.get("y", 0))
                if abs(hip_y - knee_y) < 50:
                    actions.append("sitting")
                else:
                    actions.append("standing")
            
            # åˆ†ææ‰‹éƒ¨åŠ¨ä½œ
            if self._is_using_phone(body_parts):
                actions.append("using_phone")
            if self._is_waving(body_parts):
                actions.append("waving")
            if self._is_pointing(body_parts):
                actions.append("pointing")
            if self._is_praying(body_parts):
                actions.append("praying")
            
            # å¢åŠ æ–°çš„åŠ¨ä½œåˆ†æé€»è¾‘
            if self._is_dancing(body_parts):
                actions.append("dancing")
            if self._is_clapping(body_parts):
                actions.append("clapping")
            if self._is_sitting_crosslegged(body_parts):
                actions.append("sitting_crosslegged")
                
            # åˆ†æè„¸éƒ¨åŠ¨ä½œ
            face_actions = self._analyze_face_actions(body_parts)
            if face_actions:
                actions.extend(face_actions)
            
            return actions
            
        except Exception as e:
            util.log(1, f"åˆ†æåŠ¨ä½œæ—¶å‡ºé”™: {str(e)}")
            return []

    def _analyze_face_actions(self, body_parts):
        """åˆ†æè„¸éƒ¨åŠ¨ä½œ"""
        try:
            face_actions = []
            
            if not body_parts:
                return face_actions
                
            # è·å–å…³é”®ç‚¹
            nose = body_parts.get("nose", {})
            left_eye = body_parts.get("left_eye", {})
            right_eye = body_parts.get("right_eye", {})
            mouth = body_parts.get("mouth", {})
            neck = body_parts.get("neck", {})
            
            # æ£€æµ‹å¤´éƒ¨å§¿æ€
            if nose and neck:
                nose_x = float(nose.get("x", 0))
                nose_y = float(nose.get("y", 0))
                neck_x = float(neck.get("x", 0))
                neck_y = float(neck.get("y", 0))
                
                # å¤´éƒ¨å€¾æ–œ
                if abs(nose_x - neck_x) > 30:
                    face_actions.append("head_tilt")
                
                # ç‚¹å¤´/æŠ¬å¤´
                angle = math.degrees(math.atan2(nose_y - neck_y, nose_x - neck_x))
                if angle > 20:
                    face_actions.append("head_down")
                elif angle < -20:
                    face_actions.append("head_up")
            
            # æ£€æµ‹çœ¼ç›çŠ¶æ€
            if left_eye and right_eye:
                left_score = float(left_eye.get("score", 0))
                right_score = float(right_eye.get("score", 0))
                
                if left_score < 0.3 and right_score < 0.3:
                    face_actions.append("eyes_closed")
                elif left_score > 0.7 and right_score > 0.7:
                    face_actions.append("eyes_open")
            
            # æ£€æµ‹å˜´éƒ¨åŠ¨ä½œ
            if mouth:
                mouth_height = float(mouth.get("height", 0))
                mouth_score = float(mouth.get("score", 0))
                
                if mouth_height > 20 and mouth_score > 0.5:
                    face_actions.append("mouth_open")
                elif mouth_height < 10 and mouth_score > 0.5:
                    face_actions.append("mouth_closed")
            
            return face_actions
            
        except Exception as e:
            util.log(1, f"åˆ†æè„¸éƒ¨åŠ¨ä½œæ—¶å‡ºé”™: {str(e)}")
            return []

    def _is_using_phone(self, body_parts):
        """æ£€æµ‹æ˜¯å¦åœ¨ä½¿ç”¨æ‰‹æœº"""
        try:
            head = body_parts.get("head", {})
            left_hand = body_parts.get("left_hand", {})
            right_hand = body_parts.get("right_hand", {})
            
            if head and (left_hand or right_hand):
                head_y = float(head.get("y", 0))
                left_hand_y = float(left_hand.get("y", 0)) if left_hand else 0
                right_hand_y = float(right_hand.get("y", 0)) if right_hand else 0
                
                return (abs(left_hand_y - head_y) < 100) or (abs(right_hand_y - head_y) < 100)
        except:
            pass
        return False

    def _is_praying(self, body_parts):
        """æ£€æµ‹æ˜¯å¦åœ¨ç¥ˆç¥·/ä½œæ–"""
        try:
            left_hand = body_parts.get("left_hand", {})
            right_hand = body_parts.get("right_hand", {})
            
            if left_hand and right_hand:
                left_x = float(left_hand.get("x", 0))
                right_x = float(right_hand.get("x", 0))
                left_y = float(left_hand.get("y", 0))
                right_y = float(right_hand.get("y", 0))
                return abs(left_x - right_x) < 50 and abs(left_y - right_y) < 50
        except:
            pass
        return False

    def _is_waving(self, body_parts):
        """æ£€æµ‹æ˜¯å¦åœ¨æŒ¥æ‰‹"""
        try:
            left_hand = body_parts.get("left_hand", {})
            right_hand = body_parts.get("right_hand", {})
            left_elbow = body_parts.get("left_elbow", {})
            right_elbow = body_parts.get("right_elbow", {})
            
            def is_hand_above_elbow(hand, elbow):
                if hand and elbow:
                    return float(hand.get("y", 0)) < float(elbow.get("y", 0))
                return False
            
            return is_hand_above_elbow(left_hand, left_elbow) or is_hand_above_elbow(right_hand, right_elbow)
        except:
            pass
        return False

    def _is_pointing(self, body_parts):
        """æ£€æµ‹æ˜¯å¦åœ¨æŒ‡ç‚¹"""
        try:
            left_hand = body_parts.get("left_hand", {})
            right_hand = body_parts.get("right_hand", {})
            left_elbow = body_parts.get("left_elbow", {})
            right_elbow = body_parts.get("right_elbow", {})
            
            def is_hand_extended(hand, elbow):
                if hand and elbow:
                    dx = float(hand.get("x", 0)) - float(elbow.get("x", 0))
                    dy = float(hand.get("y", 0)) - float(elbow.get("y", 0))
                    distance = (dx * dx + dy * dy) ** 0.5
                    return distance > 100
                return False
            
            return is_hand_extended(left_hand, left_elbow) or is_hand_extended(right_hand, right_elbow)
        except:
            pass
        return False

    def _is_clapping(self, body_parts):
        """æ£€æµ‹æ˜¯å¦åœ¨é¼“æŒ"""
        try:
            left_hand = body_parts.get("left_hand", {})
            right_hand = body_parts.get("right_hand", {})
            
            if left_hand and right_hand:
                left_x = float(left_hand.get("x", 0))
                right_x = float(right_hand.get("x", 0))
                left_y = float(left_hand.get("y", 0))
                right_y = float(right_hand.get("y", 0))
                
                # æ£€æŸ¥åŒæ‰‹æ˜¯å¦åœ¨ç›¸è¿‘çš„é«˜åº¦ä¸”è·ç¦»é€‚ä¸­
                height_diff = abs(left_y - right_y)
                width_diff = abs(left_x - right_x)
                
                return height_diff < 50 and width_diff < 100
        except:
            pass
        return False

    def _is_sitting_crosslegged(self, body_parts):
        """æ£€æµ‹æ˜¯å¦ç›˜è…¿è€Œå"""
        try:
            left_knee = body_parts.get("left_knee", {})
            right_knee = body_parts.get("right_knee", {})
            left_ankle = body_parts.get("left_ankle", {})
            right_ankle = body_parts.get("right_ankle", {})
            
            if all([left_knee, right_knee, left_ankle, right_ankle]):
                # æ£€æŸ¥è†ç›–æ˜¯å¦åœ¨åŒä¸€é«˜åº¦
                knee_height_diff = abs(float(left_knee.get("y", 0)) - float(right_knee.get("y", 0)))
                
                # æ£€æŸ¥è„šè¸æ˜¯å¦äº¤å‰
                ankle_x_diff = abs(float(left_ankle.get("x", 0)) - float(right_ankle.get("x", 0)))
                ankle_y_diff = abs(float(left_ankle.get("y", 0)) - float(right_ankle.get("y", 0)))
                
                return knee_height_diff < 30 and ankle_x_diff < 50 and ankle_y_diff < 30
        except:
            pass
        return False

    def _calculate_distance(self, person):
        """è®¡ç®—äººç‰©è·ç¦»"""
        try:
            location = person.get("location", {})
            if location:
                frame_height = 1080  # å‡è®¾æ ‡å‡†é«˜åº¦
                relative_position = (location.get("top", 0) + location.get("height", 0)) / frame_height
                if relative_position > 0.7:
                    return "near"
                elif relative_position > 0.4:
                    return "medium"
                else:
                    return "far"
        except:
            pass
        return "unknown"

    def _analyze_group_relationships(self, persons):
        """åˆ†æç¾¤ä½“å…³ç³»"""
        if len(persons) <= 1:
            return
            
        try:
            # æ›´æ–°ç¾¤ä½“ä¿¡æ¯
            for i, person in enumerate(persons):
                person["attributes"]["group_info"] = f"group_member_{i+1}_of_{len(persons)}"
                
            # åˆ†æäººç‰©ä¹‹é—´çš„è·ç¦»
            for i in range(len(persons)):
                for j in range(i + 1, len(persons)):
                    distance = self._calculate_person_distance(persons[i], persons[j])
                    if distance < 200:  # å‡è®¾é˜ˆå€¼
                        persons[i]["attributes"]["group_info"] += "_close"
                        persons[j]["attributes"]["group_info"] += "_close"
        except Exception as e:
            util.log(1, f"ç¾¤ä½“å…³ç³»åˆ†æå¼‚å¸¸: {str(e)}")

    def _calculate_person_distance(self, person1, person2):
        """è®¡ç®—ä¸¤ä¸ªäººä¹‹é—´çš„è·ç¦»"""
        try:
            loc1 = person1.get("location", {})
            loc2 = person2.get("location", {})
            
            x1 = loc1.get("left", 0) + loc1.get("width", 0) / 2
            y1 = loc1.get("top", 0) + loc1.get("height", 0) / 2
            x2 = loc2.get("left", 0) + loc2.get("width", 0) / 2
            y2 = loc2.get("top", 0) + loc2.get("height", 0) / 2
            
            return ((x1 - x2) ** 2 + (y1 - y2) ** 2) ** 0.5
        except:
            return float('inf')

    def _is_same_person(self, location1, location2, threshold=50):
        """åˆ¤æ–­ä¸¤ä¸ªä½ç½®ä¿¡æ¯æ˜¯å¦å±äºåŒä¸€ä¸ªäºº"""
        try:
            x1, y1 = location1.get("left", 0) + location1.get("width", 0)/2, location1.get("top", 0) + location1.get("height", 0)/2
            x2, y2 = location2.get("left", 0) + location2.get("width", 0)/2, location2.get("top", 0) + location2.get("height", 0)/2
            distance = ((x1 - x2) ** 2 + (y1 - y2) ** 2) ** 0.5
            return distance < threshold
        except:
            return False

    def _generate_observation_summary(self, detection_result):
        """ç”Ÿæˆè§‚å¯Ÿæ€»ç»“"""
        try:
            if not detection_result or not isinstance(detection_result, dict):
                return random.choice(DIALOGUE_TEMPLATES["empty_scene"])
            
            persons = detection_result.get("persons", [])
            person_count = len(persons)
            
            # 1. æ—¶é—´æ°›å›´
            time_period = detection_result.get("time_period", self._get_time_period())
            description_parts = [random.choice(ATMOSPHERE_CONFIG["time_mood"][time_period])]
            
            # 2. äººæ•°æè¿°
            if person_count == 0:
                return random.choice(ATMOSPHERE_CONFIG["person_count"][0])
            
            count_desc = ATMOSPHERE_CONFIG["person_count"].get(
                person_count if person_count <= 2 else "many"
            )[0]
            description_parts.append(count_desc)
            
            # 3. äººç‰©æè¿°
            for person in persons:
                description_parts.append(self._generate_single_person_description(person))
            
            # 4. åœºæ™¯æ°›å›´
            mood = detection_result.get("atmosphere", "peaceful")
            description_parts.append(random.choice(ATMOSPHERE_CONFIG["scene_mood"][mood]))
            
            return "ï¼Œ".join(description_parts) + "ã€‚"
            
        except Exception as e:
            util.log(1, f"[x] ç”Ÿæˆè§‚å¯Ÿæ€»ç»“å¤±è´¥: {str(e)}")
            return "æœ¬åº§çœ‹åˆ°äº†ä¸€äº›äººå½±ï¼Œä½†å…·ä½“æƒ…å†µä¸å¤ªæ¸…æ¥š..."

    def _update_context_memory(self, time_period, mood, descriptions):
        """æ›´æ–°ä¸Šä¸‹æ–‡è®°å¿†"""
        self._context_memory["last_time"] = time_period
        self._context_memory["last_mood"] = mood
        self._context_memory["last_descriptions"] = descriptions
        
        # é™åˆ¶å†å²è®°å½•é•¿åº¦
        self._emotion_memory.append(mood)
        if len(self._emotion_memory) > self._max_emotion_history:
            self._emotion_memory.pop(0)

    def _analyze_group_dynamics(self, persons):
        """åˆ†æç¾¤ä½“åŠ¨æ€å…³ç³»"""
        relationships = []
        
        if len(persons) > 1:
            for i, person1 in enumerate(persons):
                for j, person2 in enumerate(persons[i+1:], i+1):
                    relation = self._infer_relationship(person1, person2)
                    if relation:
                        relationships.append(relation)
        
        return relationships

    def _infer_relationship(self, person1, person2):
        """æ¨æµ‹ä¸¤äººå…³ç³»"""
        try:
            distance = self._calculate_distance_between_persons(person1, person2)
            interaction = self._detect_interaction(person1, person2)
            
            # æ ¹æ®è·ç¦»å’Œäº’åŠ¨æ¨æµ‹å…³ç³»
            if distance < 0.5 and interaction.get("type") == "conversation":
                return {
                    "type": "äº²å¯†",
                    "description": random.choice([
                        "çœ‹è¿™äº²å¯†æ— é—´çš„æ¨¡æ ·ï¼Œæƒ³å¿…å…³ç³»åŒªæµ…",
                        "ä¸¤äººä¸¾æ­¢äº²å¯†ï¼Œä¼¼æ˜¯æŒšå‹æˆ–äº²çœ·",
                        "è¿™èˆ¬é»˜å¥‘ï¼Œå®šæ˜¯å¸¸å¹´ç›¸è¯†"
                    ])
                }
            elif distance < 1.0 and interaction.get("type") == "cooperation":
                return {
                    "type": "åŒä¼´",
                    "description": random.choice([
                        "çœ‹è¿™é»˜å¥‘é…åˆï¼Œåº”æ˜¯åŒäº‹æˆ–ä¼™ä¼´",
                        "ä¸¤äººä¸¾æ­¢æŠ•å¥‘ï¼Œæƒ³å¿…æ˜¯å…±äº‹ä¹‹äºº",
                        "è¿™èˆ¬åä½œï¼Œå®šæ˜¯è€æ­æ¡£äº†"
                    ])
                }
            
            return None
        except Exception as e:
            util.log(1, f"æ¨æµ‹å…³ç³»æ—¶å‡ºé”™: {str(e)}")
            return None

    def _generate_mood_transition(self, current_mood, previous_mood):
        """ç”Ÿæˆæƒ…æ„Ÿè¿‡æ¸¡æè¿°"""
        if not previous_mood or current_mood == previous_mood:
            return ""
        
        transitions = {
            ("å¹³é™", "çƒ­é—¹"): [
                "åŸæœ¬å¹³é™çš„æ°”æ°›æ¸æ¸çƒ­ç»œèµ·æ¥",
                "å¯‚é™è¢«æ‰“ç ´ï¼Œçƒ­é—¹çš„æ°”æ¯æ¶ŒåŠ¨è€Œæ¥",
                "é™è°§çš„ç©ºé—´å¼€å§‹çƒ­é—¹èµ·æ¥"
            ],
            ("çƒ­é—¹", "å¹³é™"): [
                "å–§åš£æ¸æ¸å¹³æ¯ï¼Œæ¢å¤äº†å®é™",
                "çƒ­é—¹çš„æ°›å›´æ…¢æ…¢æ²‰æ·€ä¸‹æ¥",
                "ç¹åæ•£å»ï¼Œç•™ä¸‹ä¸€ç‰‡é™è°§"
            ],
            ("ä¸“æ³¨", "æ”¾æ¾"): [
                "ç´§ç»·çš„æ°”æ°›æ¸æ¸èˆ’ç¼“",
                "å‡é‡çš„ç¥è‰²å¼€å§‹èˆ’å±•",
                "ä¸“æ³¨çš„ç¥æƒ…é€æ¸è½»æ¾"
            ]
        }
        
        key = (previous_mood, current_mood)
        return random.choice(transitions.get(key, ["æ°”æ°›æ¸æ¸è½¬å˜"]))

    def _generate_description(self, attrs):
        """æ ¹æ®å±æ€§ç”Ÿæˆæè¿°"""
        try:
            desc_elements = []
            
            # 1. åŸºç¡€èº«ä»½æè¿°
            gender = attrs.get("gender", "unknown")
            age = attrs.get("age", "unknown")
            if gender != "unknown" and gender in DIALOGUE_TEMPLATES["api_feature_mapping"]["gender"]:
                desc_elements.append(random.choice(DIALOGUE_TEMPLATES["api_feature_mapping"]["gender"][gender]))
            if age != "unknown" and age in DIALOGUE_TEMPLATES["api_feature_mapping"]["age"]:
                desc_elements.append(random.choice(DIALOGUE_TEMPLATES["api_feature_mapping"]["age"][age]))
            
            # 2. æœé¥°æè¿°
            upper_wear = attrs.get("upper_wear", "unknown")
            upper_color = attrs.get("upper_color", "unknown")
            lower_wear = attrs.get("lower_wear", "unknown")
            lower_color = attrs.get("lower_color", "unknown")
            
            if upper_wear != "unknown" and upper_wear in ATTRIBUTE_MAPPINGS["upper_wear"]:
                wear_desc = random.choice(ATTRIBUTE_MAPPINGS["upper_wear"][upper_wear])
                if upper_color != "unknown" and upper_color in ATTRIBUTE_MAPPINGS["upper_color"]:
                    color_desc = random.choice(ATTRIBUTE_MAPPINGS["upper_color"][upper_color])
                    desc_elements.append(f"{color_desc}è‰²{wear_desc}")
                else:
                    desc_elements.append(wear_desc)
                
            if lower_wear != "unknown" and lower_wear in ATTRIBUTE_MAPPINGS["lower_wear"]:
                wear_desc = ATTRIBUTE_MAPPINGS["lower_wear"][lower_wear]
                if lower_color != "unknown" and lower_color in ATTRIBUTE_MAPPINGS["lower_color"]:
                    color_desc = ATTRIBUTE_MAPPINGS["lower_color"][lower_color]
                    desc_elements.append(f"{color_desc}è‰²{wear_desc}")
                else:
                    desc_elements.append(wear_desc)
            
            # ä½¿ç”¨è¿æ¥è¯ç»„åˆæè¿°
            if len(desc_elements) > 1:
                connection = random.choice(LANGUAGE_STRUCTURE["particles"]["connection"])
                return f"{desc_elements[0]}ï¼Œ{connection}{desc_elements[1]}"
            elif desc_elements:
                return desc_elements[0]
            else:
                return None
            
        except Exception as e:
            util.log(1, f"[é”™è¯¯] ç”Ÿæˆäººç‰©æè¿°å¤±è´¥: {str(e)}")
            return None

    def generate_observation_json(self, processed_data):
        """ç”Ÿæˆç»“æ„åŒ–çš„è§‚å¯Ÿæ•°æ®ä¾›LLMä½¿ç”¨"""
        try:
            util.log(1, f"[è§‚å¯Ÿ] å¼€å§‹ç”ŸæˆJSONæ•°æ®, åŸå§‹æ•°æ®: {json.dumps(processed_data, ensure_ascii=False)[:200]}...")
            
            # ç¡®ä¿processed_dataæ˜¯å­—å…¸ç±»å‹
            if not isinstance(processed_data, dict):
                util.log(1, f"[è§‚å¯Ÿ] æ— æ•ˆçš„æ•°æ®ç±»å‹: {type(processed_data)}")
                return None
            
            # è·å–äººæ•°
            persons = processed_data.get("persons", [])
            person_count = len(persons)
            util.log(1, f"[è§‚å¯Ÿ] æ£€æµ‹åˆ° {person_count} ä¸ªäºº")
            
            observation = {
                "scene": {
                    "timestamp": time.strftime("%H:%M:%S"),
                    "person_count": person_count,
                    "crowd_density": "é«˜" if person_count > 5 else "ä¸­" if person_count > 2 else "ä½",
                    "time_period": self._get_time_period(),
                    "is_camera_closing": time.time() - self.last_detection_time >= float(cfg.body_detection_interval) * 0.8
                },
                "persons": [],
                "atmosphere": {
                    "time": self._get_time_period(),
                    "crowd": "çƒ­é—¹" if person_count > 3 else "å®‰é™",
                    "mood": "æ´»è·ƒ" if person_count > 2 else "å¹³é™"
                }
            }
            
            # å¤„ç†æ¯ä¸ªäººçš„æ•°æ®
            for person in persons:
                try:
                    attrs = person.get("attributes", {})
                    person_data = {
                        "identity": {
                            "gender": attrs.get("gender", "unknown"),
                            "age": attrs.get("age", "unknown"),
                            "description": self._generate_description(attrs)
                        },
                        "appearance": {
                            "upper_wear": {
                                "type": attrs.get("upper_wear", {}).get("type", "unknown"),
                                "color": attrs.get("upper_wear", {}).get("color", "unknown")
                            },
                            "lower_wear": {
                                "type": attrs.get("lower_wear", {}).get("type", "unknown"),
                                "color": attrs.get("lower_wear", {}).get("color", "unknown")
                            },
                            "face_mask": attrs.get("face_mask", False)
                        },
                        "behavior": {
                            "orientation": attrs.get("orientation", "unknown"),
                            "actions": person.get("actions", []),
                            "gestures": person.get("gestures", []),
                            "is_using_phone": any(action == "using_phone" for action in person.get("actions", [])),
                            "is_praying": any(action == "praying" for action in person.get("actions", []))
                        },
                        "position": {
                            "distance": self._calculate_distance(person),
                            "location": person.get("location", {})
                        }
                    }
                    observation["persons"].append(person_data)
                    util.log(1, f"[è§‚å¯Ÿ] æˆåŠŸå¤„ç†ç¬¬ {len(observation['persons'])} ä¸ªäººçš„æ•°æ®")
                    
                except Exception as e:
                    util.log(1, f"[è§‚å¯Ÿ] å¤„ç†å•ä¸ªäººç‰©æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                    continue
            
            # æ·»åŠ ç¾¤ä½“åŠ¨æ€åˆ†æ
            if person_count > 1:
                observation["group_dynamics"] = self._analyze_group_dynamics(persons)
                util.log(1, f"[è§‚å¯Ÿ] å·²æ·»åŠ ç¾¤ä½“åŠ¨æ€åˆ†æ")
            
            # æ·»åŠ æƒ…æ„Ÿå»ºè®®
            observation["suggested_emotions"] = self._suggest_emotions(observation)
            util.log(1, f"[è§‚å¯Ÿ] å·²æ·»åŠ æƒ…æ„Ÿå»ºè®®")
            
            # éªŒè¯ç”Ÿæˆçš„JSONæ•°æ®
            try:
                json_str = json.dumps(observation, ensure_ascii=False)
                util.log(1, f"[è§‚å¯Ÿ] æˆåŠŸç”ŸæˆJSONæ•°æ®: {json_str[:200]}...")
                return observation
            except Exception as e:
                util.log(1, f"[è§‚å¯Ÿ] JSONåºåˆ—åŒ–å¤±è´¥: {str(e)}")
                return None
            
        except Exception as e:
            util.log(1, f"[è§‚å¯Ÿ] ç”ŸæˆJSONæ•°æ®æ—¶å‡ºé”™: {str(e)}")
            import traceback
            util.log(1, traceback.format_exc())
            return None

    def _get_time_period(self):
        """è·å–å½“å‰æ—¶é—´æ®µ"""
        hour = int(time.strftime("%H"))
        if 5 <= hour < 8:
            return "é»æ˜"
        elif 8 <= hour < 12:
            return "åˆæ—¶"
        elif 12 <= hour < 18:
            return "é»„æ˜"
        else:
            return "å­å¤œ"

    def _suggest_emotions(self, observation):
        """åŸºäºåœºæ™¯å»ºè®®æƒ…æ„ŸçŠ¶æ€"""
        emotions = []
        
        # åŸºäºäººæ•°å’Œæ°›å›´
        if observation["scene"]["person_count"] == 0:
            emotions.extend(["å¹³é™", "æ€è€ƒ"])
        elif observation["scene"]["person_count"] > 3:
            emotions.extend(["çƒ­é—¹", "æ¬¢å¿«"])
        
        # åŸºäºæ—¶é—´
        time_emotions = {
            "é»æ˜": ["å¸Œæœ›", "æœŸå¾…"],
            "åˆæ—¶": ["æ´»åŠ›", "å¿™ç¢Œ"],
            "é»„æ˜": ["æ„Ÿæ…¨", "æ€€æ—§"],
            "å­å¤œ": ["æ·±æ²‰", "æ€è€ƒ"]
        }
        emotions.extend(time_emotions.get(observation["scene"]["time_period"], []))
        
        # åŸºäºäººç‰©è¡Œä¸º
        for person in observation["persons"]:
            if person["behavior"]["is_using_phone"]:
                emotions.append("ä¸“æ³¨")
            if person["behavior"]["is_praying"]:
                emotions.append("è™”è¯š")
        
        # å¦‚æœæ‘„åƒå¤´å³å°†å…³é—­
        if observation["scene"]["is_camera_closing"]:
            emotions.append("å‘Šåˆ«")
        
        return list(set(emotions))  # å»é‡

    def check_observation_trigger(self, text):
        """æ£€æŸ¥è§‚å¯Ÿè§¦å‘è¯"""
        try:
            text = text.strip().lower()
            best_match = None
            max_weight = -1
            
            # æŒ‰ä¼˜å…ˆçº§é¡ºåºæ£€æŸ¥è§¦å‘è¯
            for trigger_type in OBSERVATION_TRIGGERS["priority_order"]:
                config = OBSERVATION_TRIGGERS[trigger_type]
                
                if trigger_type == "scene_specific":
                    # æ£€æŸ¥åœºæ™¯ç‰¹å®šè§¦å‘è¯
                    for scene_type, scene_config in config.items():
                        if scene_type != "priority":  # è·³è¿‡ä¼˜å…ˆçº§é…ç½®
                            for pattern in scene_config["patterns"]:
                                if pattern in text:
                                    weight = scene_config["weight"] * len(pattern)
                                    if weight > max_weight:
                                        max_weight = weight
                                        best_match = f"scene_{scene_type}"
                else:
                    # æ£€æŸ¥å…¶ä»–ç±»å‹è§¦å‘è¯
                    for pattern in config["patterns"]:
                        if pattern in text:
                            weight = config["weight"] * len(pattern)
                            if weight > max_weight:
                                max_weight = weight
                                best_match = trigger_type
            
            if best_match:
                # æ£€æŸ¥å‘½ä»¤å†·å´æ—¶é—´ï¼Œé˜²æ­¢é‡å¤è§¦å‘
                with self.command_lock:
                    current_time = time.time()
                    if (self.last_command_type == best_match and 
                        current_time - self.last_command_time < self.command_cooldown):
                        util.log(1, f"[ç³»ç»Ÿ] å‘½ä»¤ {best_match} å¤„äºå†·å´ä¸­ï¼Œå¿½ç•¥è¯¥è§¦å‘")
                        return None
                        
                util.log(1, f"[Debug] åŒ¹é…åˆ°è§¦å‘è¯ç±»å‹: {best_match}")
                return best_match
            
            return None
            
        except Exception as e:
            util.log(1, f"[Debug] è§¦å‘è¯æ£€æŸ¥å¤±è´¥: {str(e)}")
            return None

    def process_command(self, command_type):
        """å¤„ç†è§‚å¯Ÿå‘½ä»¤"""
        try:
            # é˜²æ­¢çŸ­æ—¶é—´å†…é‡å¤è§¦å‘ç›¸åŒå‘½ä»¤
            with self.command_lock:
                current_time = time.time()
                if (self.last_command_type == command_type and 
                    current_time - self.last_command_time < self.command_cooldown):
                    util.log(1, f"[ç³»ç»Ÿ] å‘½ä»¤å†·å´ä¸­ï¼Œå¿½ç•¥é‡å¤çš„ {command_type} å‘½ä»¤")
                    return None
                
                # è®°å½•å½“å‰å‘½ä»¤å’Œæ—¶é—´
                self.last_command_type = command_type
                self.last_command_time = current_time
            
            # 1. ç«‹å³å‡†å¤‡å¼€åœºç™½
            opening_line = random.choice(COMMAND_TEMPLATES.get(command_type, COMMAND_TEMPLATES['short_term']))
            opening_interact = Interact("opening", 2, {
                "user": "User",
                "text": opening_line,
                "tone": "lyrical"  # å¼€åœºç™½ä½¿ç”¨æŠ’æƒ…è¯­æ°”
            })

            # 2. ç«‹å³å¼€å§‹TTSåˆæˆå¹¶æ’­æ”¾å¼€åœºç™½
            self.say(opening_interact, opening_line)

            # 3. å¯åŠ¨å¹¶è¡Œåˆå§‹åŒ–çº¿ç¨‹
            init_success = False
            def async_initialize():
                nonlocal init_success
                try:
                    init_success = self.initialize()
                except Exception as e:
                    util.log(1, f"[é”™è¯¯] åˆå§‹åŒ–å¤±è´¥: {str(e)}")
                    init_success = False

            init_thread = threading.Thread(target=async_initialize)
            init_thread.start()

            # 4. ç­‰å¾…å¼€åœºç™½æ’­æ”¾å®Œæˆ - ä½¿ç”¨äº‹ä»¶è€Œä¸æ˜¯æ ‡å¿—ä½
            if hasattr(self, 'play_complete_event'):
                # ä½¿ç”¨æ›´å¯é çš„äº‹ä»¶ç­‰å¾…æœºåˆ¶
                wait_timeout = 10.0  # æœ€é•¿ç­‰å¾…10ç§’
                self.play_complete_event.wait(timeout=wait_timeout)
            else:
                # å…¼å®¹æ—§çš„ç­‰å¾…æœºåˆ¶
                timeout = 0
                max_timeout = 10.0  # ç§’
                while self.speaking and timeout < max_timeout:
                    time.sleep(0.1)
                    timeout += 0.1

            # 5. å¦‚æœæ˜¯åœæ­¢å‘½ä»¤ï¼Œç›´æ¥è¿”å›
            if command_type == "stop":
                with self.camera_lock:
                    if self.cap:
                        self.cap.release()
                        self.cap = None
                    self.status = False
                    util.log(1, "[ç³»ç»Ÿ] æ‘„åƒå¤´å·²å…³é—­")
                    return {
                        "opening": opening_line,
                        "scene": None,
                        "ending": None,
                        "features": None,
                        "is_stop": True
                    }

            # 6. ç­‰å¾…åˆå§‹åŒ–å®Œæˆ
            init_thread.join()
            if not init_success:
                error_scene = "æœ¬åº§å¤©çœ¼å—é˜»ï¼Œæš‚æ—¶çœ‹ä¸çœŸåˆ‡..."
                error_interact = Interact("error", 2, {
                    "user": "User",
                    "text": error_scene,
                    "tone": "gentle"
                })
                self.say(error_interact, error_scene)
                return {
                    "opening": opening_line,
                    "scene": error_scene,
                    "ending": None,
                    "features": None,
                    "is_stop": False
                }

            # 7. è·å–å›¾åƒå’Œåˆ†æç»“æœ
            with self.api_lock:
                frame = self.get_img()
                if frame is None:
                    self.close()
                    error_scene = "æœ¬åº§å¤©çœ¼å—é˜»ï¼Œæš‚æ—¶çœ‹ä¸çœŸåˆ‡..."
                    error_interact = Interact("error", 2, {
                        "user": "User",
                        "text": error_scene,
                        "tone": "gentle"
                    })
                    self.say(error_interact, error_scene)
                    return {
                        "opening": opening_line,
                        "scene": error_scene,
                        "ending": None,
                        "features": None,
                        "is_stop": False
                    }

                # 8. è·å–APIåˆ†æç»“æœå¹¶æ’­æ”¾åœºæ™¯æè¿°
                try:
                    # å‘é€APIè¯·æ±‚
                    api_response = self._extract_features(frame)
                    if not api_response:
                        raise Exception("APIåˆ†æå¤±è´¥")

                    # ç”Ÿæˆåœºæ™¯æè¿°å¹¶æ’­æ”¾
                    scene_description = self._generate_scene_description(api_response)
                    scene_interact = Interact("scene", 2, {
                        "user": "User",
                        "text": scene_description,
                        "tone": "gentle"
                    })
                    self.say(scene_interact, scene_description)

                    # ç­‰å¾…åœºæ™¯æè¿°æ’­æ”¾å®Œæˆ
                    while self.speaking:
                        time.sleep(0.1)

                    # æ ¹æ®äººæ•°é€‰æ‹©ç»“æŸè¯­å¹¶æ’­æ”¾
                    person_count = len(api_response.get("persons", []))
                    ending_type = "çƒ­é—¹" if person_count > 2 else "ç©ºæ—·" if person_count == 0 else "æ™®é€š"
                    ending = random.choice(DIALOGUE_TEMPLATES['scene_endings'][ending_type])
                    ending_interact = Interact("ending", 2, {
                        "user": "User",
                        "text": ending,
                        "tone": "gentle"
                    })
                    self.say(ending_interact, ending)

                    # è®¾ç½®è‡ªåŠ¨å…³é—­
                    def auto_close():
                        try:
                            time.sleep(20)
                            if self.status:
                                util.log(1, "[ç³»ç»Ÿ] è§‚å¯Ÿè¶…æ—¶ï¼Œè‡ªåŠ¨å…³é—­æ‘„åƒå¤´")
                                self.close()
                        except Exception as e:
                            util.log(1, f"[é”™è¯¯] è‡ªåŠ¨å…³é—­å¼‚å¸¸: {str(e)}")

                    close_thread = threading.Thread(target=auto_close, daemon=True)
                    close_thread.start()

                    return {
                        "opening": opening_line,
                        "scene": scene_description,
                        "ending": ending,
                        "features": api_response,
                        "is_stop": False
                    }

                except Exception as e:
                    util.log(1, f"[é”™è¯¯] å¤„ç†è§‚å¯Ÿå‘½ä»¤å¤±è´¥: {str(e)}")
                    error_scene = "æœ¬åº§å¤©çœ¼å—é˜»ï¼Œæš‚æ—¶çœ‹ä¸çœŸåˆ‡..."
                    error_ending = random.choice(DIALOGUE_TEMPLATES['scene_endings']['ç‰¹æ®Š'])
                    error_interact = Interact("error", 2, {
                        "user": "User",
                        "text": error_scene,
                        "tone": "gentle"
                    })
                    self.say(error_interact, error_scene)
                    return {
                        "opening": opening_line,
                        "scene": error_scene,
                        "ending": error_ending,
                        "features": None,
                        "is_stop": False
                    }

        except Exception as e:
            util.log(1, f"[é”™è¯¯] å¤„ç†è§‚å¯Ÿå‘½ä»¤å¤±è´¥: {str(e)}")
            error_scene = "æœ¬åº§å¤©çœ¼å—é˜»ï¼Œæš‚æ—¶çœ‹ä¸çœŸåˆ‡..."
            error_ending = random.choice(DIALOGUE_TEMPLATES['scene_endings']['ç‰¹æ®Š'])
            error_interact = Interact("error", 2, {
                "user": "User",
                "text": error_scene,
                "tone": "gentle"
            })
            self.say(error_interact, error_scene)
            return {
                "opening": opening_line,
                "scene": error_scene,
                "ending": error_ending,
                "features": None,
                "is_stop": False
            }

    def say(self, interact, text):
        """æ’­æ”¾æ–‡æœ¬å¹¶ç®¡ç†çŠ¶æ€"""
        try:
            # 1. çŠ¶æ€æ£€æŸ¥å’Œé”å®š
            with threading.Lock():
                self.speaking = True
                # åˆ›å»ºæ’­æ”¾å®Œæˆäº‹ä»¶
                if not hasattr(self, 'play_complete_event'):
                    self.play_complete_event = threading.Event()
                self.play_complete_event.clear()
            
            # 2. æ ¹æ®äº¤äº’ç±»å‹è®¾ç½®ä¼˜å…ˆçº§
            is_opening = isinstance(interact, Interact) and interact.interact_type == "opening"
            is_scene = isinstance(interact, Interact) and interact.interact_type == "scene"
            
            # 3. å‘é€åˆ°WebSocketï¼ˆç¡®ä¿çº¿ç¨‹å®‰å…¨ï¼‰
            try:
                web_instance = wsa_server.get_web_instance()
                if web_instance and hasattr(web_instance, 'is_connected') and web_instance.is_connected("User"):
                    web_instance.add_cmd({
                        "panelMsg": text,
                        "Username": "User"
                    })
            except Exception as e:
                util.log(1, f"[è­¦å‘Š] WebSocketæ¶ˆæ¯å‘é€å¤±è´¥: {str(e)}")
            
            # 4. è®°å½•åˆ°æ—¥å¿—
            util.log(1, f"[æ’­æ”¾] {text}")

            # 5. ä½¿ç”¨ç«å±±å¼•æ“TTSåˆæˆ
            from tts import get_engine
            sp = get_engine()
            sp.connect()
            
            # è®¾ç½®è¯­æ°”
            style = "lyrical" if is_opening else "gentle"
            
            # åˆæˆéŸ³é¢‘
            try:
                result = sp.to_sample(text, style)
                if result:
                    # æ’­æ”¾éŸ³é¢‘
                    import wave
                    import sounddevice as sd
                    import numpy as np
                    
                    with wave.open(result, 'rb') as wf:
                        frames = wf.readframes(wf.getnframes())
                        audio_data = np.frombuffer(frames, dtype=np.int16)
                        # ä½¿ç”¨å›è°ƒå‡½æ•°æ ‡è®°æ’­æ”¾ç»“æŸ
                        def callback(outdata, frames, time, status):
                            if status:
                                util.log(1, f"[è­¦å‘Š] æ’­æ”¾å›è°ƒçŠ¶æ€: {status}")
                            return None
                        
                        # éé˜»å¡æ’­æ”¾ï¼Œä½†ä½¿ç”¨äº‹ä»¶ç­‰å¾…å®Œæˆ
                        stream = sd.OutputStream(
                            samplerate=wf.getframerate(),
                            channels=wf.getnchannels(),
                            callback=callback,
                            finished_callback=lambda: self.play_complete_event.set()
                        )
                        
                        with stream:
                            sd.play(audio_data, wf.getframerate())
                            # ä½¿ç”¨äº‹ä»¶ç­‰å¾…æ’­æ”¾å®Œæˆ
                            self.play_complete_event.wait(timeout=len(audio_data)/wf.getframerate() + 2.0)  # æ·»åŠ 2ç§’å®‰å…¨é—´éš”
                            sd.wait()  # ç¡®ä¿æ’­æ”¾å®Œæˆ
            except Exception as e:
                util.log(1, f"[é”™è¯¯] TTSåˆæˆæˆ–æ’­æ”¾å¤±è´¥: {str(e)}")
                with threading.Lock():
                    self.speaking = False
                    self.play_complete_event.set()  # è®¾ç½®äº‹ä»¶é¿å…æ­»é”
            
            return text
            
        except Exception as e:
            util.log(1, f"[é”™è¯¯] æ’­æ”¾å¤±è´¥: {str(e)}")
            with threading.Lock():
                self.speaking = False
                if hasattr(self, 'play_complete_event'):
                    self.play_complete_event.set()  # è®¾ç½®äº‹ä»¶é¿å…æ­»é”
            return text
        
        finally:
            # ç¡®ä¿çŠ¶æ€æ­£ç¡®é‡ç½®
            if not is_opening and not is_scene:  # å¼€åœºç™½å’Œåœºæ™¯æè¿°éœ€è¦ä¿æŒspeakingçŠ¶æ€
                with threading.Lock():
                    self.speaking = False
                    if hasattr(self, 'play_complete_event'):
                        self.play_complete_event.set()  # ç¡®ä¿äº‹ä»¶è¢«è®¾ç½®

    def _save_to_cache(self, cache_type, key, value):
        pass

    def _get_from_cache(self, cache_type, key):
        pass

    def _extract_features(self, frame):
        """ä»å›¾åƒä¸­æå–ç‰¹å¾"""
        try:
            # 1. å›¾åƒç¼–ç å’Œé¢„å¤„ç†
            _, img_encoded = cv2.imencode('.jpg', frame)
            if img_encoded is None:
                util.log(1, "[é”™è¯¯] å›¾åƒç¼–ç å¤±è´¥")
                return None
            
            image_base64 = base64.b64encode(img_encoded).decode('utf-8')
            
            # 2. è·å–access token
            if not self.access_token or time.time() - self.last_token_time > 3600:
                self.access_token = self.api_manager.get_access_token()
                if not self.access_token:
                    util.log(1, "[é”™è¯¯] æ— æ³•è·å–API access token")
                    return None
                self.last_token_time = time.time()
            
            # 3. å‡†å¤‡APIè°ƒç”¨
            headers = {'Content-Type': 'application/x-www-form-urlencoded'}
            data = {'image': image_base64}
            max_retries = 3
            retry_delay = 1
            
            # 4. è°ƒç”¨å¤šä¸ªAPIå¹¶åˆå¹¶ç»“æœ
            api_results = {}
            
            # 4.1 äººä½“æ£€æµ‹å’Œå±æ€§è¯†åˆ«
            util.log(1, "[API] å‘é€äººä½“æ£€æµ‹å’Œå±æ€§è¯†åˆ«è¯·æ±‚...")
            url = f"https://aip.baidubce.com/rest/2.0/image-classify/v1/body_attr?access_token={self.access_token}"
            response = self._make_api_call(url, headers, data, max_retries, retry_delay)
            if response:
                api_results["body_attr"] = response
            
            # 4.2 äººä½“å…³é”®ç‚¹è¯†åˆ«
            util.log(1, "[API] å‘é€äººä½“å…³é”®ç‚¹è¯†åˆ«è¯·æ±‚...")
            url = f"https://aip.baidubce.com/rest/2.0/image-classify/v1/body_analysis?access_token={self.access_token}"
            response = self._make_api_call(url, headers, data, max_retries, retry_delay)
            if response:
                api_results["body_analysis"] = response
            
            # 4.3 æ‰‹åŠ¿è¯†åˆ«
            util.log(1, "[API] å‘é€æ‰‹åŠ¿è¯†åˆ«è¯·æ±‚...")
            url = f"https://aip.baidubce.com/rest/2.0/image-classify/v1/gesture?access_token={self.access_token}"
            response = self._make_api_call(url, headers, data, max_retries, retry_delay)
            if response:
                api_results["gesture"] = response
            
            # 4.4 äººæµé‡ç»Ÿè®¡
            util.log(1, "[API] å‘é€äººæµé‡ç»Ÿè®¡è¯·æ±‚...")
            url = f"https://aip.baidubce.com/rest/2.0/image-classify/v1/body_num?access_token={self.access_token}"
            response = self._make_api_call(url, headers, data, max_retries, retry_delay)
            if response:
                api_results["crowd_count"] = response
            
            # 4.5 æ‰‹éƒ¨å…³é”®ç‚¹è¯†åˆ«
            util.log(1, "[API] å‘é€æ‰‹éƒ¨å…³é”®ç‚¹è¯†åˆ«è¯·æ±‚...")
            url = f"https://aip.baidubce.com/rest/2.0/image-classify/v1/hand_analysis?access_token={self.access_token}"
            response = self._make_api_call(url, headers, data, max_retries, retry_delay)
            if response:
                api_results["hand_analysis"] = response

            # 5. å¤„ç†APIç»“æœ
            if not api_results:
                util.log(1, "[é”™è¯¯] æ‰€æœ‰APIè°ƒç”¨å‡å¤±è´¥")
                return None
            
            # 6. åˆå¹¶å¤„ç†ç»“æœ
            persons = []
            
            # 6.1 å¤„ç†äººä½“å±æ€§ç»“æœ
            if "body_attr" in api_results:
                body_attr = api_results["body_attr"]
                for person in body_attr.get("person_info", []):
                    person_data = {
                        "attributes": self._extract_attributes(person),
                        "location": person.get("location", {}),
                        "body_parts": {},
                        "actions": [],
                        "gestures": []
                    }
                    persons.append(person_data)
            
            # 6.2 å¤„ç†äººä½“å…³é”®ç‚¹ç»“æœ
            if "body_analysis" in api_results:
                body_analysis = api_results["body_analysis"]
                for i, person in enumerate(body_analysis.get("person_info", [])):
                    if i < len(persons):
                        persons[i]["body_parts"] = person.get("body_parts", {})
                        persons[i]["actions"].extend(self._analyze_actions(person.get("body_parts", {})))
            
            # 6.3 å¤„ç†æ‰‹åŠ¿è¯†åˆ«ç»“æœ
            if "gesture" in api_results:
                gesture_result = api_results["gesture"]
                for i, person in enumerate(persons):
                    person["gestures"] = self._extract_gestures(gesture_result)
            
            # 6.4 å¤„ç†æ‰‹éƒ¨å…³é”®ç‚¹ç»“æœ
            if "hand_analysis" in api_results:
                hand_result = api_results["hand_analysis"]
                for i, person in enumerate(persons):
                    if i < len(persons):
                        persons[i]["hand_keypoints"] = hand_result.get("hand_info", [])
            
            # 6.5 æ·»åŠ äººæµé‡ä¿¡æ¯
            crowd_info = {
                "total_count": len(persons),
                "density": "é«˜" if len(persons) > 10 else "ä¸­" if len(persons) > 5 else "ä½"
            }
            if "crowd_count" in api_results:
                crowd_result = api_results["crowd_count"]
                crowd_info["detected_count"] = crowd_result.get("person_num", len(persons))
            
            return {
                "persons": persons,
                "crowd_info": crowd_info,
                "timestamp": time.time()
            }
            
        except Exception as e:
            util.log(1, f"[é”™è¯¯] ç‰¹å¾æå–å¤±è´¥: {str(e)}")
            import traceback
            util.log(1, traceback.format_exc())
            return None

    def _make_api_call(self, url, headers, data, max_retries, retry_delay):
        """ç»Ÿä¸€çš„APIè°ƒç”¨æ–¹æ³•"""
        for attempt in range(max_retries):
            try:
                response = requests.post(url, headers=headers, data=data)
                if response.status_code == 200:
                    result = response.json()
                    if "error_code" not in result:
                        return result
                    else:
                        util.log(1, f"[é”™è¯¯] APIè¿”å›é”™è¯¯: {result.get('error_msg', '')}")
            
                if attempt < max_retries - 1:
                    time.sleep(retry_delay)
                
            except Exception as e:
                util.log(1, f"[é”™è¯¯] APIè°ƒç”¨å¼‚å¸¸: {str(e)}")
                if attempt < max_retries - 1:
                    time.sleep(retry_delay)
        
        return None

    def _generate_scene_description(self, features):
        """ç”Ÿæˆåœºæ™¯æè¿°"""
        try:
            if not features or not features.get("persons"):
                return random.choice(DIALOGUE_TEMPLATES["empty_scene"])
            
            desc_parts = []
            current_tone = "gentle"  # é»˜è®¤è¯­æ°”
            
            # 1. æ—¶é—´æ°›å›´
            time_period = self._get_time_period()
            time_config = ATMOSPHERE_CONFIG["time_mood"][time_period]
            time_desc = random.choice(time_config["patterns"])
            current_tone = time_config["tone"]
            desc_parts.append(time_desc)
            
            # 2. äººæ•°æè¿°
            person_count = len(features["persons"])
            count_key = person_count if person_count <= 2 else "many"
            count_config = ATMOSPHERE_CONFIG["person_count"][count_key]
            transition = random.choice(LANGUAGE_STRUCTURE["transitions"]["time_to_count"])
            count_desc = f"{transition}{random.choice(count_config['patterns'])}"
            current_tone = count_config["tone"]
            desc_parts.append(count_desc)
            
            # 3. äººç‰©æè¿°
            for i, person in enumerate(features["persons"]):
                if i > 0:
                    desc_parts.append(random.choice(LANGUAGE_STRUCTURE["transitions"]["count_to_person"]))
                
                person_desc = self._generate_single_person_description(person)
                if person_desc:
                    desc_parts.append(person_desc)
                    
                # æ·»åŠ åŠ¨ä½œæè¿°
                action_desc = self._generate_action_description(person.get("actions", []))
                if action_desc:
                    transition = random.choice(LANGUAGE_STRUCTURE["transitions"]["person_to_action"])
                    desc_parts.append(f"{transition}{action_desc}")
            
            # 4. åœºæ™¯æ°›å›´
            mood = self._analyze_scene_mood(features)
            mood_config = ATMOSPHERE_CONFIG["scene_mood"][mood]
            transition = random.choice(LANGUAGE_STRUCTURE["transitions"]["action_to_mood"])
            mood_desc = f"{transition}{random.choice(mood_config)}"
            desc_parts.append(mood_desc)
            
            # 5. æ·»åŠ ç»“è¯­
            conclusion = random.choice(LANGUAGE_STRUCTURE["particles"]["conclusion"])
            desc_parts.append(conclusion)
            
            # ç»„åˆæè¿°
            description = "ï¼Œ".join(desc_parts) + "ã€‚"
            
            # è®°å½•ä½¿ç”¨çš„è¯­æ°”
            if hasattr(self, '_last_tone'):
                self._last_tone = current_tone
            
            return description
            
        except Exception as e:
            util.log(1, f"[é”™è¯¯] ç”Ÿæˆåœºæ™¯æè¿°å¤±è´¥: {str(e)}")
            return "æœ¬åº§å¤©çœ¼å—é˜»ï¼Œæš‚æ—¶çœ‹ä¸çœŸåˆ‡..."

    def _generate_single_person_description(self, person):
        """ç”Ÿæˆå•äººæè¿°"""
        try:
            desc_parts = []
            
            # 1. è·å–åŸºç¡€å±æ€§
            attrs = person.get("attributes", {})
            gender = attrs.get("gender", "unknown")
            age = attrs.get("age", "unknown")
            
            # 2. ç”Ÿæˆèº«ä»½æè¿°
            if gender != "unknown" and age != "unknown":
                gender_key = "ç”·" if "ç”·" in gender else "å¥³"
                age_key = age.replace("_", "")
                if gender_key in PERSON_FEATURES["identity"] and age_key in PERSON_FEATURES["identity"][gender_key]:
                    identity_config = PERSON_FEATURES["identity"][gender_key][age_key]
                    desc_parts.append(random.choice(identity_config["patterns"]))
            
            # 3. ç”Ÿæˆæœé¥°æè¿°
            upper_wear = attrs.get("upper_wear", "unknown")
            upper_color = attrs.get("upper_color", "unknown")
            
            if upper_wear != "unknown" and upper_color != "unknown":
                if upper_wear in ATTRIBUTE_MAPPINGS["upper_wear"] and upper_color in ATTRIBUTE_MAPPINGS["upper_color"]:
                    wear_desc = random.choice(ATTRIBUTE_MAPPINGS["upper_wear"][upper_wear])
                    color_desc = random.choice(ATTRIBUTE_MAPPINGS["upper_color"][upper_color])
                    desc_parts.append(f"èº«ç€{color_desc}è‰²{wear_desc}")
            
            # 4. ç”Ÿæˆå§¿æ€æè¿°
            actions = person.get("actions", [])
            if "ç«™ç«‹" in actions:
                desc_parts.append("æŒºç«‹è€Œç«‹")
            elif "åç€" in actions:
                desc_parts.append("é™åä¸€æ—")
            
            # ä½¿ç”¨è¿æ¥è¯ç»„åˆæè¿°
            if len(desc_parts) > 1:
                connection = random.choice(LANGUAGE_STRUCTURE["particles"]["connection"])
                return f"{desc_parts[0]}ï¼Œ{connection}{desc_parts[1]}"
            elif desc_parts:
                return desc_parts[0]
            else:
                return None
            
        except Exception as e:
            util.log(1, f"[é”™è¯¯] ç”Ÿæˆäººç‰©æè¿°å¤±è´¥: {str(e)}")
            return None

    def _analyze_scene_mood(self, features):
        """åˆ†æåœºæ™¯æ°›å›´"""
        try:
            # åŸºäºäººæ•°åˆ¤æ–­
            person_count = len(features.get("persons", []))
            if person_count == 0:
                return "peaceful"
            elif person_count > 3:
                return "lively"
                
            # åŸºäºåŠ¨ä½œåˆ¤æ–­
            solemn_actions = ["pray", "meditation", "ceremony"]
            lively_actions = ["talk", "laugh", "play"]
            
            action_count = {"solemn": 0, "lively": 0, "peaceful": 0}
            
            for person in features.get("persons", []):
                for action in person.get("actions", []):
                    if action in solemn_actions:
                        action_count["solemn"] += 1
                    elif action in lively_actions:
                        action_count["lively"] += 1
                    else:
                        action_count["peaceful"] += 1
                        
            # æ ¹æ®åŠ¨ä½œç»Ÿè®¡åˆ¤æ–­æ°›å›´
            max_action = max(action_count.items(), key=lambda x: x[1])[0]
            return max_action
            
        except Exception as e:
            util.log(1, f"[x] åœºæ™¯æ°›å›´åˆ†æå¤±è´¥: {str(e)}")
            return "peaceful"

    def _check_standing_pose(self, body_parts):
        """æ£€æŸ¥æ˜¯å¦ç«™ç«‹"""
        try:
            if not body_parts:
                return False
            
            # æ£€æŸ¥å…³é”®ç‚¹å¾—åˆ†
            key_points = ["nose", "neck", "right_knee", "left_knee"]
            scores = [body_parts.get(point, {}).get("score", 0) for point in key_points]
            
            # å¦‚æœå…³é”®ç‚¹å¾—åˆ†éƒ½è¾ƒé«˜ï¼Œè¯´æ˜å¯èƒ½æ˜¯ç«™ç«‹å§¿åŠ¿
            return all(score > 0.5 for score in scores)
            
        except Exception as e:
            util.log(1, f"[x] å§¿æ€æ£€æŸ¥å¤±è´¥: {str(e)}")
            return False
    
    def _check_sitting_pose(self, body_parts):
        """æ£€æŸ¥æ˜¯å¦åç€"""
        try:
            if not body_parts:
                return False
                
            # æ£€æŸ¥è†ç›–å’Œè‡€éƒ¨çš„ä½ç½®å…³ç³»
            hip_y = body_parts.get("hip", {}).get("y", 0)
            knee_y = body_parts.get("knee", {}).get("y", 0)
            
            # å¦‚æœè†ç›–é«˜äºè‡€éƒ¨ï¼Œå¯èƒ½æ˜¯åå§¿
            return hip_y > 0 and knee_y > 0 and knee_y < hip_y
            
        except Exception as e:
            util.log(1, f"[x] å§¿æ€æ£€æŸ¥å¤±è´¥: {str(e)}")
            return False

    def _try_camera_backend(self, backend, backend_name):
        """å°è¯•ä½¿ç”¨ç‰¹å®šåç«¯æ‰“å¼€æ‘„åƒå¤´"""
        try:
            if backend == 0:
                self.cap = cv2.VideoCapture(0)
            else:
                self.cap = cv2.VideoCapture(0 + backend)
            
            if self.cap is None or not self.cap.isOpened():
                util.log(1, f"[x] {backend_name} åç«¯æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
                return False
            
            # æµ‹è¯•æ˜¯å¦èƒ½è¯»å–å¸§
            ret, frame = self.cap.read()
            if not ret or frame is None:
                util.log(1, f"[x] {backend_name} åç«¯æ— æ³•è¯»å–ç”»é¢")
                if self.cap:
                    self.cap.release()
                    self.cap = None
                return False
            
            # è®¾ç½®æ‘„åƒå¤´å‚æ•°
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
            self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
            
            util.log(1, f"ä½¿ç”¨ {backend_name} åç«¯æˆåŠŸæ‰“å¼€æ‘„åƒå¤´")
            return True
            
        except Exception as e:
            util.log(1, f"ä½¿ç”¨ {backend_name} åç«¯å¤±è´¥: {str(e)}")
            if self.cap:
                self.cap.release()
                self.cap = None
            return False

    def get_img(self):
        """è·å–æ‘„åƒå¤´å›¾åƒ"""
        try:
            with self.camera_lock:
                if not self.cap or not self.cap.isOpened():
                    if not self.initialize():
                        return None
                        
                # æ£€æŸ¥æ—¶é—´é—´éš”
                current_time = time.time()
                if current_time - self.last_detection_time < float(cfg.body_detection_interval):
                    return None
                    
                # è¯»å–å›¾åƒ
                ret, frame = self.cap.read()
                if not ret or frame is None:
                    util.log(1, "[!] æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢")
                    return None
                    
                self.last_detection_time = current_time
                return frame
                
        except Exception as e:
            util.log(1, f"[x] è·å–å›¾åƒå¤±è´¥: {str(e)}")
            return None

    def _generate_action_description(self, actions):
        """ç”ŸæˆåŠ¨ä½œæè¿°"""
        if not actions:
            return None
        
        action_templates = {
            "using_phone": ["æ­£åœ¨çœ‹æ‰‹æœº", "ä½å¤´ç©æ‰‹æœº", "ä¸“æ³¨äºæ‰‹æœº"],
            "waving": ["åœ¨æŒ¥æ‰‹", "æŒ¥èˆç€æ‰‹è‡‚", "æ­£åœ¨æ‰“æ‹›å‘¼"],
            "pointing": ["æŒ‡ç€è¿œæ–¹", "åšå‡ºæŒ‡ç‚¹çš„å§¿åŠ¿", "æ‰‹æŒ‡å‘å‰æ–¹"],
            "praying": ["åŒæ‰‹åˆå", "åšå‡ºç¥ˆç¥·å§¿åŠ¿", "è™”è¯šåœ°ç¥·å‘Š"],
            # æ–°å¢è„¸éƒ¨åŠ¨ä½œæè¿°
            "head_tilt": ["æ­ªç€å¤´", "å¤´å¾®å¾®å€¾æ–œ", "ä¾§ç€å¤´"],
            "head_down": ["ä½ç€å¤´", "å‚é¦–è€Œç«‹", "å¤´å¾®å¾®ä½å‚"],
            "head_up": ["æŠ¬ç€å¤´", "ä»°æœ›è¿œæ–¹", "æ˜‚é¦–è€Œç«‹"],
            "eyes_closed": ["é—­ç€çœ¼ç›", "åŒç›®å¾®é—­", "åˆçœ¼æ²‰æ€"],
            "eyes_open": ["çå¤§çœ¼ç›", "ç›®å…‰ç‚¯ç‚¯", "çœ¼ç¥ä¸“æ³¨"],
            "mouth_open": ["å¼ ç€å˜´", "æ­£åœ¨è¯´è¯", "å£è‹¥æ‚¬æ²³"],
            "mouth_closed": ["æŠ¿ç€å˜´", "é»˜é»˜æ— è¨€", "æ²‰é»˜ä¸è¯­"]
        }
        
        descriptions = []
        for action in actions:
            if action in action_templates:
                descriptions.append(random.choice(action_templates[action]))
            
        if descriptions:
            return "ï¼Œ".join(descriptions)
        return None

    def _generate_gesture_description(self, gestures):
        """ç”Ÿæˆæ‰‹åŠ¿æè¿°"""
        if not gestures:
            return None
        
        gesture_templates = {
            "wave": ["æŒ¥æ‰‹ç¤ºæ„", "å‹å¥½åœ°æŒ¥æ‰‹", "æ‰“ç€æ‹›å‘¼"],
            "point": ["æŒ‡å‘å‰æ–¹", "åšå‡ºæŒ‡å¼•å§¿åŠ¿", "æ‰‹æŒ‡æŸå¤„"],
            "pray": ["åŒæ‰‹åˆå", "ä½œæ–è¡Œç¤¼", "æ­æ•¬åœ°è¡Œç¤¼"],
            "hold": ["æ‰‹æŒç‰©å“", "æ‹¿ç€ä»€ä¹ˆ", "æŒä¸­æœ‰ç‰©"]
        }
        
        descriptions = []
        for gesture in gestures:
            gesture_type = gesture.get("type")
            if gesture_type in gesture_templates:
                descriptions.append(random.choice(gesture_templates[gesture_type]))
            
        if descriptions:
            return "ï¼Œ".join(descriptions)
        return None

    def _check_api_limits(self):
        """æ£€æŸ¥APIè°ƒç”¨é™åˆ¶"""
        with self.api_lock:
            current_time = time.time()
            
            # æ£€æŸ¥è°ƒç”¨é—´éš”
            if current_time - self._api_limits['last_call_time'] < self._api_limits['min_interval']:
                time.sleep(self._api_limits['min_interval'])
            
            # æ£€æŸ¥æ¯æ—¥é™åˆ¶
            today = time.strftime("%Y-%m-%d")
            if today != getattr(self, '_last_check_date', None):
                self._api_limits['calls_today'] = 0
                self._last_check_date = today
                
            if self._api_limits['calls_today'] >= self._api_limits['daily_limit']:
                raise Exception("å·²è¾¾åˆ°æ¯æ—¥APIè°ƒç”¨é™åˆ¶")
            
            # æ›´æ–°è®¡æ•°å™¨
            self._api_limits['last_call_time'] = current_time
            self._api_limits['calls_today'] += 1
            
            return True

    def _save_opening_line(self, command_type, opening_line):
        """ä¿å­˜å¼€åœºç™½åˆ°ç¼“å­˜"""
        with self.cache_lock:
            self._opening_lines_cache[command_type] = opening_line

    def _get_opening_line(self, command_type):
        """ä»ç¼“å­˜è·å–å¼€åœºç™½"""
        with self.cache_lock:
            return self._opening_lines_cache.get(command_type)

    def _is_dancing(self, body_parts):
        """æ£€æµ‹æ˜¯å¦åœ¨è·³èˆ"""
        try:
            left_leg = body_parts.get("left_leg", {})
            right_leg = body_parts.get("right_leg", {})
            left_hand = body_parts.get("left_hand", {})
            right_hand = body_parts.get("right_hand", {})
            
            if left_leg and right_leg and (left_hand or right_hand):
                left_leg_y = float(left_leg.get("y", 0))
                right_leg_y = float(right_leg.get("y", 0))
                left_hand_y = float(left_hand.get("y", 0)) if left_hand else 0
                right_hand_y = float(right_hand.get("y", 0)) if right_hand else 0
                
                # åˆ¤æ–­è…¿éƒ¨å’Œæ‰‹éƒ¨çš„ç›¸å¯¹ä½ç½®
                if abs(left_leg_y - right_leg_y) < 50 and abs(left_hand_y - left_leg_y) < 100:
                    return True
        except:
            pass
        return False
