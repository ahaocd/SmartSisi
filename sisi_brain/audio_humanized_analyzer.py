#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
éŸ³é¢‘äººæ€§åŒ–åˆ†æå™¨
åŠŸèƒ½ï¼š5æ¬¡éŸ³é¢‘ç´¯ç§¯åè¿›è¡Œäººæ€§åŒ–åˆ†ææè¿°
åˆ†æå†…å®¹ï¼šç°åœ¨ä»€ä¹ˆæƒ…å†µã€å¯èƒ½çš„åœ°æ–¹ã€æœ‰ä»€ä¹ˆå£°éŸ³ã€å“ªäº›äººã€å“ªäº›éŸ³ä¹
"""

import json
import time
import logging
from typing import List, Dict, Any, Optional
from dataclasses import dataclass

@dataclass
class AudioAnalysisResult:
    """éŸ³é¢‘åˆ†æç»“æœ"""
    situation_description: str  # æƒ…å†µæè¿°
    location_guess: str        # åœ°ç‚¹çŒœæµ‹
    sound_analysis: List[str]  # å£°éŸ³åˆ†æ
    people_analysis: str       # äººå‘˜åˆ†æ
    music_analysis: str        # éŸ³ä¹åˆ†æ
    confidence: float          # ç½®ä¿¡åº¦
    timestamp: float           # æ—¶é—´æˆ³

class AudioHumanizedAnalyzer:
    """éŸ³é¢‘äººæ€§åŒ–åˆ†æå™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # ğŸ”§ ä½¿ç”¨ç»Ÿä¸€é…ç½®ç³»ç»Ÿ
        try:
            from utils.config_util import load_config
            config = load_config()
            
            self.api_key = config.get('audio_humanized_api_key', '')
            self.base_url = config.get('audio_humanized_base_url', '')
            self.model = config.get('audio_humanized_model', 'Qwen/Qwen3-8B')
            self.temperature = float(config.get('audio_humanized_temperature', '0.6'))
            self.max_tokens = int(config.get('audio_humanized_max_tokens', '2000'))
            
            self.logger.info(f"âœ… éŸ³é¢‘äººæ€§åŒ–åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ - æ¨¡å‹: {self.model}")
            
        except Exception as e:
            self.logger.error(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
            # å¤‡ç”¨é…ç½®
            self.api_key = '910663e20c4a49b286f27009dde10497.qYauy3JahUXDed7C'
            self.base_url = 'https://open.bigmodel.cn/api/paas/v4/'
            self.model = 'GLM-4.5-Flash'
            self.temperature = 0.6
            self.max_tokens = 2000
    
    def analyze_accumulated_audio(self, audio_contexts: List[Dict[str, Any]]) -> AudioAnalysisResult:
        """
        åˆ†æç´¯ç§¯çš„éŸ³é¢‘ä¸Šä¸‹æ–‡

        Args:
            audio_contexts: ç´¯ç§¯çš„3æ¬¡éŸ³é¢‘ä¸Šä¸‹æ–‡æ•°æ®

        Returns:
            AudioAnalysisResult: äººæ€§åŒ–åˆ†æç»“æœ
        """
        try:
            self.logger.info(f"ğŸ§  å¼€å§‹åˆ†æ{len(audio_contexts)}ä¸ªç´¯ç§¯éŸ³é¢‘ä¸Šä¸‹æ–‡")

            # ğŸ¯ ä¸´æ—¶ç»•è¿‡APIè°ƒç”¨ï¼Œç›´æ¥ä½¿ç”¨æ™ºèƒ½å›é€€åˆ†æ
            if not self.api_key or len(self.api_key) < 10:
                self.logger.warning("âš ï¸ APIå¯†é’¥æ— æ•ˆï¼Œç›´æ¥ä½¿ç”¨æ™ºèƒ½å›é€€åˆ†æ")
                fallback_result = self._create_fallback_result(audio_contexts)
                self.logger.info(f"ğŸ›¡ï¸ ä½¿ç”¨æ™ºèƒ½å›é€€ç»“æœ: {fallback_result.situation_description}")
                return fallback_result

            # æ„å»ºåˆ†ææç¤ºè¯
            analysis_prompt = self._build_analysis_prompt(audio_contexts)

            # è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œåˆ†æ
            analysis_result = self._call_llm_analysis(analysis_prompt)

            # è§£æåˆ†æç»“æœ
            parsed_result = self._parse_analysis_result(analysis_result)

            self.logger.info(f"âœ… éŸ³é¢‘äººæ€§åŒ–åˆ†æå®Œæˆ - ç½®ä¿¡åº¦: {parsed_result.confidence:.2f}")
            return parsed_result

        except Exception as e:
            self.logger.error(f"âŒ éŸ³é¢‘äººæ€§åŒ–åˆ†æå¤±è´¥: {e}")
            # ğŸ”§ APIå¤±è´¥æ—¶ï¼Œè¿”å›è¯†åˆ«åˆ°çš„æ•°æ®ï¼Œå»é™¤ç©ºæ•°æ®
            fallback_result = self._create_data_aligned_result(audio_contexts)
            self.logger.info(f"ğŸ›¡ï¸ ä½¿ç”¨æ•°æ®å¯¹é½ç»“æœ: {fallback_result.situation_description}")
            return fallback_result
    
    def _build_analysis_prompt(self, audio_contexts: List[Dict[str, Any]]) -> str:
        """æ„å»ºåˆ†ææç¤ºè¯"""
        
        # æ•´ç†éŸ³é¢‘æ•°æ® - ğŸ”§ ä¿®å¤æ•°æ®æ ¼å¼é—®é¢˜
        audio_summary = []
        for i, context in enumerate(audio_contexts, 1):
            audio_type = context.get('audio_type', 'unknown')
            confidence = float(context.get('confidence', 0.0))  # ç¡®ä¿æ˜¯float
            features = context.get('features', {})
            
            # ğŸ”§ ä¿®å¤æ—¶é—´æˆ³å¤„ç† - æ”¯æŒå­—ç¬¦ä¸²å’Œæ•°å­—
            timestamp = context.get('timestamp', time.time())
            if isinstance(timestamp, str):
                try:
                    # å°è¯•è§£æISOæ ¼å¼æ—¶é—´æˆ³
                    from datetime import datetime
                    dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                    timestamp = dt.timestamp()
                except:
                    timestamp = time.time()
            elif not isinstance(timestamp, (int, float)):
                timestamp = time.time()
            
            audio_summary.append(f"""
ç¬¬{i}æ¬¡æ£€æµ‹ (æ—¶é—´: {time.strftime('%H:%M:%S', time.localtime(float(timestamp)))}):
- éŸ³é¢‘ç±»å‹: {audio_type}
- ç½®ä¿¡åº¦: {confidence:.2f}
- ç‰¹å¾: {json.dumps(features, ensure_ascii=False, indent=2)}
""")
        
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„éŸ³é¢‘ç¯å¢ƒåˆ†æå¸ˆï¼Œå…·æœ‰ä¸°å¯Œçš„å£°å­¦åˆ†æå’Œç¯å¢ƒæ„ŸçŸ¥ç»éªŒã€‚
è¯·åŸºäºä»¥ä¸‹5æ¬¡è¿ç»­çš„éŸ³é¢‘æ£€æµ‹æ•°æ®ï¼Œè¿›è¡Œäººæ€§åŒ–çš„ç¯å¢ƒåˆ†ææè¿°ã€‚

=== éŸ³é¢‘æ£€æµ‹æ•°æ® ===
{''.join(audio_summary)}

=== åˆ†æè¦æ±‚ ===
è¯·ä»ä»¥ä¸‹5ä¸ªç»´åº¦è¿›è¡Œè¯¦ç»†åˆ†æï¼š

1. **æƒ…å†µæè¿°**: æ ¹æ®éŸ³é¢‘æ•°æ®æ¨æµ‹å½“å‰çš„æ•´ä½“æƒ…å†µå’Œç¯å¢ƒçŠ¶æ€
2. **åœ°ç‚¹çŒœæµ‹**: åŸºäºå£°éŸ³ç‰¹å¾æ¨æµ‹å¯èƒ½çš„åœ°ç‚¹æˆ–åœºæ‰€ç±»å‹
3. **å£°éŸ³åˆ†æ**: è¯¦ç»†åˆ†ææ£€æµ‹åˆ°çš„å„ç§å£°éŸ³åŠå…¶ç‰¹å¾
4. **äººå‘˜åˆ†æ**: æ¨æµ‹ç¯å¢ƒä¸­çš„äººæ•°ã€æ´»åŠ¨çŠ¶æ€ã€äº¤æµæƒ…å†µ
5. **éŸ³ä¹åˆ†æ**: åˆ†ææ˜¯å¦æœ‰éŸ³ä¹æ’­æ”¾ï¼ŒéŸ³ä¹ç±»å‹å’Œç‰¹å¾

è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼š
{{
    "situation_description": "è¯¦ç»†çš„æƒ…å†µæè¿°",
    "location_guess": "åœ°ç‚¹çŒœæµ‹",
    "sound_analysis": ["å£°éŸ³1", "å£°éŸ³2", "å£°éŸ³3"],
    "people_analysis": "äººå‘˜åˆ†æ",
    "music_analysis": "éŸ³ä¹åˆ†æ",
    "confidence": 0.85
}}
"""
        return prompt
    
    def _call_llm_analysis(self, prompt: str) -> str:
        """è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œåˆ†æ"""

        # ğŸ”¥ è¯¦ç»†æ—¥å¿—ï¼šæ£€æŸ¥é…ç½®
        self.logger.info(f"ğŸ”¥ [APIè°ƒç”¨] å¼€å§‹è°ƒç”¨GLM-4.5-Flash")
        self.logger.info(f"ğŸ”¥ [APIè°ƒç”¨] APIå¯†é’¥: {self.api_key[:10]}...{self.api_key[-5:] if len(self.api_key) > 15 else 'çŸ­å¯†é’¥'}")
        self.logger.info(f"ğŸ”¥ [APIè°ƒç”¨] Base URL: {self.base_url}")
        self.logger.info(f"ğŸ”¥ [APIè°ƒç”¨] æ¨¡å‹: {self.model}")

        if not self.api_key:
            raise Exception("APIå¯†é’¥æœªé…ç½®")

        import requests

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        data = {
            "model": self.model,
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "temperature": self.temperature,
            "max_tokens": self.max_tokens
        }

        self.logger.info(f"ğŸ”¥ [APIè°ƒç”¨] è¯·æ±‚URL: {self.base_url}/chat/completions")
        self.logger.info(f"ğŸ”¥ [APIè°ƒç”¨] è¯·æ±‚æ•°æ®: {str(data)[:200]}...")

        try:
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=headers,
                json=data,
                timeout=20  # ğŸ”§ ä¿®æ”¹è¶…æ—¶æ—¶é—´åˆ°20ç§’
            )

            self.logger.info(f"ğŸ”¥ [APIè°ƒç”¨] å“åº”çŠ¶æ€ç : {response.status_code}")
            self.logger.info(f"ğŸ”¥ [APIè°ƒç”¨] å“åº”å¤´: {dict(response.headers)}")

            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content']
                self.logger.info(f"ğŸ”¥ [APIè°ƒç”¨] æˆåŠŸï¼è¿”å›å†…å®¹é•¿åº¦: {len(content)}")
                self.logger.info(f"ğŸ”¥ [APIè°ƒç”¨] è¿”å›å†…å®¹é¢„è§ˆ: {content[:100]}...")
                return content
            else:
                error_text = response.text
                self.logger.error(f"ğŸ”¥ [APIè°ƒç”¨] å¤±è´¥ï¼çŠ¶æ€ç : {response.status_code}")
                self.logger.error(f"ğŸ”¥ [APIè°ƒç”¨] é”™è¯¯å“åº”: {error_text}")
                raise Exception(f"APIè°ƒç”¨å¤±è´¥: {response.status_code} - {error_text}")

        except requests.exceptions.Timeout:
            self.logger.error(f"ğŸ”¥ [APIè°ƒç”¨] è¶…æ—¶ï¼20ç§’å†…æœªå“åº”")
            raise Exception("APIè°ƒç”¨è¶…æ—¶")
        except requests.exceptions.ConnectionError as e:
            self.logger.error(f"ğŸ”¥ [APIè°ƒç”¨] è¿æ¥é”™è¯¯: {e}")
            raise Exception(f"APIè¿æ¥å¤±è´¥: {e}")
        except Exception as e:
            self.logger.error(f"ğŸ”¥ [APIè°ƒç”¨] æœªçŸ¥é”™è¯¯: {e}")
            raise
    
    def _parse_analysis_result(self, analysis_text: str) -> AudioAnalysisResult:
        """è§£æåˆ†æç»“æœ"""
        
        try:
            # å°è¯•è§£æJSON
            if '```json' in analysis_text:
                json_start = analysis_text.find('```json') + 7
                json_end = analysis_text.find('```', json_start)
                json_text = analysis_text[json_start:json_end].strip()
            else:
                # å¯»æ‰¾JSONå¯¹è±¡
                start = analysis_text.find('{')
                end = analysis_text.rfind('}') + 1
                json_text = analysis_text[start:end]
            
            result_data = json.loads(json_text)
            
            return AudioAnalysisResult(
                situation_description=result_data.get('situation_description', ''),
                location_guess=result_data.get('location_guess', ''),
                sound_analysis=result_data.get('sound_analysis', []),
                people_analysis=result_data.get('people_analysis', ''),
                music_analysis=result_data.get('music_analysis', ''),
                confidence=float(result_data.get('confidence', 0.5)),
                timestamp=time.time()
            )
            
        except Exception as e:
            self.logger.error(f"âŒ è§£æåˆ†æç»“æœå¤±è´¥: {e}")
            self.logger.error(f"âŒ åŸå§‹åˆ†ææ–‡æœ¬: {analysis_text[:200]}...")
            # ç¡®ä¿è¿”å›AudioAnalysisResultç±»å‹
            return self._create_fallback_result([])
    
    def _create_fallback_result(self, audio_contexts: List[Dict[str, Any]] = None) -> AudioAnalysisResult:
        """ğŸ›¡ï¸ åŸºäºåŸå§‹æ•°æ®åˆ›å»ºæ™ºèƒ½å›é€€ç»“æœ"""

        if not audio_contexts:
            # ğŸ”¥ ä¿®å¤ï¼šè¿”å›åŸºäºçœŸå®æ•°æ®çš„åŸºç¡€åˆ†æ
            return AudioAnalysisResult(
                situation_description="æœªæ£€æµ‹åˆ°éŸ³é¢‘æ´»åŠ¨",
                location_guess="ç¯å¢ƒä¿¡æ¯ä¸è¶³",
                sound_analysis=["é™éŸ³"],
                people_analysis="æ— äººå‘˜æ´»åŠ¨æ£€æµ‹",
                music_analysis="æ— éŸ³ä¹æ£€æµ‹",
                confidence=0.1,  # ä½ç½®ä¿¡åº¦ï¼Œè¡¨ç¤ºæ•°æ®ä¸è¶³
                timestamp=time.time()
            )

        try:
            # ğŸ¯ åŸºäºåŸå§‹éŸ³é¢‘ä¸Šä¸‹æ–‡æ•°æ®è¿›è¡Œæ™ºèƒ½åˆ†æ
            self.logger.info(f"ğŸ›¡ï¸ å¼€å§‹åŸºäº{len(audio_contexts)}ä¸ªåŸå§‹éŸ³é¢‘ä¸Šä¸‹æ–‡åˆ›å»ºå›é€€åˆ†æ")

            # ç»Ÿè®¡éŸ³é¢‘ç±»å‹
            audio_types = []
            confidences = []
            timestamps = []
            features_list = []

            for i, context in enumerate(audio_contexts):
                # ğŸ”§ ä¿®å¤æ•°æ®æ ¼å¼é—®é¢˜ - æ”¯æŒå¤šç§æ•°æ®æº
                audio_type = 'unknown'
                confidence = 0.0

                # æ–¹æ³•1ï¼šç›´æ¥ä»contextè·å–
                if 'audio_type' in context:
                    audio_type = context.get('audio_type', 'unknown')
                    confidence = float(context.get('confidence', 0.0))

                # æ–¹æ³•2ï¼šä»featuresä¸­è·å–ï¼ˆSmartAudioCollectoræ ¼å¼ï¼‰
                elif 'features' in context and isinstance(context['features'], dict):
                    features = context['features']
                    if 'audio_type' in features:
                        audio_type = features.get('audio_type', 'unknown')
                        confidence = float(features.get('confidence', 0.0))

                # æ–¹æ³•3ï¼šä»åµŒå¥—ç»“æ„ä¸­è·å–
                elif isinstance(context, dict):
                    # æ£€æŸ¥æ˜¯å¦æœ‰åµŒå¥—çš„éŸ³é¢‘åˆ†æç»“æœ
                    for key, value in context.items():
                        if isinstance(value, dict) and 'audio_type' in value:
                            audio_type = value.get('audio_type', 'unknown')
                            confidence = float(value.get('confidence', 0.0))
                            break

                # ğŸ” è°ƒè¯•ï¼šè®°å½•æ•°æ®æ ¼å¼
                self.logger.info(f"ğŸ” [å›é€€åˆ†æ] æ‰¹æ¬¡{i+1}: audio_type={audio_type}, confidence={confidence:.2f}")
                self.logger.info(f"ğŸ” [å›é€€åˆ†æ] åŸå§‹æ•°æ®: {str(context)[:200]}...")

                timestamp = context.get('timestamp', time.time())
                features = context.get('features', {})

                audio_types.append(audio_type)
                confidences.append(confidence)
                timestamps.append(timestamp)
                features_list.append(features)

            # åˆ†æéŸ³é¢‘ç±»å‹åˆ†å¸ƒ
            speech_count = audio_types.count('speech')
            music_count = audio_types.count('music')
            noise_count = audio_types.count('noise')
            silence_count = audio_types.count('silence')

            # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
            avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0

            # ğŸ¯ åŸºäºæ•°æ®ç”Ÿæˆæƒ…å†µæè¿°
            if speech_count >= len(audio_contexts) * 0.6:
                situation_description = f"æ£€æµ‹åˆ°{speech_count}æ¬¡è¯­éŸ³æ´»åŠ¨ï¼Œæ¨æµ‹ä¸ºå¯¹è¯æˆ–äº¤æµç¯å¢ƒï¼ŒæŒç»­æ—¶é—´çº¦{len(audio_contexts)*10}ç§’"
                location_guess = "å®¤å†…å¯¹è¯åœºæ‰€ï¼ˆåŠå…¬å®¤ã€ä¼šè®®å®¤æˆ–å®¶åº­ç¯å¢ƒï¼‰"
                people_analysis = f"æ¨æµ‹æœ‰{max(1, speech_count//2)}äººå‚ä¸å¯¹è¯ï¼Œäº¤æµè¾ƒä¸ºæ´»è·ƒ"
            elif music_count >= len(audio_contexts) * 0.4:
                situation_description = f"æ£€æµ‹åˆ°{music_count}æ¬¡éŸ³ä¹æ’­æ”¾ï¼Œæ¨æµ‹ä¸ºå¨±ä¹æˆ–ä¼‘é—²ç¯å¢ƒ"
                location_guess = "å¨±ä¹åœºæ‰€æˆ–ä¸ªäººä¼‘é—²ç©ºé—´"
                people_analysis = f"éŸ³ä¹ç¯å¢ƒï¼Œå¯èƒ½æœ‰{max(1, (speech_count + music_count)//3)}äººåœ¨åœº"
            elif silence_count >= len(audio_contexts) * 0.5:
                situation_description = f"ç¯å¢ƒè¾ƒä¸ºå®‰é™ï¼Œæ£€æµ‹åˆ°{silence_count}æ¬¡é™éŸ³ï¼Œå¯èƒ½ä¸ºä¸“æ³¨å·¥ä½œæˆ–ä¼‘æ¯ç¯å¢ƒ"
                location_guess = "å®‰é™çš„å®¤å†…ç¯å¢ƒï¼ˆå›¾ä¹¦é¦†ã€åŠå…¬å®¤æˆ–å§å®¤ï¼‰"
                people_analysis = "ç¯å¢ƒå®‰é™ï¼Œäººå‘˜æ´»åŠ¨è¾ƒå°‘"
            else:
                situation_description = f"æ··åˆéŸ³é¢‘ç¯å¢ƒï¼ŒåŒ…å«è¯­éŸ³({speech_count}æ¬¡)ã€éŸ³ä¹({music_count}æ¬¡)ã€å™ªéŸ³({noise_count}æ¬¡)"
                location_guess = "å¤æ‚çš„å®¤å†…ç¯å¢ƒï¼Œå¯èƒ½ä¸ºå¤šåŠŸèƒ½åœºæ‰€"
                people_analysis = f"å¤šæ ·åŒ–ç¯å¢ƒï¼Œæ¨æµ‹æœ‰{max(1, len(set(audio_types)))}ç§ä¸åŒæ´»åŠ¨"

            # ğŸ¯ ç”Ÿæˆå£°éŸ³åˆ†æ
            sound_analysis = []
            if speech_count > 0:
                sound_analysis.append(f"è¯­éŸ³æ´»åŠ¨: {speech_count}æ¬¡ï¼Œå¹³å‡ç½®ä¿¡åº¦{sum(c for i, c in enumerate(confidences) if audio_types[i] == 'speech')/max(1, speech_count):.2f}")
            if music_count > 0:
                sound_analysis.append(f"éŸ³ä¹æ£€æµ‹: {music_count}æ¬¡ï¼Œå¯èƒ½ä¸ºèƒŒæ™¯éŸ³ä¹æˆ–ä¸»åŠ¨æ’­æ”¾")
            if noise_count > 0:
                sound_analysis.append(f"ç¯å¢ƒå™ªéŸ³: {noise_count}æ¬¡ï¼Œç¯å¢ƒå¯èƒ½è¾ƒä¸ºå˜ˆæ‚")
            if silence_count > 0:
                sound_analysis.append(f"é™éŸ³æ—¶æ®µ: {silence_count}æ¬¡ï¼Œç¯å¢ƒæ•´ä½“è¾ƒä¸ºå®‰é™")

            if not sound_analysis:
                sound_analysis = ["æ£€æµ‹åˆ°éŸ³é¢‘æ´»åŠ¨ï¼Œä½†ç±»å‹ä¸æ˜ç¡®"]

            # ğŸ¯ ç”ŸæˆéŸ³ä¹åˆ†æ
            if music_count > 0:
                music_analysis = f"æ£€æµ‹åˆ°{music_count}æ¬¡éŸ³ä¹æ´»åŠ¨ï¼Œå¯èƒ½ä¸ºèƒŒæ™¯éŸ³ä¹æˆ–å¨±ä¹æ’­æ”¾ï¼Œå»ºè®®å…³æ³¨ç”¨æˆ·éŸ³ä¹åå¥½"
            else:
                music_analysis = "æœªæ£€æµ‹åˆ°æ˜æ˜¾çš„éŸ³ä¹æ´»åŠ¨ï¼Œç¯å¢ƒä»¥è¯­éŸ³æˆ–é™éŸ³ä¸ºä¸»"

            # ğŸ¯ è®¡ç®—å›é€€ç½®ä¿¡åº¦ï¼ˆåŸºäºåŸå§‹æ•°æ®è´¨é‡ï¼‰
            fallback_confidence = min(0.7, max(0.3, avg_confidence * 0.8))  # å›é€€ç½®ä¿¡åº¦ç•¥ä½äºåŸå§‹æ•°æ®

            self.logger.info(f"ğŸ›¡ï¸ å›é€€åˆ†æå®Œæˆ - è¯­éŸ³:{speech_count}, éŸ³ä¹:{music_count}, é™éŸ³:{silence_count}, ç½®ä¿¡åº¦:{fallback_confidence:.2f}")

            return AudioAnalysisResult(
                situation_description=situation_description,
                location_guess=location_guess,
                sound_analysis=sound_analysis,
                people_analysis=people_analysis,
                music_analysis=music_analysis,
                confidence=fallback_confidence,
                timestamp=time.time()
            )

        except Exception as e:
            self.logger.error(f"âŒ æ™ºèƒ½å›é€€åˆ†æå¤±è´¥: {e}")
            # æœ€ç»ˆå›é€€åˆ°åŸºç¡€ç»“æœ
            return AudioAnalysisResult(
                situation_description="éŸ³é¢‘åˆ†æé‡åˆ°æŠ€æœ¯é—®é¢˜ï¼Œä½¿ç”¨åŸºç¡€ç¯å¢ƒæ¨æµ‹",
                location_guess="å®¤å†…ç¯å¢ƒ",
                sound_analysis=["æ£€æµ‹åˆ°éŸ³é¢‘ä¿¡å·"],
                people_analysis="æ— æ³•ç¡®å®šå…·ä½“äººå‘˜æƒ…å†µ",
                music_analysis="éŸ³é¢‘åˆ†æåŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨",
                confidence=0.2,
                timestamp=time.time()
            )

    def _create_data_aligned_result(self, audio_contexts: List[Dict[str, Any]]) -> AudioAnalysisResult:
        """ğŸ”§ æ•°æ®å¯¹é½æ–¹æ³•ï¼šå»é™¤ç©ºæ•°æ®ï¼Œè¿”å›è¯†åˆ«åˆ°çš„æ•°æ®"""
        if not audio_contexts:
            return AudioAnalysisResult(
                situation_description="",
                location_guess="",
                sound_analysis=[],
                people_analysis="",
                music_analysis="",
                confidence=0.0,
                timestamp=time.time()
            )

        # æ”¶é›†æ‰€æœ‰æœ‰æ•ˆæ•°æ®
        situation_parts = []
        sound_analysis = []
        speakers = []
        music_detected = False
        total_confidence = 0.0
        valid_count = 0

        for i, context in enumerate(audio_contexts):
            audio_type = context.get('audio_type', '')
            confidence = context.get('confidence', 0.0)
            features = context.get('features', {})

            # ğŸ”¥ è¯¦ç»†æ—¥å¿—ï¼šæ£€æŸ¥æ¯ä¸ªä¸Šä¸‹æ–‡æ•°æ®
            self.logger.info(f"ğŸ”¥ [æ•°æ®å¯¹é½] ä¸Šä¸‹æ–‡{i+1}: audio_type='{audio_type}', confidence={confidence}")
            self.logger.info(f"ğŸ”¥ [æ•°æ®å¯¹é½] ä¸Šä¸‹æ–‡{i+1}: features keys={list(features.keys())}")

            # ğŸ”§ ä¿®å¤ï¼šå³ä½¿audio_typeä¸ºç©ºï¼Œä¹Ÿå°è¯•ä»featuresä¸­æå–æ•°æ®
            if not audio_type and features:
                # å°è¯•ä»YAMNetç»“æœä¸­è·å–éŸ³é¢‘ç±»å‹
                yamnet = features.get('yamnet_result', {})
                if yamnet.get('top_class'):
                    audio_type = yamnet['top_class']
                    confidence = yamnet.get('confidence', 0.5)
                    self.logger.info(f"ğŸ”§ [æ•°æ®ä¿®å¤] ä»YAMNetè·å–: {audio_type}, {confidence}")

            # ğŸ”§ ä¿®å¤ï¼šé™ä½è·³è¿‡æ¡ä»¶ï¼Œåªè·³è¿‡å®Œå…¨æ— æ•ˆçš„æ•°æ®
            if not audio_type and confidence <= 0 and not features:
                self.logger.warning(f"âš ï¸ [æ•°æ®å¯¹é½] è·³è¿‡å®Œå…¨æ— æ•ˆçš„ä¸Šä¸‹æ–‡{i+1}")
                continue

            valid_count += 1
            total_confidence += confidence

            # æ”¶é›†éŸ³é¢‘ç±»å‹
            situation_parts.append(f"æ£€æµ‹åˆ°{audio_type}")
            sound_analysis.append(f"{audio_type}: {confidence:.2f}")

            # å¤„ç†SenseVoiceæ•°æ®
            sensevoice = features.get('sensevoice_result', {})
            if sensevoice:
                text = sensevoice.get('text', '').strip()
                speaker = sensevoice.get('speaker_id', '')
                has_bgm = sensevoice.get('has_bgm', False)

                if text:
                    situation_parts.append(f"è¯†åˆ«æ–‡æœ¬: {text[:20]}...")
                if speaker and speaker not in speakers:
                    speakers.append(speaker)
                if has_bgm:
                    music_detected = True

            # å¤„ç†YAMNetæ•°æ®
            yamnet = features.get('yamnet_result', {})
            if yamnet:
                top_class = yamnet.get('top_class', '')
                if top_class:
                    sound_analysis.append(f"YAMNet: {top_class}")

        # ç”Ÿæˆç»“æœ
        avg_confidence = total_confidence / valid_count if valid_count > 0 else 0.0

        situation_description = " | ".join(situation_parts) if situation_parts else ""
        location_guess = "è¯­éŸ³äº¤äº’ç¯å¢ƒ" if speakers else "éŸ³é¢‘æ£€æµ‹ç¯å¢ƒ"
        people_analysis = f"{len(speakers)}äºº" if speakers else ""
        music_analysis = "æ£€æµ‹åˆ°èƒŒæ™¯éŸ³ä¹" if music_detected else ""

        return AudioAnalysisResult(
            situation_description=situation_description,
            location_guess=location_guess,
            sound_analysis=sound_analysis,
            people_analysis=people_analysis,
            music_analysis=music_analysis,
            confidence=avg_confidence,
            timestamp=time.time()
        )




# å…¨å±€å®ä¾‹
_audio_humanized_analyzer = None

def get_audio_humanized_analyzer() -> AudioHumanizedAnalyzer:
    """è·å–éŸ³é¢‘äººæ€§åŒ–åˆ†æå™¨å®ä¾‹"""
    global _audio_humanized_analyzer
    if _audio_humanized_analyzer is None:
        _audio_humanized_analyzer = AudioHumanizedAnalyzer()
    return _audio_humanized_analyzer
