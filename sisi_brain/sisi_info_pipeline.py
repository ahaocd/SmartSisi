#!/usr/bin/env python3
"""
ğŸ”„ Sisiä¿¡æ¯ä¼ é€’ç®¡é“
å°†æ‰€æœ‰æ”¶é›†çš„ä¿¡æ¯ä¼ é€’ç»™Kimi K2æ¨¡å‹

ä¿¡æ¯æµï¼š
FunASR â†’ YAMNet â†’ Mem0 â†’ RAG â†’ ä¿¡æ¯æ•´åˆ â†’ Kimi K2 â†’ ä¸‰ä¸ªæ¨¡å—

ä¼ é€’æ–¹å¼ï¼š
1. JSONæ ¼å¼ä¿¡æ¯åŒ…
2. WebSocketå®æ—¶ä¼ é€’  
3. æ¶ˆæ¯é˜Ÿåˆ—å¼‚æ­¥å¤„ç†
4. ç›´æ¥å‡½æ•°è°ƒç”¨
"""

import os
import sys
import json
import asyncio
import logging
from typing import Dict, List, Optional, Any
from pathlib import Path
from dataclasses import dataclass, asdict
import threading
import queue
import time

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))
from utils import config_util as cfg
from utils import util

# è®¾ç½®æ—¥å¿—
def setup_pipeline_logger():
    logger = logging.getLogger('sisi_pipeline')
    logger.setLevel(logging.INFO)
    
    log_dir = Path(util.ensure_log_dir("brain"))
    
    handler = logging.FileHandler(log_dir / "sisi_pipeline.log", encoding='utf-8')
    formatter = logging.Formatter('%(asctime)s [ä¿¡æ¯ç®¡é“] %(message)s')
    handler.setFormatter(formatter)
    
    if not logger.handlers:
        logger.addHandler(handler)
    
    return logger

pipeline_logger = setup_pipeline_logger()

@dataclass
class SisiInfoPackage:
    """Sisiä¿¡æ¯åŒ… - ä¼ é€’ç»™Kimi K2çš„å®Œæ•´ä¿¡æ¯"""
    
    # åŸºç¡€ä¿¡æ¯
    timestamp: float
    user_input: str
    audio_path: str
    speaker_id: str
    
    # FunASRç»“æœ
    asr_result: Dict = None
    asr_confidence: float = 0.0
    
    # YAMNetéŸ³é¢‘åˆ†æ
    audio_analysis: Dict = None

    # éŸ³ä¹è¯†åˆ«ä¿¡æ¯ï¼ˆACRCloud + å¤§æ¨¡å‹åˆ†æï¼‰
    music_info: Dict = None

    # ğŸ—‘ï¸ è®°å¿†ä¿¡æ¯å·²ç§»é™¤ - ç”±åŠ¨æ€ä¸­æ¢ç›´æ¥è°ƒç”¨è®°å¿†ç³»ç»Ÿ
    
    # RAGæ£€ç´¢ç»“æœ
    rag_context: Dict = None
    
    # ç”¨æˆ·ç”»åƒ
    user_profile: Dict = None
    
    # ç¯å¢ƒä¸Šä¸‹æ–‡
    environment_context: Dict = None
    
    # å¤„ç†çŠ¶æ€
    processing_stage: str = "collecting"
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return asdict(self)
    
    def to_json(self) -> str:
        """è½¬æ¢ä¸ºJSONæ ¼å¼"""
        return json.dumps(self.to_dict(), ensure_ascii=False, indent=2)

class SisiInfoCollector:
    """ğŸ” Sisiä¿¡æ¯æ”¶é›†å™¨"""
    
    def __init__(self):
        self.funasr_client = None
        self.yamnet_analyzer = None
        # ğŸ—‘ï¸ mem0_clientå·²ç§»é™¤ - è®°å¿†è°ƒç”¨ç”±åŠ¨æ€ä¸­æ¢è´Ÿè´£
        self.rag_client = None
        
        self._initialize_clients()
        pipeline_logger.info("ğŸ” Sisiä¿¡æ¯æ”¶é›†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _initialize_clients(self):
        """åˆå§‹åŒ–å„ä¸ªå®¢æˆ·ç«¯"""
        try:
            # ğŸ¯ ä½¿ç”¨ç»Ÿä¸€é…ç½®ç³»ç»Ÿ
            # ğŸ”§ ä¿®å¤é…ç½®åŠ è½½é€»è¾‘ - ç›´æ¥ä½¿ç”¨utils.config_util
            from utils.config_util import load_config
            self.brain_config = load_config()

            if self.brain_config and isinstance(self.brain_config, dict):
                pipeline_logger.info("âœ… å‰è„‘ç³»ç»Ÿé…ç½®åŠ è½½æˆåŠŸ")
            else:
                pipeline_logger.error("âŒ é…ç½®åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                self.brain_config = {}

            # ğŸ¯ åˆå§‹åŒ–çœŸå®çš„å¤§æ¨¡å‹å®¢æˆ·ç«¯
            self._init_llm_clients()

            pipeline_logger.info("âœ… å„ç³»ç»Ÿå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            pipeline_logger.error(f"âŒ å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")

    def _init_llm_clients(self):
        """åˆå§‹åŒ–å¤§æ¨¡å‹å®¢æˆ·ç«¯"""
        try:
            from openai import OpenAI

            # ğŸ¯ ä½¿ç”¨system.confä¸­çš„å‰è„‘ç³»ç»Ÿé…ç½®
            # ä»å…¨å±€é…ç½®å˜é‡ä¸­è·å–APIé…ç½®
            try:
                from utils.config_util import memory_llm_api_key, memory_llm_base_url
                api_key = memory_llm_api_key or ""
                base_url = memory_llm_base_url or ""
            except ImportError:
                # å›é€€åˆ°é…ç½®å­—å…¸æ–¹å¼
                api_key = self.brain_config.get("memory_llm_api_key", "")
                base_url = self.brain_config.get("memory_llm_base_url", "")

            if api_key and base_url:
                # åˆå§‹åŒ–SiliconFlowå®¢æˆ·ç«¯
                self.llm_client = OpenAI(
                    api_key=api_key,
                    base_url=base_url
                )
                pipeline_logger.info("âœ… SiliconFlowå¤§æ¨¡å‹å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
            else:
                pipeline_logger.error("âŒ ç¼ºå°‘APIé…ç½®ä¿¡æ¯")
                self.llm_client = None

        except Exception as e:
            pipeline_logger.error(f"âŒ å¤§æ¨¡å‹å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.llm_client = None
    
    async def collect_funasr_info(self, audio_path: str) -> Dict:
        """æ”¶é›†FunASRä¿¡æ¯ - ğŸ”¥ å¤ç”¨ä¸»äº¤äº’çš„SenseVoiceå’Œå£°çº¹JSONæ•°æ®"""
        try:
            # ğŸ”¥ ä»ä¸»äº¤äº’æµç¨‹è·å–å·²å¤„ç†çš„SenseVoiceå’Œå£°çº¹æ•°æ®
            # é¿å…é‡å¤å¤„ç†ï¼Œç›´æ¥å¤ç”¨JSONæ•°æ®

            pipeline_logger.info("ğŸ¤ å¤ç”¨ä¸»äº¤äº’çš„SenseVoiceå’Œå£°çº¹JSONæ•°æ®")

            # ğŸ¯ ä»sisi_coreè·å–æœ€æ–°çš„éŸ³é¢‘ä¸Šä¸‹æ–‡æ•°æ®
            try:
                from core.sisi_core import get_sisi_core
                sisi_core = get_sisi_core()

                if sisi_core and hasattr(sisi_core, 'latest_audio_context') and sisi_core.latest_audio_context:
                    main_context = sisi_core.latest_audio_context
                    audio_context = main_context.get('audio_context', {})

                    # ğŸ¯ æå–çœŸæ­£çš„SenseVoice JSONæ•°æ®
                    sensevoice_data = audio_context.get('sensevoice', {})
                    voiceprint_data = audio_context.get('voiceprint', {})

                    if sensevoice_data:
                        pipeline_logger.info(f"âœ… æˆåŠŸå¤ç”¨SenseVoice JSONæ•°æ®: {sensevoice_data.get('clean_text', 'N/A')[:20]}...")
                        pipeline_logger.info(f"âœ… æˆåŠŸå¤ç”¨å£°çº¹JSONæ•°æ®: {voiceprint_data.get('real_name', 'N/A')}")

                        return {
                            "text": sensevoice_data.get("clean_text", ""),
                            "original_text": sensevoice_data.get("text", ""),
                            "has_bgm": sensevoice_data.get("has_bgm", False),
                            "emotion": sensevoice_data.get("emotion", "neutral"),
                            "language": sensevoice_data.get("language", "zh"),
                            "speaker_info": {
                                "speaker_id": voiceprint_data.get("speaker_id", "unknown"),
                                "username": voiceprint_data.get("username", "stranger"),
                                "real_name": voiceprint_data.get("real_name", "æœªçŸ¥ç”¨æˆ·"),
                                "confidence": voiceprint_data.get("confidence", 0.0),
                                "is_familiar": voiceprint_data.get("is_familiar", False)
                            },
                            "confidence": float(audio_context.get("confidence", 0.9)),
                            "file_path": audio_context.get("file_path", audio_path),
                            "source": "reused_sensevoice_voiceprint_json"
                        }

            except Exception as reuse_error:
                pipeline_logger.warning(f"âš ï¸ å¤ç”¨SenseVoiceå’Œå£°çº¹JSONæ•°æ®å¤±è´¥: {reuse_error}")

            # å¤‡ç”¨æ–¹æ¡ˆï¼šè¿”å›åŸºç¡€ä¿¡æ¯
            return {
                "text": "SenseVoiceå’Œå£°çº¹JSONæ•°æ®å¤ç”¨å¤±è´¥",
                "confidence": 0.5,
                "speaker_info": "fallback",
                "duration": 0.0,
                "source": "fallback_asr"
            }

        except Exception as e:
            pipeline_logger.error(f"âŒ FunASRä¿¡æ¯æ”¶é›†å¤±è´¥: {e}")
            return {}
    
    async def collect_yamnet_info(self, audio_path: str, text: str = "", speaker_id: str = "unknown") -> Dict:
        """æ”¶é›†éŸ³é¢‘ç¯å¢ƒåˆ†æä¿¡æ¯ - ä½¿ç”¨SenseVoice AEDæ›¿ä»£YAMNet"""
        try:
            # ğŸ¯ è°ƒç”¨SenseVoice AEDè¿›è¡ŒéŸ³é¢‘äº‹ä»¶æ£€æµ‹
            # TODO: å®ç°SenseVoice AEDè°ƒç”¨
            # result = await self._call_sensevoice_aed(audio_path)

            # ğŸ”§ ä¿®å¤ï¼šå¤ç”¨ä¸»äº¤äº’çš„éŸ³é¢‘åˆ†ææ•°æ®ï¼Œé¿å…é‡å¤APIè°ƒç”¨
            try:
                # ğŸ¯ ä¼˜å…ˆä»ä¸»äº¤äº’æµç¨‹è·å–å·²å¤„ç†çš„éŸ³é¢‘åˆ†ææ•°æ®
                from core.sisi_core import get_sisi_core
                sisi_core = get_sisi_core()

                # å°è¯•è·å–ä¸»äº¤äº’çš„éŸ³é¢‘ä¸Šä¸‹æ–‡æ•°æ®
                main_audio_context = None
                if hasattr(sisi_core, 'latest_audio_context'):
                    main_audio_context = sisi_core.latest_audio_context

                if main_audio_context and main_audio_context.get('analysis_result'):
                    # å¤ç”¨ä¸»äº¤äº’çš„åˆ†æç»“æœ
                    analysis_result = main_audio_context['analysis_result']
                    pipeline_logger.info(f"ğŸ”„ å¤ç”¨ä¸»äº¤äº’çš„éŸ³é¢‘åˆ†æç»“æœ")

                    result = {
                        "environment_type": analysis_result.get("environment_type", "quiet"),
                        "has_music": analysis_result.get("has_music", False),
                        "noise_level": analysis_result.get("noise_level", 0.3),
                        "people_count": analysis_result.get("people_count", 1),
                        "dominant_sounds": analysis_result.get("dominant_sounds", ["speech"]),
                        "audio_quality": analysis_result.get("audio_quality", 0.8),
                        "analysis_source": "ReusedMainInteraction"
                    }
                else:
                    # ğŸš¨ å›é€€ï¼šåªåœ¨æ²¡æœ‰ä¸»äº¤äº’æ•°æ®æ—¶æ‰è°ƒç”¨AudioContextProcessor
                    pipeline_logger.warning(f"âš ï¸ æœªæ‰¾åˆ°ä¸»äº¤äº’éŸ³é¢‘æ•°æ®ï¼Œä½¿ç”¨åŸºç¡€ç¯å¢ƒåˆ†æ")

                    result = {
                        "environment_type": "quiet",
                        "has_music": False,
                        "noise_level": 0.3,
                        "people_count": 1,
                        "dominant_sounds": ["speech"],
                        "audio_quality": 0.8,
                        "analysis_source": "BasicFallback"
                    }

                # ğŸ¯ å…³é”®ä¿®å¤ï¼šå°†äº¤äº’éŸ³é¢‘æ•°æ®æ·»åŠ åˆ°ç´¯ç§¯ç®¡ç†å™¨ï¼Œå®ç°æ•°æ®å¯¹é½
                try:
                    from sisi_brain.audio_accumulation_manager import get_audio_accumulation_manager
                    accumulation_manager = get_audio_accumulation_manager()

                    # ğŸ”¥ æ„å»ºå¢å¼ºçš„éŸ³é¢‘ä¸Šä¸‹æ–‡æ•°æ® - åŒ…å«AudioContextProcessorçš„åˆ†æç»“æœ
                    enhanced_audio_context = {
                        'audio_path': audio_path,
                        'text': text,
                        'speaker_id': speaker_id,
                        'analysis_result': analysis_result,
                        'environment_analysis': result,
                        'timestamp': time.time(),
                        # ğŸ¯ æ–°å¢ï¼šæ ‡è®°ä¸ºäº¤äº’éŸ³é¢‘æ•°æ®
                        'source_type': 'interaction',
                        'audio_events': analysis_result.get('audio_events', []) if analysis_result else [],
                        'speaker_info': analysis_result.get('speaker_info', {}) if analysis_result else {},
                        'context_analysis': analysis_result.get('context_analysis', {}) if analysis_result else {}
                    }

                    # ğŸ¯ æ·»åŠ åˆ°ç´¯ç§¯ç®¡ç†å™¨ï¼Œä¸åå°éŸ³é¢‘æ•°æ®ä¸€èµ·å¤„ç†
                    batch_id = accumulation_manager.add_audio_context(enhanced_audio_context)
                    if batch_id:
                        pipeline_logger.info(f"ğŸ¯ äº¤äº’éŸ³é¢‘æ•°æ®å·²æ·»åŠ åˆ°ç´¯ç§¯ç®¡ç†å™¨: {batch_id}")
                        pipeline_logger.info(f"ğŸ”„ äº¤äº’æ•°æ®å°†åœ¨ç¬¬3è½®ä¸åå°æ•°æ®ä¸€èµ·äº¤ä»˜ç»™åŠ¨æ€æç¤ºè¯ä¸­æ¢")

                except Exception as acc_error:
                    pipeline_logger.error(f"âŒ äº¤äº’éŸ³é¢‘æ•°æ®æ·»åŠ åˆ°ç´¯ç§¯ç®¡ç†å™¨å¤±è´¥: {acc_error}")

                pipeline_logger.info(f"ğŸµ éŸ³é¢‘ç¯å¢ƒåˆ†æå®Œæˆ: {result['environment_type']} (æ¥æº: AudioContextProcessor)")

            except Exception as audio_error:
                pipeline_logger.warning(f"âš ï¸ AudioContextProcessoråˆ†æå¤±è´¥: {audio_error}")
                # å›é€€åˆ°åŸºç¡€åˆ†æ
                result = {
                    "environment_type": "quiet",
                    "has_music": False,
                    "noise_level": 0.3,
                    "people_count": 1,
                    "dominant_sounds": ["speech"],
                    "audio_quality": 0.8,
                    "analysis_source": "fallback"
                }

            return result

        except Exception as e:
            pipeline_logger.error(f"âŒ éŸ³é¢‘ç¯å¢ƒåˆ†æå¤±è´¥: {e}")
            return {}

    async def collect_music_info(self, audio_path: str) -> Dict:
        """ğŸµ æ”¶é›†éŸ³ä¹è¯†åˆ«ä¿¡æ¯ï¼ˆACRCloud + å¤§æ¨¡å‹åˆ†æï¼‰"""
        try:
            # å¯¼å…¥éŸ³ä¹åˆ†æå™¨
            from sisi_brain.acrcloud_music_analyzer import get_music_analyzer

            analyzer = get_music_analyzer()

            # æ£€æŸ¥æ˜¯å¦å¯ç”¨éŸ³ä¹è¯†åˆ«
            if not analyzer.enabled:
                pipeline_logger.info("ğŸµ éŸ³ä¹è¯†åˆ«å·²ç¦ç”¨")
                return {"music_recognition_enabled": False}

            # ğŸ”¥ ä½¿ç”¨YAMNetä¸“ä¸šéŸ³ä¹æ£€æµ‹æ›¿ä»£å†™æ­»çš„True
            try:
                from llm.audio_context_processor import get_audio_context_processor
                audio_processor = get_audio_context_processor()
                analysis_result = audio_processor.analyze_audio_context(audio_path)

                # ğŸ¯ è·å–YAMNetéŸ³ä¹æ£€æµ‹ç»“æœ
                has_music = analysis_result.get('has_music', False)
                music_confidence = analysis_result.get('confidence', 0.0)

                # ğŸ¯ YAMNetéŸ³ä¹æ£€æµ‹é˜ˆå€¼ï¼š0.6ä»¥ä¸Šæ‰è§¦å‘åœ¨çº¿è¯†åˆ«
                music_threshold = 0.6
                has_music = has_music and music_confidence >= music_threshold

                pipeline_logger.info(f"ğŸµ YAMNetéŸ³ä¹æ£€æµ‹: {has_music} (ç½®ä¿¡åº¦: {music_confidence:.3f}, é˜ˆå€¼: {music_threshold})")

                if not has_music:
                    pipeline_logger.info(f"ğŸµ æœªè¾¾åˆ°éŸ³ä¹æ£€æµ‹é˜ˆå€¼ï¼Œè·³è¿‡åœ¨çº¿è¯†åˆ«")

            except Exception as e:
                pipeline_logger.warning(f"âš ï¸ YAMNetéŸ³ä¹æ£€æµ‹å¤±è´¥ï¼Œè·³è¿‡éŸ³ä¹è¯†åˆ«: {e}")
                has_music = False

            if has_music:
                pipeline_logger.info(f"ğŸµ æ£€æµ‹åˆ°éŸ³ä¹ï¼Œå¼€å§‹è¯†åˆ«: {Path(audio_path).name}")

                # è¿›è¡Œç»¼åˆéŸ³ä¹åˆ†æ
                music_analysis = await analyzer.comprehensive_music_analysis(audio_path)

                if music_analysis:
                    result = {
                        "music_recognition_enabled": True,
                        "music_detected": True,
                        "yamnet_detection": {
                            "confidence": music_confidence,
                            "threshold": music_threshold,
                            "detection_method": "YAMNet_521_classes"
                        },
                        "song_name": music_analysis.basic_info.song_name,
                        "artist": music_analysis.basic_info.artist,
                        "album": music_analysis.basic_info.album,
                        "genre": music_analysis.basic_info.genre,
                        "confidence": music_analysis.basic_info.confidence,
                        "emotional_analysis": music_analysis.emotional_analysis,
                        "musical_elements": music_analysis.musical_elements,
                        "cultural_context": music_analysis.cultural_context,
                        "recommendations": music_analysis.recommendations,
                        "dynamic_prompts": music_analysis.dynamic_prompts,
                        "daily_usage": analyzer.get_daily_usage_stats()
                    }

                    pipeline_logger.info(f"âœ… éŸ³ä¹è¯†åˆ«æˆåŠŸ: {music_analysis.basic_info.song_name} - {music_analysis.basic_info.artist}")
                    return result
                else:
                    pipeline_logger.warning("âš ï¸ éŸ³ä¹è¯†åˆ«å¤±è´¥")
                    return {
                        "music_recognition_enabled": True,
                        "music_detected": True,
                        "yamnet_detection": {
                            "confidence": music_confidence,
                            "threshold": music_threshold,
                            "detection_method": "YAMNet_521_classes"
                        },
                        "recognition_failed": True,
                        "daily_usage": analyzer.get_daily_usage_stats()
                    }
            else:
                pipeline_logger.info(f"ğŸµ YAMNetæœªæ£€æµ‹åˆ°éŸ³ä¹ (ç½®ä¿¡åº¦: {music_confidence:.3f} < é˜ˆå€¼: {music_threshold})")
                return {
                    "music_recognition_enabled": True,
                    "music_detected": False
                }

        except Exception as e:
            pipeline_logger.error(f"âŒ éŸ³ä¹ä¿¡æ¯æ”¶é›†å¤±è´¥: {e}")
            return {"music_recognition_enabled": False, "error": str(e)}
    
    async def collect_memory_info(self, text: str, speaker_id: str) -> Dict:
        """
        æ”¶é›†è®°å¿†ä¿¡æ¯ - å…¼å®¹æ€§æ–¹æ³•
        å®é™…è®°å¿†è°ƒç”¨ç”±åŠ¨æ€æç¤ºè¯ä¸­æ¢è´Ÿè´£ï¼Œè¿™é‡Œè¿”å›å ä½ç¬¦æ•°æ®
        """
        try:
            pipeline_logger.info(f"ğŸ§  è®°å¿†ä¿¡æ¯æ”¶é›†ï¼ˆå…¼å®¹æ¨¡å¼ï¼‰: {text[:50]}...")

            # è¿”å›å…¼å®¹çš„è®°å¿†ä¿¡æ¯ç»“æ„
            return {
                "memory_available": False,
                "memory_context": "è®°å¿†è°ƒç”¨ç”±åŠ¨æ€æç¤ºè¯ä¸­æ¢è´Ÿè´£",
                "user_profile": {
                    "speaker_id": speaker_id,
                    "familiarity": "unknown"
                },
                "interaction_history": [],
                "confidence": 0.1,
                "source": "compatibility_placeholder"
            }

        except Exception as e:
            pipeline_logger.error(f"âŒ è®°å¿†ä¿¡æ¯æ”¶é›†å¤±è´¥: {e}")
            return {
                "memory_available": False,
                "memory_context": "è®°å¿†æ”¶é›†å¤±è´¥",
                "error": str(e)
            }
    
    async def collect_rag_info(self, text: str, speaker_id: str) -> Dict:
        """æ”¶é›†RAGæ£€ç´¢ä¿¡æ¯ - è°ƒç”¨çœŸå®RAGç³»ç»Ÿ"""
        try:
            # ğŸ”¥ è°ƒç”¨çœŸå®çš„RAGç³»ç»Ÿ
            from sisi_rag.sisi_rag_system import get_rag_system

            rag_system = get_rag_system()

            if rag_system.initialized:
                # ä½¿ç”¨çœŸå®çš„RAGç³»ç»Ÿæ£€ç´¢
                context = rag_system.retrieve_context(text, speaker_id, top_k=3)

                if context.get('context_documents'):
                    result = {
                        "relevant_documents": [doc['content'][:100] + "..." for doc in context['context_documents']],
                        "context_score": sum(doc['relevance_score'] for doc in context['context_documents']) / len(context['context_documents']),
                        "retrieved_knowledge": f"æ£€ç´¢åˆ°{len(context['context_documents'])}ä¸ªç›¸å…³æ–‡æ¡£",
                        "total_results": context['total_results'],
                        "rag_system": "chromadb",
                        "available": True
                    }
                else:
                    result = {
                        "relevant_documents": [],
                        "context_score": 0.0,
                        "retrieved_knowledge": "æœªæ‰¾åˆ°ç›¸å…³çŸ¥è¯†",
                        "total_results": 0,
                        "rag_system": "chromadb",
                        "available": True
                    }

                pipeline_logger.info(f"ğŸ“š çœŸå®RAGä¿¡æ¯æ”¶é›†å®Œæˆ: {context['total_results']}ä¸ªæ–‡æ¡£")
            else:
                # RAGç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
                result = {
                    "relevant_documents": [],
                    "context_score": 0.0,
                    "retrieved_knowledge": "RAGç³»ç»Ÿæœªåˆå§‹åŒ–",
                    "total_results": 0,
                    "rag_system": "fallback",
                    "available": False
                }

                pipeline_logger.warning(f"âš ï¸ RAGç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")

            return result

        except Exception as e:
            pipeline_logger.error(f"âŒ RAGä¿¡æ¯æ”¶é›†å¤±è´¥: {e}")
            return {
                "relevant_documents": [],
                "context_score": 0.0,
                "retrieved_knowledge": "RAGç³»ç»Ÿæš‚æ—¶ä¸å¯ç”¨",
                "available": False,
                "error": str(e)
            }
    
    async def collect_all_info(self, audio_path: str, text: str, speaker_id: str) -> SisiInfoPackage:
        """æ”¶é›†æ‰€æœ‰ä¿¡æ¯ - å¹¶è¡Œå¤„ç†"""
        start_time = time.time()
        
        # åˆ›å»ºä¿¡æ¯åŒ…
        info_package = SisiInfoPackage(
            timestamp=start_time,
            user_input=text,
            audio_path=audio_path,
            speaker_id=speaker_id
        )
        
        try:
            # ğŸ”¥ æ¢å¤å®Œæ•´ä¿¡æ¯ç®¡é“ï¼šæ”¶é›†æ‰€æœ‰6ç§ä¿¡æ¯
            pipeline_logger.info(f"ğŸ” å¼€å§‹å®Œæ•´ä¿¡æ¯æ”¶é›†: {text[:30]}...")

            # 1. å¤ç”¨ä¸»äº¤äº’çš„ASRä¿¡æ¯ï¼ˆSenseVoice + å£°çº¹ï¼‰
            info_package.asr_result = await self.collect_funasr_info(audio_path)
            pipeline_logger.info(f"âœ… ASRä¿¡æ¯æ”¶é›†å®Œæˆ")

            # 2. å®Œæ•´éŸ³é¢‘åˆ†æï¼ˆYAMNet + ç¯å¢ƒæ£€æµ‹ï¼‰
            info_package.audio_analysis = await self.collect_yamnet_info(audio_path, text, speaker_id)  # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨textè€Œä¸æ˜¯user_input
            pipeline_logger.info(f"âœ… éŸ³é¢‘åˆ†æå®Œæˆ")

            # ğŸ¯ ä¿®å¤ï¼šéŸ³ä¹è¯†åˆ«å’ŒRAGæ£€ç´¢ä½¿ç”¨å¿«é€Ÿæ¨¡å¼ï¼Œé¿å…é•¿æ—¶é—´é˜»å¡
            # 3. éŸ³ä¹è¯†åˆ«ä¿¡æ¯ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼Œ5ç§’è¶…æ—¶ï¼‰
            try:
                import asyncio
                info_package.music_info = await asyncio.wait_for(
                    self.collect_music_info(audio_path),
                    timeout=5.0  # ğŸ”¥ 5ç§’è¶…æ—¶ï¼Œé¿å…é•¿æ—¶é—´é˜»å¡
                )
                pipeline_logger.info(f"âœ… éŸ³ä¹ä¿¡æ¯æ”¶é›†å®Œæˆ")
            except asyncio.TimeoutError:
                pipeline_logger.warning(f"âš ï¸ éŸ³ä¹è¯†åˆ«è¶…æ—¶ï¼Œä½¿ç”¨é»˜è®¤ç»“æœ")
                info_package.music_info = {"music_recognition_enabled": False, "timeout": True}

            # 4. RAGæ£€ç´¢ç»“æœï¼ˆå¿«é€Ÿæ¨¡å¼ï¼Œ3ç§’è¶…æ—¶ï¼‰
            try:
                info_package.rag_context = await asyncio.wait_for(
                    self.collect_rag_info(text, speaker_id),
                    timeout=3.0  # ğŸ”¥ 3ç§’è¶…æ—¶ï¼Œé¿å…é•¿æ—¶é—´é˜»å¡
                )
                pipeline_logger.info(f"âœ… RAGä¿¡æ¯æ”¶é›†å®Œæˆ")
            except asyncio.TimeoutError:
                pipeline_logger.warning(f"âš ï¸ RAGæ£€ç´¢è¶…æ—¶ï¼Œä½¿ç”¨é»˜è®¤ç»“æœ")
                info_package.rag_context = {"documents": [], "timeout": True}

            # 5. ç”¨æˆ·ç”»åƒ
            info_package.user_profile = {
                "user_id": speaker_id,
                "is_admin": speaker_id == "ç¢§æ½­é£˜é›ª",
                "interaction_style": "friendly"
            }
            pipeline_logger.info(f"âœ… ç”¨æˆ·ç”»åƒæ„å»ºå®Œæˆ")

            # 6. ç¯å¢ƒä¸Šä¸‹æ–‡
            processing_time = round((time.time() - start_time) * 1000, 2)
            info_package.environment_context = {
                "current_time": time.strftime("%H:%M:%S"),
                "processing_time_ms": processing_time,
                "mode": "complete_collection"
            }

            info_package.processing_stage = "completed"

            pipeline_logger.info(f"ğŸ“¦ å®Œæ•´ä¿¡æ¯æ”¶é›†å®Œæˆ ({processing_time}ms)")

        except Exception as e:
            pipeline_logger.error(f"âŒ ä¿¡æ¯æ”¶é›†å¤±è´¥: {e}")
            info_package.processing_stage = "failed"
            info_package.processing_stage = "failed"
        
        return info_package

class SisiInfoTransmitter:
    """ğŸ“¡ Sisiä¿¡æ¯ä¼ é€’å™¨"""
    
    def __init__(self):
        self.transmission_methods = {
            "direct_call": self._direct_function_call,
            "json_message": self._json_message_transmission,
            "websocket": self._websocket_transmission,
            "message_queue": self._message_queue_transmission
        }
        
        self.message_queue = queue.Queue()
        self.websocket_clients = []
        
        pipeline_logger.info("ğŸ“¡ Sisiä¿¡æ¯ä¼ é€’å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _direct_function_call(self, info_package: SisiInfoPackage, target_module: str) -> str:
        """ç›´æ¥å‡½æ•°è°ƒç”¨ä¼ é€’ - ğŸ¯ å¿«é€Ÿæ¨¡å¼ï¼Œé¿å…APIè°ƒç”¨"""
        try:
            # ğŸ¯ å¿«é€Ÿæ¨¡å¼ï¼šä¸è°ƒç”¨çœŸå®APIï¼Œç›´æ¥ç”Ÿæˆæ¨¡æ¿æç¤ºè¯
            # è¿™æ ·å¯ä»¥å°†å¤„ç†æ—¶é—´ä»41ç§’å‡å°‘åˆ°æ¯«ç§’çº§

            # è·å–åŸºç¡€æ¨¡æ¿ - åªä¿ç•™åŠ¨æ€æç¤ºè¯ç”Ÿæˆ
            base_templates = {
                "åŠ¨æ€æç¤ºè¯ç”Ÿæˆ": "[åŠ¨æ€ä¸Šä¸‹æ–‡å¢å¼º] éŸ³é¢‘ç¯å¢ƒ:{env}, è¯´è¯äººç†Ÿæ‚‰åº¦:{familiarity}, æƒ…ç»ª:{emotion}\n\nåŸºäºéŸ³é¢‘åˆ†æã€RAGæ£€ç´¢ã€è®°å¿†ç³»ç»Ÿï¼Œä¸ºliusisi.pyç”Ÿæˆå¢å¼ºçš„åŠ¨æ€æç¤ºè¯ã€‚"
            }

            # è·å–åŸºç¡€æ¨¡æ¿
            template = base_templates.get(target_module, "æœªçŸ¥æ¨¡å—")

            # å¡«å……å˜é‡
            env = info_package.environment_context.get("current_time", "æœªçŸ¥")
            familiarity = "0.0"  # æ¨¡æ‹Ÿå€¼
            emotion = "ä¸­æ€§"  # æ¨¡æ‹Ÿå€¼
            history_count = "0"  # æ¨¡æ‹Ÿå€¼
            preferences = ""  # æ¨¡æ‹Ÿå€¼

            # æ›¿æ¢å˜é‡
            prompt = template.format(
                env=env,
                familiarity=familiarity,
                emotion=emotion,
                history_count=history_count,
                preferences=preferences
            )

            pipeline_logger.info(f"ğŸ§  å¿«é€Ÿæç¤ºè¯ç”Ÿæˆå®Œæˆ: {target_module}")
            return prompt

        except Exception as e:
            pipeline_logger.error(f"âŒ æç¤ºè¯ç”Ÿæˆå¤±è´¥: {e}")
            return ""
    
    def _json_message_transmission(self, info_package: SisiInfoPackage, target_module: str) -> str:
        """JSONæ¶ˆæ¯ä¼ é€’"""
        try:
            # æ„å»ºJSONæ¶ˆæ¯
            message = {
                "type": "prompt_generation_request",
                "target_module": target_module,
                "info_package": info_package.to_dict(),
                "timestamp": time.time()
            }
            
            # å‘é€åˆ°æ¶ˆæ¯é˜Ÿåˆ—
            self.message_queue.put(json.dumps(message, ensure_ascii=False))
            
            pipeline_logger.info(f"ğŸ“¨ JSONæ¶ˆæ¯ä¼ é€’å®Œæˆ: {target_module}")
            return "message_queued"
            
        except Exception as e:
            pipeline_logger.error(f"âŒ JSONæ¶ˆæ¯ä¼ é€’å¤±è´¥: {e}")
            return ""
    
    def _websocket_transmission(self, info_package: SisiInfoPackage, target_module: str) -> str:
        """WebSocketä¼ é€’"""
        try:
            # WebSocketå®æ—¶ä¼ é€’
            message = {
                "type": "realtime_prompt_request",
                "target_module": target_module,
                "info_package": info_package.to_dict()
            }
            
            # å‘é€ç»™æ‰€æœ‰WebSocketå®¢æˆ·ç«¯
            for client in self.websocket_clients:
                try:
                    # client.send(json.dumps(message))
                    pass
                except:
                    pass
            
            pipeline_logger.info(f"ğŸŒ WebSocketä¼ é€’å®Œæˆ: {target_module}")
            return "websocket_sent"
            
        except Exception as e:
            pipeline_logger.error(f"âŒ WebSocketä¼ é€’å¤±è´¥: {e}")
            return ""
    
    def _message_queue_transmission(self, info_package: SisiInfoPackage, target_module: str) -> str:
        """æ¶ˆæ¯é˜Ÿåˆ—ä¼ é€’"""
        try:
            # å¼‚æ­¥æ¶ˆæ¯é˜Ÿåˆ—å¤„ç†
            task = {
                "type": "async_prompt_generation",
                "target_module": target_module,
                "info_package": info_package.to_dict(),
                "priority": self._get_module_priority(target_module)
            }
            
            self.message_queue.put(task)
            
            pipeline_logger.info(f"ğŸ“¬ æ¶ˆæ¯é˜Ÿåˆ—ä¼ é€’å®Œæˆ: {target_module}")
            return "queued_for_processing"
            
        except Exception as e:
            pipeline_logger.error(f"âŒ æ¶ˆæ¯é˜Ÿåˆ—ä¼ é€’å¤±è´¥: {e}")
            return ""
    
    def _get_module_priority(self, module: str) -> int:
        """è·å–æ¨¡å—ä¼˜å…ˆçº§"""
        priorities = {
            "åŠ¨æ€æç¤ºè¯ç”Ÿæˆ": 1  # å”¯ä¸€æ¨¡å—
        }
        return priorities.get(module, 3)
    
    def transmit_to_kimi_k2(self, info_package: SisiInfoPackage,
                           target_modules: List[str],
                           method: str = "direct_call") -> Dict[str, str]:
        """ä¼ é€’ä¿¡æ¯åˆ°Kimi K2ç”Ÿæˆæç¤ºè¯å¹¶æ³¨å…¥åˆ°ç°æœ‰ç³»ç»Ÿ"""

        # 1. ç”ŸæˆåŸºç¡€æç¤ºè¯
        base_prompts = {}
        transmission_func = self.transmission_methods.get(method, self._direct_function_call)

        for module in target_modules:
            try:
                result = transmission_func(info_package, module)
                base_prompts[module] = result

            except Exception as e:
                pipeline_logger.error(f"âŒ ä¼ é€’åˆ°{module}å¤±è´¥: {e}")
                base_prompts[module] = ""

        # 2. æ³¨å…¥åŠ¨æ€ä¸Šä¸‹æ–‡åˆ°ç°æœ‰ç³»ç»Ÿ - ä½¿ç”¨å†…ç½®æ–¹æ³•æ›¿ä»£ç¼ºå¤±æ¨¡å—
        try:
            # ğŸ¯ ç›´æ¥ä½¿ç”¨åŠ¨æ€ä¸Šä¸‹æ–‡ä¸­æ¢è¿›è¡Œæ³¨å…¥ï¼Œé¿å…ä¾èµ–ç¼ºå¤±çš„æ¨¡å—
            from sisi_brain.dynamic_context_hub import get_dynamic_context_hub

            hub = get_dynamic_context_hub()

            # æ„å»ºåŠ¨æ€æç¤ºè¯
            dynamic_prompt = ""
            if hasattr(hub, 'current_context') and hub.current_context:
                dynamic_prompt = hub.get_dynamic_prompt_for_sisi()

            # ç®€åŒ–æ³¨å…¥é€»è¾‘ï¼šç›´æ¥å°†åŠ¨æ€æç¤ºè¯æ·»åŠ åˆ°åŸºç¡€æç¤ºè¯ä¸­
            injected_prompts = {}
            for module, base_prompt in base_prompts.items():
                if dynamic_prompt:
                    injected_prompts[module] = f"{dynamic_prompt}\n\n{base_prompt}"
                else:
                    injected_prompts[module] = base_prompt

            pipeline_logger.info("ğŸ’‰ åŠ¨æ€ä¸Šä¸‹æ–‡æ³¨å…¥å®Œæˆ")
            return injected_prompts

        except Exception as e:
            pipeline_logger.error(f"âŒ åŠ¨æ€ä¸Šä¸‹æ–‡æ³¨å…¥å¤±è´¥: {e}")
            return base_prompts

    def _get_original_system_prompts(self) -> Dict[str, str]:
        """è·å–ç°æœ‰ç³»ç»Ÿçš„åŸå§‹æç¤ºè¯"""
        return {
            "åŠ¨æ€æç¤ºè¯ç”Ÿæˆ": "åŸºäºéŸ³é¢‘åˆ†æã€RAGæ£€ç´¢ã€è®°å¿†ç³»ç»Ÿï¼Œä¸ºliusisi.pyç”Ÿæˆå¢å¼ºçš„åŠ¨æ€æç¤ºè¯ã€‚"
        }

class SisiInfoPipeline:
    """ğŸ”„ Sisiå®Œæ•´ä¿¡æ¯ç®¡é“"""
    
    def __init__(self):
        self.collector = SisiInfoCollector()
        self.transmitter = SisiInfoTransmitter()
        
        pipeline_logger.info("ğŸ”„ Sisiä¿¡æ¯ç®¡é“åˆå§‹åŒ–å®Œæˆ")
    
    async def process_user_input(self, audio_path: str, text: str, speaker_id: str) -> Dict[str, str]:
        """å¤„ç†ç”¨æˆ·è¾“å…¥ - å®Œæ•´æµç¨‹"""

        try:
            pipeline_logger.info(f"ğŸ”„ å¼€å§‹å¤„ç†ç”¨æˆ·è¾“å…¥: éŸ³é¢‘={audio_path}, æ–‡æœ¬={text[:50]}..., è¯´è¯äºº={speaker_id}")

            # 1. æ”¶é›†æ‰€æœ‰ä¿¡æ¯
            pipeline_logger.info("ğŸ“¥ å¼€å§‹æ”¶é›†æ‰€æœ‰ä¿¡æ¯...")
            info_package = await self.collector.collect_all_info(audio_path, text, speaker_id)
            pipeline_logger.info(f"ğŸ“¦ ä¿¡æ¯æ”¶é›†å®Œæˆ: ä¿¡æ¯åŒ…å·²ç”Ÿæˆ")

            # 2. ä¼ é€’ç»™åŠ¨æ€æç¤ºè¯ç”Ÿæˆæ¨¡å—
            target_modules = ["åŠ¨æ€æç¤ºè¯ç”Ÿæˆ"]
            pipeline_logger.info(f"ğŸ“¤ å¼€å§‹ä¼ é€’ä¿¡æ¯åˆ°ç›®æ ‡æ¨¡å—: {target_modules}")

            results = self.transmitter.transmit_to_kimi_k2(
                info_package,
                target_modules,
                method="direct_call"  # æ‚¨å¯ä»¥é€‰æ‹©ä¼ é€’æ–¹å¼
            )

            pipeline_logger.info(f"ğŸ‰ å®Œæ•´ä¿¡æ¯ç®¡é“å¤„ç†å®Œæˆ: {results.get('status', 'unknown')}")
            return {
                "status": "success",
                "info_package_processed": True,
                "target_modules": target_modules,
                "results": results
            }

        except Exception as e:
            pipeline_logger.error(f"âŒ ä¿¡æ¯ç®¡é“å¤„ç†å¤±è´¥: {e}")
            return {
                "status": "error",
                "error": str(e)
            }

# å…¨å±€ç®¡é“å®ä¾‹
_sisi_pipeline = None

def get_sisi_pipeline():
    """è·å–Sisiä¿¡æ¯ç®¡é“å®ä¾‹"""
    global _sisi_pipeline
    if _sisi_pipeline is None:
        _sisi_pipeline = SisiInfoPipeline()
    return _sisi_pipeline

async def process_sisi_input(audio_path: str, text: str, speaker_id: str) -> Dict[str, str]:
    """ä¾¿æ·å‡½æ•°ï¼šå¤„ç†Sisiè¾“å…¥"""
    pipeline = get_sisi_pipeline()
    return await pipeline.process_user_input(audio_path, text, speaker_id)

def test_sisi_pipeline():
    """ğŸ§ª çœŸå®çš„ã€å…¨é¢çš„å‰è„‘ç³»ç»Ÿæµ‹è¯•"""
    print("ğŸ§ª å‰è„‘ç³»ç»Ÿå®Œæ•´æµ‹è¯•")
    print("="*80)

    async def run_comprehensive_test():
        # ğŸ¯ æµ‹è¯•ç”¨ä¾‹ï¼šä½¿ç”¨çœŸå®çš„å£°éŸ³æ–‡ä»¶å’Œè¾“å…¥
        test_cases = [
            {
                "name": "ç®¡ç†å‘˜å£°çº¹æµ‹è¯•",
                "text": "ç³»å•Š",
                "audio_path": os.path.join(cfg.cache_root or "cache_data", "é”¦åè·¯å››æ®µ_converted.wav"),
                "speaker_id": "ç¢§æ½­é£˜é›ª",
                "expected_admin": True
            },
            {
                "name": "æ™®é€šç”¨æˆ·æµ‹è¯•",
                "text": "å–‚å–‚å–‚ç†Šæ€»",
                "audio_path": "test_audio.wav",
                "speaker_id": "User",
                "expected_admin": False
            },
            {
                "name": "éŸ³ä¹è¯†åˆ«æµ‹è¯•",
                "text": "è¿™é¦–æ­Œä¸é”™å‘¢",
                "audio_path": "music_test.wav",
                "speaker_id": "ç¢§æ½­é£˜é›ª",
                "expected_music": True
            },
            {
                "name": "å™ªéŸ³ç¯å¢ƒæµ‹è¯•",
                "text": "å¥½åµå•Šï¼Œè°åœ¨ä¸€ç›´å•°å—¦ï¼Ÿ",
                "audio_path": "noisy_test.wav",
                "speaker_id": "ç¢§æ½­é£˜é›ª",
                "expected_noisy": True
            }
        ]

        pipeline = get_sisi_pipeline()

        for i, test_case in enumerate(test_cases, 1):
            print(f"\n{'='*20} æµ‹è¯• {i}: {test_case['name']} {'='*20}")
            print(f"ğŸ“ è¾“å…¥æ–‡æœ¬: {test_case['text']}")
            print(f"ğŸ¤ éŸ³é¢‘æ–‡ä»¶: {test_case['audio_path']}")
            print(f"ğŸ‘¤ è¯´è¯äºº: {test_case['speaker_id']}")

            start_time = time.time()

            try:
                # ğŸ¯ æµ‹è¯•ä¿¡æ¯æ”¶é›†
                print("\nğŸ” æ­¥éª¤1: æµ‹è¯•ä¿¡æ¯æ”¶é›†...")
                info_package = await pipeline.collector.collect_all_info(
                    test_case['audio_path'],
                    test_case['text'],
                    test_case['speaker_id']
                )

                collection_time = round((time.time() - start_time) * 1000, 2)
                print(f"âœ… ä¿¡æ¯æ”¶é›†å®Œæˆ ({collection_time}ms)")

                # ğŸ¯ éªŒè¯æ”¶é›†ç»“æœ
                print("\nğŸ“Š æ­¥éª¤2: éªŒè¯æ”¶é›†ç»“æœ...")
                _validate_info_package(info_package, test_case)

                # ğŸ¯ æµ‹è¯•æç¤ºè¯ç”Ÿæˆ
                print("\nğŸ’­ æ­¥éª¤3: æµ‹è¯•æç¤ºè¯ç”Ÿæˆ...")
                target_modules = ["åŠ¨æ€æç¤ºè¯ç”Ÿæˆ"]

                prompt_start = time.time()
                results = pipeline.transmitter.transmit_to_kimi_k2(
                    info_package,
                    target_modules,
                    method="direct_call"
                )
                prompt_time = round((time.time() - prompt_start) * 1000, 2)
                print(f"âœ… æç¤ºè¯ç”Ÿæˆå®Œæˆ ({prompt_time}ms)")

                # ğŸ¯ éªŒè¯æç¤ºè¯ç»“æœ
                print("\nğŸ¯ æ­¥éª¤4: éªŒè¯æç¤ºè¯ç»“æœ...")
                _validate_prompt_results(results, target_modules)

                total_time = round((time.time() - start_time) * 1000, 2)
                print(f"\nğŸ‰ æµ‹è¯• {i} å®Œæˆï¼æ€»è€—æ—¶: {total_time}ms")

                # ğŸ¯ æ€§èƒ½æ£€æŸ¥
                if total_time > 10000:  # è¶…è¿‡10ç§’
                    print(f"âš ï¸  è­¦å‘Š: å¤„ç†æ—¶é—´è¿‡é•¿ ({total_time}ms)")
                elif total_time < 1000:  # å°‘äº1ç§’
                    print(f"ğŸš€ ä¼˜ç§€: å¤„ç†é€Ÿåº¦å¾ˆå¿« ({total_time}ms)")
                else:
                    print(f"âœ… è‰¯å¥½: å¤„ç†æ—¶é—´åˆç† ({total_time}ms)")

            except Exception as e:
                print(f"âŒ æµ‹è¯• {i} å¤±è´¥: {str(e)}")
                import traceback
                traceback.print_exc()

        print(f"\n{'='*80}")
        print("ğŸ‰ å‰è„‘ç³»ç»Ÿå®Œæ•´æµ‹è¯•å®Œæˆï¼")

    def _validate_info_package(info_package: SisiInfoPackage, test_case: dict):
        """éªŒè¯ä¿¡æ¯åŒ…å†…å®¹"""
        print("  ğŸ“‹ éªŒè¯ä¿¡æ¯åŒ…...")

        # åŸºç¡€éªŒè¯
        assert info_package.user_input == test_case['text'], "ç”¨æˆ·è¾“å…¥ä¸åŒ¹é…"
        assert info_package.speaker_id == test_case['speaker_id'], "è¯´è¯äººIDä¸åŒ¹é…"
        print("  âœ… åŸºç¡€ä¿¡æ¯éªŒè¯é€šè¿‡")

        # ASRç»“æœéªŒè¯
        assert info_package.asr_result is not None, "ASRç»“æœä¸ºç©º"
        assert 'text' in info_package.asr_result, "ASRç»“æœç¼ºå°‘æ–‡æœ¬"
        print("  âœ… ASRç»“æœéªŒè¯é€šè¿‡")

        # ç”¨æˆ·ç”»åƒéªŒè¯
        if test_case.get('expected_admin'):
            assert info_package.user_profile.get('is_admin') == True, "ç®¡ç†å‘˜èº«ä»½è¯†åˆ«å¤±è´¥"
            print("  âœ… ç®¡ç†å‘˜èº«ä»½éªŒè¯é€šè¿‡")

        # éŸ³é¢‘åˆ†æéªŒè¯
        assert info_package.audio_analysis is not None, "éŸ³é¢‘åˆ†æç»“æœä¸ºç©º"
        print("  âœ… éŸ³é¢‘åˆ†æéªŒè¯é€šè¿‡")

        # å¤„ç†é˜¶æ®µéªŒè¯
        assert info_package.processing_stage == "completed", "å¤„ç†é˜¶æ®µä¸æ­£ç¡®"
        print("  âœ… å¤„ç†é˜¶æ®µéªŒè¯é€šè¿‡")

    def _validate_prompt_results(results: dict, target_modules: list):
        """éªŒè¯æç¤ºè¯ç»“æœ"""
        print("  ğŸ“‹ éªŒè¯æç¤ºè¯ç»“æœ...")

        # æ£€æŸ¥æ‰€æœ‰æ¨¡å—éƒ½æœ‰ç»“æœ
        for module in target_modules:
            assert module in results, f"ç¼ºå°‘{module}çš„ç»“æœ"
            assert results[module] is not None, f"{module}ç»“æœä¸ºç©º"
            print(f"  âœ… {module}ç»“æœéªŒè¯é€šè¿‡")

        # æ£€æŸ¥ç»“æœå†…å®¹
        for module, result in results.items():
            if isinstance(result, str) and len(result) > 0:
                print(f"  ğŸ“ {module}: {result[:50]}...")
            else:
                print(f"  âš ï¸  {module}: ç»“æœä¸ºç©ºæˆ–æ ¼å¼å¼‚å¸¸")

    asyncio.run(run_comprehensive_test())

if __name__ == "__main__":
    test_sisi_pipeline()
