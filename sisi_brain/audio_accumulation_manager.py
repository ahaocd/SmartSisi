#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
éŸ³é¢‘ç´¯ç§¯ç®¡ç†å™¨
åŠŸèƒ½ï¼šç®¡ç†20æ¬¡éŸ³é¢‘åˆ†æç´¯ç§¯ï¼Œè§¦å‘åŠ¨æ€å¤§æ¨¡å‹ä¸­æ¢æŠ½å–ï¼Œç®¡ç†ç¼“å­˜æ¸…ç†
"""

import json
import time
import logging
import threading
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict
from pathlib import Path
import pickle

from utils import config_util as cfg
from .audio_humanized_analyzer import get_audio_humanized_analyzer, AudioAnalysisResult
from .music_humanized_processor import get_music_humanized_processor, MusicProcessResult

@dataclass
class AccumulationBatch:
    """ç´¯ç§¯æ‰¹æ¬¡æ•°æ®"""
    batch_id: str                           # æ‰¹æ¬¡ID
    audio_analysis: AudioAnalysisResult     # éŸ³é¢‘äººæ€§åŒ–åˆ†æç»“æœ
    music_results: List[MusicProcessResult] # éŸ³ä¹å¤„ç†ç»“æœåˆ—è¡¨
    raw_audio_contexts: List[Dict[str, Any]] # åŸå§‹éŸ³é¢‘ä¸Šä¸‹æ–‡
    timestamp: float                        # æ‰¹æ¬¡æ—¶é—´æˆ³
    processed: bool = False                 # æ˜¯å¦å·²è¢«åŠ¨æ€ä¸­æ¢å¤„ç†

class AudioAccumulationManager:
    """éŸ³é¢‘ç´¯ç§¯ç®¡ç†å™¨"""
    
    def __init__(self, cache_dir: str = None):
        self.logger = logging.getLogger(__name__)
        if not cache_dir:
            base_cache = cfg.cache_root or "cache_data"
            cache_dir = str(Path(base_cache) / "audio_accumulation")
        
        # ç´¯ç§¯é…ç½® - ğŸ”§ ä¿®å¤é˜ˆå€¼åŒ¹é…é—®é¢˜
        self.batch_size = 3          # 3æ¬¡åˆ†æä¸€æ‰¹ï¼ˆåŒ¹é…éŸ³é¢‘æ”¶é›†å™¨ï¼‰
        self.max_batches = 4         # æœ€å¤šä¿å­˜4æ‰¹ (4*3=12æ¬¡)
        self.hub_trigger_count = 1   # 1æ‰¹åè§¦å‘åŠ¨æ€ä¸­æ¢æŠ½å– (1*3=3æ¬¡éŸ³é¢‘)
        
        # å­˜å‚¨
        self.current_contexts: List[Dict[str, Any]] = []  # å½“å‰ç´¯ç§¯çš„éŸ³é¢‘ä¸Šä¸‹æ–‡
        self.accumulated_batches: List[AccumulationBatch] = []  # ç´¯ç§¯çš„æ‰¹æ¬¡
        self.music_queue: List[Dict[str, Any]] = []  # éŸ³ä¹è¯†åˆ«é˜Ÿåˆ—
        
        # ç¼“å­˜ç®¡ç†
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.cache_file = self.cache_dir / "accumulation_state.pkl"
        
        # ç»„ä»¶
        self.audio_analyzer = get_audio_humanized_analyzer()
        self.music_processor = get_music_humanized_processor()
        
        # çº¿ç¨‹é”
        self.lock = threading.Lock()
        
        # åŠ è½½ç¼“å­˜çŠ¶æ€
        self._load_cache_state()
        
        self.logger.info(f"âœ… éŸ³é¢‘ç´¯ç§¯ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ - æ‰¹æ¬¡å¤§å°: {self.batch_size}, æœ€å¤§æ‰¹æ¬¡: {self.max_batches}")
    
    def add_audio_context(self, audio_context: Dict[str, Any]) -> Optional[str]:
        """
        æ·»åŠ éŸ³é¢‘ä¸Šä¸‹æ–‡
        è¦æ±‚ï¼šaudio_context å†…å« 'voiceprint.identity'ï¼ˆowner/stranger, user_id, usernameï¼‰
        """
        with self.lock:
            try:
                # è½»é‡æ ¡éªŒå¹¶æ‰“å°èº«ä»½æ‘˜è¦ï¼Œæ–¹ä¾¿è¿½æº¯
                try:
                    identity = audio_context.get('voiceprint', {}).get('identity', {}) if isinstance(audio_context, dict) else {}
                    label = identity.get('label'); uid = identity.get('user_id'); uname = identity.get('username')
                    if label and uid is not None:
                        self.logger.info(f"ğŸ§­ [ç´¯ç§¯ç®¡ç†å™¨] èº«ä»½={label}, user_id={uid}, username={uname}")
                except Exception:
                    pass

                self.current_contexts.append(audio_context)
                self.logger.info(f"âœ… [ç´¯ç§¯ç®¡ç†å™¨] éŸ³é¢‘ä¸Šä¸‹æ–‡å·²æ·»åŠ : {len(self.current_contexts)}/{self.batch_size}")

                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ‰¹æ¬¡å¤§å°
                if len(self.current_contexts) >= self.batch_size:
                    batch_id = self._process_batch()
                    self._save_cache_state()
                    return batch_id

                return None

            except Exception as e:
                self.logger.error(f"âŒ æ·»åŠ éŸ³é¢‘ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
                return None
    
    def add_music_recognition(self, acrcloud_result: Dict[str, Any], audio_context: Dict[str, Any] = None) -> None:
        """
        æ·»åŠ éŸ³ä¹è¯†åˆ«ç»“æœ
        
        Args:
            acrcloud_result: ACRCloudè¯†åˆ«ç»“æœ
            audio_context: ç›¸å…³çš„éŸ³é¢‘ä¸Šä¸‹æ–‡
        """
        with self.lock:
            try:
                music_data = {
                    'acrcloud_result': acrcloud_result,
                    'audio_context': audio_context,
                    'timestamp': time.time()
                }
                self.music_queue.append(music_data)
                self.logger.info(f"ğŸµ æ·»åŠ éŸ³ä¹è¯†åˆ«ç»“æœ - é˜Ÿåˆ—é•¿åº¦: {len(self.music_queue)}")
                
            except Exception as e:
                self.logger.error(f"âŒ æ·»åŠ éŸ³ä¹è¯†åˆ«ç»“æœå¤±è´¥: {e}")
    
    def _process_separated_batch(self) -> str:
        """å¤„ç†åˆ†ç¦»å¼æ‰¹æ¬¡ - ğŸ”¥ æ–°çš„åˆ†ç¦»å¤„ç†é€»è¾‘"""

        batch_id = f"separated_batch_{int(time.time())}_{len(self.accumulated_batches)}"

        try:
            # ğŸ¯ åˆ†ç¦»å¼å¤„ç†ï¼šåˆå¹¶æ‰€æœ‰ç±»å‹çš„æ•°æ®è¿›è¡Œåˆ†æ
            all_contexts = []

            # æ”¶é›†æ‰€æœ‰ç±»å‹çš„ä¸Šä¸‹æ–‡
            if hasattr(self, 'separated_contexts'):
                for data_type, contexts in self.separated_contexts.items():
                    all_contexts.extend(contexts)
                    self.logger.info(f"ğŸ“Š æ”¶é›†{data_type}: {len(contexts)}ä¸ªä¸Šä¸‹æ–‡")

            # å…¼å®¹ä¼ ç»Ÿæ ¼å¼
            all_contexts.extend(self.current_contexts)

            if not all_contexts:
                self.logger.warning("âš ï¸ æ²¡æœ‰å¯å¤„ç†çš„éŸ³é¢‘ä¸Šä¸‹æ–‡")
                return batch_id

            # 1. è¿›è¡ŒéŸ³é¢‘äººæ€§åŒ–åˆ†æï¼ˆä½¿ç”¨æ‰€æœ‰å¯ç”¨æ•°æ®ï¼‰
            self.logger.info(f"ğŸ§  å¼€å§‹å¤„ç†åˆ†ç¦»å¼æ‰¹æ¬¡ {batch_id} - {len(all_contexts)}ä¸ªéŸ³é¢‘ä¸Šä¸‹æ–‡")
            audio_analysis = self.audio_analyzer.analyze_accumulated_audio(all_contexts)

            # ğŸ” è°ƒè¯•ï¼šæ£€æŸ¥éŸ³é¢‘åˆ†æç»“æœ
            self.logger.info(f"ğŸ” [è°ƒè¯•] éŸ³é¢‘åˆ†æç»“æœç±»å‹: {type(audio_analysis)}")
            if hasattr(audio_analysis, 'situation_description'):
                self.logger.info(f"ğŸ” [è°ƒè¯•] æƒ…å†µæè¿°: {audio_analysis.situation_description}")
            else:
                self.logger.warning(f"âš ï¸ [è°ƒè¯•] éŸ³é¢‘åˆ†æç»“æœç¼ºå°‘situation_descriptionå±æ€§")

            # 2. æ¸…ç©ºå·²å¤„ç†çš„æ•°æ®
            if hasattr(self, 'separated_contexts'):
                for data_type in self.separated_contexts:
                    processed_count = len(self.separated_contexts[data_type])
                    self.separated_contexts[data_type] = []
                    self.logger.info(f"ğŸ—‘ï¸ å·²æ¸…ç©º{data_type}: {processed_count}ä¸ªä¸Šä¸‹æ–‡")

            self.current_contexts = []

            return self._complete_batch_processing(batch_id, audio_analysis, all_contexts)

        except Exception as e:
            self.logger.error(f"âŒ åˆ†ç¦»å¼æ‰¹æ¬¡å¤„ç†å¤±è´¥: {e}")
            return batch_id

    def _process_batch(self) -> str:
        """å¤„ç†ä¼ ç»Ÿæ‰¹æ¬¡ - ä¿æŒå‘åå…¼å®¹"""

        batch_id = f"batch_{int(time.time())}_{len(self.accumulated_batches)}"

        try:
            # 1. è¿›è¡ŒéŸ³é¢‘äººæ€§åŒ–åˆ†æ
            self.logger.info(f"ğŸ§  å¼€å§‹å¤„ç†ä¼ ç»Ÿæ‰¹æ¬¡ {batch_id} - {len(self.current_contexts)}ä¸ªéŸ³é¢‘ä¸Šä¸‹æ–‡")
            audio_analysis = self.audio_analyzer.analyze_accumulated_audio(self.current_contexts)

            # ğŸ” è°ƒè¯•ï¼šæ£€æŸ¥éŸ³é¢‘åˆ†æç»“æœ
            self.logger.info(f"ğŸ” [è°ƒè¯•] éŸ³é¢‘åˆ†æç»“æœç±»å‹: {type(audio_analysis)}")
            self.logger.info(f"ğŸ” [è°ƒè¯•] æ˜¯å¦ä¸ºNone: {audio_analysis is None}")
            if hasattr(audio_analysis, 'situation_description'):
                self.logger.info(f"ğŸ” [è°ƒè¯•] æƒ…å†µæè¿°: {audio_analysis.situation_description}")
            if hasattr(audio_analysis, '__dataclass_fields__'):
                self.logger.info(f"ğŸ” [è°ƒè¯•] æ˜¯dataclass: True")
            else:
                self.logger.warning(f"âš ï¸ [è°ƒè¯•] ä¸æ˜¯dataclass: {type(audio_analysis)}")

            return self._complete_batch_processing(batch_id, audio_analysis, self.current_contexts)

        except Exception as e:
            self.logger.error(f"âŒ ä¼ ç»Ÿæ‰¹æ¬¡å¤„ç†å¤±è´¥: {e}")
            return batch_id

    def _complete_batch_processing(self, batch_id: str, audio_analysis, contexts_list) -> str:
        """å®Œæˆæ‰¹æ¬¡å¤„ç†çš„é€šç”¨é€»è¾‘"""

        try:
            # 2. å¤„ç†ç›¸å…³çš„éŸ³ä¹è¯†åˆ«ç»“æœ
            music_results = []
            processed_music_indices = []

            for i, music_data in enumerate(self.music_queue):
                # æ£€æŸ¥éŸ³ä¹è¯†åˆ«æ—¶é—´æ˜¯å¦åœ¨å½“å‰æ‰¹æ¬¡æ—¶é—´èŒƒå›´å†…
                music_time = music_data['timestamp']
                batch_start_time = min(ctx.get('timestamp', time.time()) for ctx in self.current_contexts)
                batch_end_time = max(ctx.get('timestamp', time.time()) for ctx in self.current_contexts)

                if batch_start_time <= music_time <= batch_end_time + 30:  # 30ç§’å®¹å·®
                    music_result = self.music_processor.process_music_recognition(
                        music_data['acrcloud_result'],
                        music_data['audio_context']
                    )
                    music_results.append(music_result)
                    processed_music_indices.append(i)

            # ç§»é™¤å·²å¤„ç†çš„éŸ³ä¹è¯†åˆ«ç»“æœ
            for i in reversed(processed_music_indices):
                self.music_queue.pop(i)

            # 3. åˆ›å»ºç´¯ç§¯æ‰¹æ¬¡
            batch = AccumulationBatch(
                batch_id=batch_id,
                audio_analysis=audio_analysis,
                music_results=music_results,
                raw_audio_contexts=self.current_contexts.copy(),
                timestamp=time.time()
            )

            # 4. æ·»åŠ åˆ°ç´¯ç§¯æ‰¹æ¬¡åˆ—è¡¨
            self.accumulated_batches.append(batch)

            # 5. æ¸…ç©ºå½“å‰ä¸Šä¸‹æ–‡
            self.current_contexts.clear()

            # 6. æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…ç†æ—§æ‰¹æ¬¡
            if len(self.accumulated_batches) > self.max_batches:
                removed_batch = self.accumulated_batches.pop(0)
                self.logger.info(f"ğŸ—‘ï¸ æ¸…ç†æ—§æ‰¹æ¬¡: {removed_batch.batch_id}")

            # 7. æ£€æŸ¥æ˜¯å¦è§¦å‘åŠ¨æ€ä¸­æ¢æŠ½å–
            if len(self.accumulated_batches) >= self.hub_trigger_count:
                self._trigger_dynamic_hub_extraction()

            self.logger.info(f"âœ… æ‰¹æ¬¡å¤„ç†å®Œæˆ {batch_id} - éŸ³é¢‘åˆ†æç½®ä¿¡åº¦: {audio_analysis.confidence:.2f}, éŸ³ä¹ç»“æœ: {len(music_results)}ä¸ª")
            return batch_id

        except Exception as e:
            self.logger.error(f"âŒ æ‰¹æ¬¡å¤„ç†å¤±è´¥: {e}")
            # æ¸…ç©ºå½“å‰ä¸Šä¸‹æ–‡é¿å…æ•°æ®ç§¯å‹
            self.current_contexts.clear()
            return batch_id
    
    def _trigger_dynamic_hub_extraction(self) -> None:
        """è§¦å‘åŠ¨æ€å¤§æ¨¡å‹ä¸­æ¢æŠ½å– - çœŸæ­£è°ƒç”¨åŠ¨æ€ä¸­æ¢"""

        try:
            self.logger.info(f"ğŸ¯ è§¦å‘åŠ¨æ€å¤§æ¨¡å‹ä¸­æ¢æŠ½å– - {len(self.accumulated_batches)}ä¸ªæ‰¹æ¬¡")

            # æ ‡è®°æ‰€æœ‰æ‰¹æ¬¡ä¸ºå·²å¤„ç†
            for batch in self.accumulated_batches:
                batch.processed = True

            # ğŸ”¥ çœŸæ­£è°ƒç”¨åŠ¨æ€å¤§æ¨¡å‹ä¸­æ¢ - åŒæ—¶æŠ½å–éŸ³é¢‘+è®°å¿†+RAG
            from sisi_brain.dynamic_context_hub import get_dynamic_context_hub

            hub = get_dynamic_context_hub()

            # å‡†å¤‡éŸ³é¢‘æ‰¹æ¬¡æ•°æ® (å·²ç»è¿‡ä¸“é—¨æ¨¡å‹å¤„ç†)
            audio_batches = []
            for batch in self.accumulated_batches:
                # ğŸ”§ ä¿®å¤asdict()é”™è¯¯ï¼šå¼ºåˆ¶ç¡®ä¿æ•°æ®ç±»å‹ä¸€è‡´æ€§
                try:
                    # æ£€æŸ¥audio_analysisæ˜¯å¦ä¸ºAudioAnalysisResultç±»å‹
                    from sisi_brain.audio_humanized_analyzer import AudioAnalysisResult

                    if isinstance(batch.audio_analysis, AudioAnalysisResult):
                        audio_analysis_dict = asdict(batch.audio_analysis)
                        self.logger.info(f"âœ… æ‰¹æ¬¡{len(audio_batches)+1}: AudioAnalysisResultæ­£ç¡®è½¬æ¢")
                    elif hasattr(batch.audio_analysis, '__dataclass_fields__'):
                        audio_analysis_dict = asdict(batch.audio_analysis)
                        self.logger.info(f"âœ… æ‰¹æ¬¡{len(audio_batches)+1}: dataclassæ­£ç¡®è½¬æ¢")
                    elif isinstance(batch.audio_analysis, dict):
                        # å¦‚æœå·²ç»æ˜¯å­—å…¸ï¼Œç›´æ¥ä½¿ç”¨
                        audio_analysis_dict = batch.audio_analysis
                        self.logger.warning(f"âš ï¸ æ‰¹æ¬¡{len(audio_batches)+1}: audio_analysiså·²æ˜¯dictç±»å‹")
                    else:
                        # å°è¯•è½¬æ¢ä¸ºå­—å…¸
                        audio_analysis_dict = batch.audio_analysis.__dict__ if hasattr(batch.audio_analysis, '__dict__') else {}
                        self.logger.error(f"âŒ æ‰¹æ¬¡{len(audio_batches)+1}: audio_analysisç±»å‹å¼‚å¸¸: {type(batch.audio_analysis)}")

                    # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨ï¼Œé¿å…N/Aå€¼
                    required_fields = ['situation_description', 'location_guess', 'sound_analysis', 'people_analysis', 'music_analysis', 'confidence']
                    for field in required_fields:
                        if field not in audio_analysis_dict or audio_analysis_dict[field] is None:
                            if field == 'confidence':
                                audio_analysis_dict[field] = 0.5
                            elif field in ['sound_analysis']:
                                audio_analysis_dict[field] = []
                            else:
                                audio_analysis_dict[field] = f"æ‰¹æ¬¡{len(audio_batches)+1}æ•°æ®æ”¶é›†ä¸­"

                    music_results_list = []
                    for music in batch.music_results:
                        if hasattr(music, '__dataclass_fields__'):
                            music_results_list.append(asdict(music))
                        else:
                            music_results_list.append(music.__dict__ if hasattr(music, '__dict__') else {})

                    batch_data = {
                        'audio_analysis': audio_analysis_dict,
                        'music_results': music_results_list,
                        'raw_audio_contexts': batch.raw_audio_contexts,
                        'timestamp': batch.timestamp
                    }
                    audio_batches.append(batch_data)

                except Exception as e:
                    self.logger.error(f"âŒ æ‰¹æ¬¡æ•°æ®è½¬æ¢å¤±è´¥: {e}")
                    self.logger.error(f"âŒ audio_analysisç±»å‹: {type(batch.audio_analysis)}")
                    self.logger.error(f"âŒ audio_analysiså†…å®¹: {batch.audio_analysis}")

                    # ğŸ¯ ä½¿ç”¨çœŸå®æ•°æ®çš„å›é€€ç­–ç•¥ï¼Œè€Œä¸æ˜¯ç©ºæ•°æ®
                    if hasattr(batch.audio_analysis, 'situation_description'):
                        # å¦‚æœæœ‰å±æ€§ä½†è½¬æ¢å¤±è´¥ï¼Œæ‰‹åŠ¨æ„å»ºå­—å…¸
                        audio_analysis_dict = {
                            'situation_description': getattr(batch.audio_analysis, 'situation_description', 'æ•°æ®è½¬æ¢å¤±è´¥'),
                            'location_guess': getattr(batch.audio_analysis, 'location_guess', 'æœªçŸ¥ä½ç½®'),
                            'sound_analysis': getattr(batch.audio_analysis, 'sound_analysis', ['éŸ³é¢‘å¤„ç†å¼‚å¸¸']),
                            'people_analysis': getattr(batch.audio_analysis, 'people_analysis', 'äººå‘˜åˆ†æå¤±è´¥'),
                            'music_analysis': getattr(batch.audio_analysis, 'music_analysis', 'éŸ³ä¹åˆ†æå¤±è´¥'),
                            'confidence': getattr(batch.audio_analysis, 'confidence', 0.1),
                            'timestamp': getattr(batch.audio_analysis, 'timestamp', time.time())
                        }
                    else:
                        # å®Œå…¨å¤±è´¥æ—¶çš„æœ€å°æ•°æ®
                        audio_analysis_dict = {
                            'situation_description': f'æ‰¹æ¬¡æ•°æ®è½¬æ¢å¼‚å¸¸: {str(e)}',
                            'location_guess': 'æ•°æ®å¤„ç†å¤±è´¥',
                            'sound_analysis': ['ç³»ç»Ÿå¼‚å¸¸'],
                            'people_analysis': 'æ— æ³•åˆ†æ',
                            'music_analysis': 'æ— æ³•åˆ†æ',
                            'confidence': 0.05,
                            'timestamp': time.time()
                        }

                    batch_data = {
                        'audio_analysis': audio_analysis_dict,
                        'music_results': [],
                        'raw_audio_contexts': batch.raw_audio_contexts,
                        'timestamp': batch.timestamp
                    }
                    audio_batches.append(batch_data)

            # ğŸ§  é€šè¿‡ä¿¡æ¯ç®¡é“æŠ½å–è®°å¿†åº“å’ŒRAGæ•°æ® (é¿å…é‡å¤ä»£ç )
            memory_data, rag_data = self._extract_memory_and_rag_via_pipeline()

            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä¼ é€’å®Œæ•´çš„éŸ³é¢‘äººæ€§åŒ–åˆ†æç»“æœç»™åŠ¨æ€ä¸­æ¢
            self.logger.info(f"ğŸ”¥ [å…³é”®ä¼ é€’] å¼€å§‹ä¼ é€’éŸ³é¢‘äººæ€§åŒ–åˆ†æç»“æœç»™åŠ¨æ€ä¸­æ¢")
            self.logger.info(f"ğŸ”¥ [å…³é”®ä¼ é€’] éŸ³é¢‘æ‰¹æ¬¡æ•°é‡: {len(audio_batches)}")

            # ğŸ” è¯¦ç»†æ£€æŸ¥æ¯ä¸ªæ‰¹æ¬¡çš„æ•°æ®å®Œæ•´æ€§
            valid_batches = []
            for i, batch in enumerate(audio_batches):
                audio_analysis = batch.get('audio_analysis', {})
                situation_desc = audio_analysis.get('situation_description', '')

                if situation_desc and situation_desc != 'æ•°æ®æ”¶é›†ä¸­':
                    self.logger.info(f"âœ… [å…³é”®ä¼ é€’] æ‰¹æ¬¡{i+1}: æœ‰æ•ˆæ•°æ® - {situation_desc[:50]}...")
                    valid_batches.append(batch)
                else:
                    self.logger.warning(f"âš ï¸ [å…³é”®ä¼ é€’] æ‰¹æ¬¡{i+1}: æ•°æ®ä¸å®Œæ•´ - {situation_desc}")
                    # ä¸ºä¸å®Œæ•´çš„æ‰¹æ¬¡è¡¥å……åŸºç¡€æ•°æ®
                    if not situation_desc:
                        audio_analysis['situation_description'] = f"æ‰¹æ¬¡{i+1}éŸ³é¢‘æ•°æ®å¤„ç†ä¸­"
                        audio_analysis['location_guess'] = "æ•°æ®æ”¶é›†ç¯å¢ƒ"
                        audio_analysis['confidence'] = 0.3
                    valid_batches.append(batch)

                self.logger.info(f"ğŸ”¥ [å…³é”®ä¼ é€’] æ‰¹æ¬¡{i+1}: éŸ³é¢‘åˆ†æå­—æ®µæ•°={len(audio_analysis)}, éŸ³ä¹ç»“æœ={len(batch['music_results'])}ä¸ª")

            # ä½¿ç”¨éªŒè¯åçš„æ‰¹æ¬¡æ•°æ®
            audio_batches = valid_batches

            # è°ƒç”¨åŠ¨æ€ä¸­æ¢ç”Ÿæˆä¸Šä¸‹æ–‡ - ç»¼åˆåˆ†æä¸‰ä¸ªæ•°æ®æº
            dynamic_context = hub.extract_and_generate_context(
                audio_batches=audio_batches,
                memory_data=memory_data,  # çœŸæ­£çš„è®°å¿†æ•°æ®
                rag_data=rag_data,       # çœŸæ­£çš„RAGæ•°æ®
                current_user_input=""    # ğŸ”§ ä¿®å¤ï¼šæ·»åŠ current_user_inputå‚æ•°é¿å…environmentå˜é‡æœªå®šä¹‰é”™è¯¯
            )

            self.logger.info(f"ğŸ”¥ [å…³é”®ä¼ é€’] åŠ¨æ€ä¸­æ¢æ¥æ”¶å®Œæˆï¼Œç”Ÿæˆä¸Šä¸‹æ–‡ç½®ä¿¡åº¦: {dynamic_context.confidence:.2f}")

            self.logger.info(f"âœ… åŠ¨æ€ä¸­æ¢æŠ½å–å®Œæˆ - ç½®ä¿¡åº¦: {dynamic_context.confidence:.2f}")
            self.logger.info(f"ğŸ“ éŸ³é¢‘æ‘˜è¦: {dynamic_context.audio_summary[:100]}...")
            self.logger.info(f"ğŸ’­ äº¤äº’å»ºè®®: {dynamic_context.interaction_suggestions[:100]}...")

            # ä¿å­˜æŠ½å–ç»“æœåˆ°æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
            extraction_file = self.cache_dir / f"hub_extraction_{int(time.time())}.json"
            with open(extraction_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'dynamic_context': asdict(dynamic_context),
                    'extraction_time': time.time(),
                    'total_audio_contexts': sum(len(batch.raw_audio_contexts) for batch in self.accumulated_batches),
                    'total_music_results': sum(len(batch.music_results) for batch in self.accumulated_batches)
                }, f, ensure_ascii=False, indent=2, default=str)

            self.logger.info(f"ğŸ“¤ åŠ¨æ€ä¸­æ¢æŠ½å–ç»“æœå·²ä¿å­˜: {extraction_file}")

            # ğŸ”§ ä¿®å¤ï¼šä¸ç«‹å³æ¸…ç©ºï¼Œä¿ç•™æ•°æ®ä¾›å‰è„‘ç³»ç»Ÿä½¿ç”¨
            # åªæ ‡è®°ä¸ºå·²å¤„ç†ï¼Œä½†ä¿ç•™æ•°æ®
            self.logger.info(f"âœ… åŠ¨æ€ä¸­æ¢æŠ½å–å®Œæˆï¼Œä¿ç•™{len(self.accumulated_batches)}ä¸ªæ‰¹æ¬¡ä¾›å‰è„‘ç³»ç»Ÿä½¿ç”¨")

        except Exception as e:
            self.logger.error(f"âŒ åŠ¨æ€ä¸­æ¢æŠ½å–å¤±è´¥: {e}")
            # ğŸ”§ ä¿®å¤ï¼šå¤±è´¥æ—¶ä¹Ÿä¿ç•™æ•°æ®ï¼Œä¾›å‰è„‘ç³»ç»Ÿä½¿ç”¨
            self.logger.info(f"âš ï¸ æŠ½å–å¤±è´¥ï¼Œä½†ä¿ç•™{len(self.accumulated_batches)}ä¸ªæ‰¹æ¬¡ä¾›å‰è„‘ç³»ç»Ÿä½¿ç”¨")

    def _extract_memory_and_rag_via_pipeline(self) -> tuple[Dict[str, Any], Dict[str, Any]]:
        """é€šè¿‡ä¿¡æ¯ç®¡é“æŠ½å–è®°å¿†å’ŒRAGæ•°æ® - é¿å…é‡å¤ä»£ç """
        try:
            # å¯¼å…¥ä¿¡æ¯ç®¡é“
            from sisi_brain.sisi_info_pipeline import get_sisi_pipeline

            pipeline = get_sisi_pipeline()

            # ä»ç´¯ç§¯çš„éŸ³é¢‘ä¸Šä¸‹æ–‡ä¸­æå–æŸ¥è¯¢ä¿¡æ¯
            all_speakers = set()
            all_texts = []

            for batch in self.accumulated_batches:
                for context in batch.raw_audio_contexts:
                    # ç»Ÿä¸€ä» voiceprint.identity å– user_id
                    vid = (context.get('voiceprint', {}) or {}).get('identity', {}) if isinstance(context, dict) else {}
                    speaker_id = (vid or {}).get('user_id', 'unknown')
                    text = context.get('text', '')
                    if speaker_id != 'unknown':
                        all_speakers.add(speaker_id)
                    if text:
                        all_texts.append(text)

            # æ„å»ºç»¼åˆæŸ¥è¯¢
            query = " ".join(all_texts[:5]) if all_texts else "éŸ³é¢‘ç¯å¢ƒåˆ†æ"
            main_speaker = list(all_speakers)[0] if all_speakers else "unknown"

            # ğŸ”¥ ä½¿ç”¨ä¿¡æ¯ç®¡é“æ”¶é›†è®°å¿†å’ŒRAGä¿¡æ¯ (é¿å…é‡å¤ä»£ç )
            import asyncio

            # å¼‚æ­¥æ”¶é›†è®°å¿†å’ŒRAGä¿¡æ¯
            try:
                loop = asyncio.get_running_loop()
                memory_task = loop.create_task(pipeline.collector.collect_memory_info(query, main_speaker))
                rag_task = loop.create_task(pipeline.collector.collect_rag_info(query, main_speaker))

                memory_data = loop.run_until_complete(memory_task)
                rag_data = loop.run_until_complete(rag_task)
            except RuntimeError:
                # å¦‚æœæ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„
                memory_data = asyncio.run(pipeline.collector.collect_memory_info(query, main_speaker))
                rag_data = asyncio.run(pipeline.collector.collect_rag_info(query, main_speaker))

            self.logger.info(f"ğŸ§ ğŸ“š é€šè¿‡ä¿¡æ¯ç®¡é“æŠ½å–å®Œæˆ: è®°å¿†ç³»ç»Ÿ={memory_data.get('memory_system', 'unknown')}, RAGç³»ç»Ÿ={rag_data.get('rag_system', 'unknown')}")

            return memory_data, rag_data

        except Exception as e:
            self.logger.error(f"âŒ é€šè¿‡ä¿¡æ¯ç®¡é“æŠ½å–å¤±è´¥: {e}")

            # è¿”å›ç©ºæ•°æ®
            empty_memory = {
                'relevant_memories': [],
                'memory_context': 'è®°å¿†ç³»ç»Ÿæš‚æ—¶ä¸å¯ç”¨',
                'available': False,
                'error': str(e)
            }

            empty_rag = {
                'relevant_documents': [],
                'context_score': 0.0,
                'retrieved_knowledge': 'RAGç³»ç»Ÿæš‚æ—¶ä¸å¯ç”¨',
                'available': False,
                'error': str(e)
            }

            return empty_memory, empty_rag
    
    def _save_cache_state(self) -> None:
        """ä¿å­˜ç¼“å­˜çŠ¶æ€"""
        try:
            state_data = {
                'current_contexts': self.current_contexts,
                'accumulated_batches': [asdict(batch) for batch in self.accumulated_batches],
                'music_queue': self.music_queue,
                'timestamp': time.time()
            }
            
            with open(self.cache_file, 'wb') as f:
                pickle.dump(state_data, f)
                
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜ç¼“å­˜çŠ¶æ€å¤±è´¥: {e}")
    
    def _load_cache_state(self) -> None:
        """åŠ è½½ç¼“å­˜çŠ¶æ€"""
        try:
            if self.cache_file.exists():
                with open(self.cache_file, 'rb') as f:
                    state_data = pickle.load(f)
                
                self.current_contexts = state_data.get('current_contexts', [])
                self.music_queue = state_data.get('music_queue', [])
                
                # é‡å»ºç´¯ç§¯æ‰¹æ¬¡å¯¹è±¡
                batch_dicts = state_data.get('accumulated_batches', [])
                self.accumulated_batches = []
                for batch_dict in batch_dicts:
                    # é‡å»ºå¯¹è±¡
                    batch = AccumulationBatch(**batch_dict)
                    self.accumulated_batches.append(batch)
                
                self.logger.info(f"ğŸ“‚ åŠ è½½ç¼“å­˜çŠ¶æ€æˆåŠŸ - å½“å‰ä¸Šä¸‹æ–‡: {len(self.current_contexts)}, ç´¯ç§¯æ‰¹æ¬¡: {len(self.accumulated_batches)}")
                
        except Exception as e:
            self.logger.error(f"âŒ åŠ è½½ç¼“å­˜çŠ¶æ€å¤±è´¥: {e}")
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–ç®¡ç†å™¨çŠ¶æ€"""
        with self.lock:
            return {
                'current_contexts_count': len(self.current_contexts),
                'accumulated_batches_count': len(self.accumulated_batches),
                'music_queue_count': len(self.music_queue),
                'next_batch_progress': f"{len(self.current_contexts)}/{self.batch_size}",
                'hub_trigger_progress': f"{len(self.accumulated_batches)}/{self.hub_trigger_count}",
                'cache_dir': str(self.cache_dir)
            }
    
    def clear_cache(self) -> None:
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        with self.lock:
            self.current_contexts.clear()
            self.accumulated_batches.clear()
            self.music_queue.clear()
            
            # åˆ é™¤ç¼“å­˜æ–‡ä»¶
            if self.cache_file.exists():
                self.cache_file.unlink()
            
            self.logger.info("ğŸ—‘ï¸ å·²æ¸…ç©ºæ‰€æœ‰éŸ³é¢‘ç´¯ç§¯ç¼“å­˜")

# å…¨å±€å®ä¾‹
_audio_accumulation_manager = None

def get_audio_accumulation_manager() -> AudioAccumulationManager:
    """è·å–éŸ³é¢‘ç´¯ç§¯ç®¡ç†å™¨å®ä¾‹"""
    global _audio_accumulation_manager
    if _audio_accumulation_manager is None:
        _audio_accumulation_manager = AudioAccumulationManager()
    return _audio_accumulation_manager

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    manager = get_audio_accumulation_manager()
    
    # æ¨¡æ‹Ÿæ·»åŠ éŸ³é¢‘ä¸Šä¸‹æ–‡
    for i in range(12):  # æµ‹è¯•12ä¸ªä¸Šä¸‹æ–‡ (ä¼šäº§ç”Ÿ2ä¸ªæ‰¹æ¬¡)
        test_context = {
            'audio_type': 'music' if i % 3 == 0 else 'speech',
            'confidence': 0.8,
            'features': {'test': f'feature_{i}'},
            'timestamp': time.time() + i
        }
        
        batch_id = manager.add_audio_context(test_context)
        if batch_id:
            print(f"âœ… è§¦å‘æ‰¹æ¬¡å¤„ç†: {batch_id}")
        
        time.sleep(0.1)
    
    # æŸ¥çœ‹çŠ¶æ€
    status = manager.get_status()
    print(f"ğŸ“Š ç®¡ç†å™¨çŠ¶æ€: {json.dumps(status, indent=2, ensure_ascii=False)}")
