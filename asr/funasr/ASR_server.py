import asyncio
import websockets
import argparse
import json
import logging
import os
import time
import threading
import concurrent.futures

# ğŸ”§ ä¿®å¤FFmpegè·¯å¾„é—®é¢˜ï¼ˆtorchcodecéœ€è¦FFmpeg sharedç‰ˆæœ¬çš„DLLï¼‰
def fix_ffmpeg_path():
    """ä¿®å¤FFmpegè·¯å¾„ï¼Œè®©torchcodecèƒ½æ‰¾åˆ°DLL"""
    ffmpeg_paths = [
        # BtbN FFmpeg 7.1 GPL Shared (å¸¦DLLï¼Œå…¼å®¹torchcodec 0.9.1)
        r"C:\Users\senlin\AppData\Local\Microsoft\WinGet\Packages\BtbN.FFmpeg.GPL.Shared.7.1_Microsoft.Winget.Source_8wekyb3d8bbwe\ffmpeg-n7.1.3-22-g40b336e650-win64-gpl-shared-7.1\bin",
        r"C:\Program Files\ffmpeg\bin",
        r"C:\ffmpeg\bin",
    ]
    for ffmpeg_path in ffmpeg_paths:
        if os.path.exists(ffmpeg_path):
            current_path = os.environ.get('PATH', '')
            if ffmpeg_path not in current_path:
                os.environ['PATH'] = ffmpeg_path + ';' + current_path
            os.environ['FFMPEG_BINARY'] = os.path.join(ffmpeg_path, "ffmpeg.exe")
            print(f"[FFmpeg] è·¯å¾„å·²é…ç½®: {ffmpeg_path}")
            return True
    print("[FFmpeg] æœªæ‰¾åˆ°sharedç‰ˆæœ¬")
    return False

# åœ¨å¯¼å…¥FunASRä¹‹å‰ä¿®å¤FFmpeg
fix_ffmpeg_path()

# ä¼˜å…ˆè®¾ç½®æœ¬åœ°æ¨¡å‹ç¼“å­˜ç›®å½•ï¼Œé¿å…æ¯æ¬¡è”ç½‘ä¸‹è½½
try:
    os.environ.setdefault('MODELSCOPE_CACHE', r"C:\Users\senlin\.cache\modelscope\hub")
except Exception:
    pass

from funasr import AutoModel

# SISIå£°çº¹è¯†åˆ«ç³»ç»Ÿ - å”¯ä¸€çš„å£°çº¹è¯†åˆ«æ–¹æ¡ˆ
print("[SISI] å£°çº¹è¯†åˆ«ç³»ç»Ÿå·²å°±ç»ª")

# è®¾ç½®æ—¥å¿—çº§åˆ«
logger = logging.getLogger(__name__)
logger.setLevel(logging.CRITICAL)

# è§£æå‘½ä»¤è¡Œå‚æ•°
parser = argparse.ArgumentParser()
parser.add_argument("--host", type=str, default="0.0.0.0", help="host ip, localhost, 0.0.0.0")
parser.add_argument("--port", type=int, default=10197, help="grpc server port")
parser.add_argument("--ngpu", type=int, default=1, help="0 for cpu, 1 for gpu")
args = parser.parse_args()

# åˆå§‹åŒ–æ¨¡å‹
print("model loading")
print(f"FunASRç‰ˆæœ¬æ£€æŸ¥...")

# æ£€æŸ¥FunASRç‰ˆæœ¬
try:
    import funasr
    print(f"FunASRç‰ˆæœ¬: {funasr.__version__}")
except:
    print("æ— æ³•è·å–FunASRç‰ˆæœ¬")

# æ£€æŸ¥ModelScopeç‰ˆæœ¬
try:
    import modelscope
    print(f"ModelScopeç‰ˆæœ¬: {modelscope.__version__}")
except:
    print("æ— æ³•è·å–ModelScopeç‰ˆæœ¬")

# ğŸ”¥ è¯»å–é…ç½®æ–‡ä»¶ï¼Œæ ¹æ®asr_modeé€‰æ‹©æ¨¡å‹
import configparser
config = configparser.ConfigParser()
# ä¿®å¤ï¼šæ­£ç¡®è®¡ç®—é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆASR_server.pyåœ¨SmartSisi/asr/funasr/ï¼Œéœ€è¦å‘ä¸Š3å±‚åˆ°SmartSisi/ï¼‰
current_file = os.path.abspath(__file__)  # E:\liusisi\SmartSisi\asr\funasr\ASR_server.py
asr_dir = os.path.dirname(current_file)  # E:\liusisi\SmartSisi\asr\funasr
smartsisi_dir = os.path.dirname(os.path.dirname(asr_dir))  # E:\liusisi\SmartSisi
config_path = os.path.join(smartsisi_dir, "system.conf")
asr_mode = "sensevoice"  # é»˜è®¤å€¼

try:
    print(f"[é…ç½®] å°è¯•è¯»å–é…ç½®æ–‡ä»¶: {config_path}")
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    config.read(config_path, encoding='utf-8')
    asr_mode = config.get('key', 'asr_mode', fallback='sensevoice').lower()
    print(f"[é…ç½®] é…ç½®æ–‡ä»¶è¯»å–æˆåŠŸ: asr_mode = {asr_mode}")
except Exception as e:
    print(f"[é…ç½®] é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼ sensevoice")

# æ ¹æ®é…ç½®åŠ è½½å¯¹åº”æ¨¡å‹
local_root = os.path.expandvars(r"C:\Users\senlin\.cache\modelscope\hub\models\iic")

if asr_mode == "funasr":
    # ä½¿ç”¨FunASR Paraformeræ¨¡å‹
    print("[é…ç½®] æ¨¡å¼: FunASR (Paraformer)")
    try:
        local_paraformer = os.path.join(local_root, "speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch")
        local_vad = os.path.join(local_root, "speech_fsmn_vad_zh-cn-16k-common-pytorch")
        local_punc = os.path.join(local_root, "punc_ct-transformer_zh-cn-common-vocab272727-pytorch")

        if os.path.exists(local_paraformer) and os.path.exists(local_vad) and os.path.exists(local_punc):
            print("[æ¨¡å‹] ä½¿ç”¨æœ¬åœ°Paraformeræ¨¡å‹")
            asr_model = AutoModel(
                model=local_paraformer,
                vad_model=local_vad,
                punc_model=local_punc,
                disable_update=True,
                device="cpu"
            )
        else:
            print("[æ¨¡å‹] ä½¿ç”¨è¿œç¨‹Paraformeræ¨¡å‹")
            asr_model = AutoModel(
                model="iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
                vad_model="iic/speech_fsmn_vad_zh-cn-16k-common-pytorch",
                punc_model="iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch",
                disable_update=True,
                device="cpu"
            )
        print("[æ¨¡å‹] FunASR ParaformeråŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"[é”™è¯¯] ParaformeråŠ è½½å¤±è´¥: {e}")
        raise

else:
    # ä½¿ç”¨SenseVoiceæ¨¡å‹ï¼ˆé»˜è®¤ï¼‰
    print("[é…ç½®] æ¨¡å¼: SenseVoice")
    try:
        local_model = os.path.join(local_root, "SenseVoiceSmall")
        local_vad = os.path.join(local_root, "speech_fsmn_vad_zh-cn-16k-common-pytorch")
        local_punc = os.path.join(local_root, "punc_ct-transformer_zh-cn-common-vocab272727-pytorch")

        if os.path.exists(local_model) and os.path.exists(local_vad) and os.path.exists(local_punc):
            print("[æ¨¡å‹] ä½¿ç”¨æœ¬åœ°SenseVoiceæ¨¡å‹")
            asr_model = AutoModel(
                model=local_model,
                vad_model=local_vad,
                punc_model=local_punc,
                disable_update=True,
                device="cpu"
            )
        else:
            print("[æ¨¡å‹] ä½¿ç”¨è¿œç¨‹SenseVoiceæ¨¡å‹")
            asr_model = AutoModel(
                model="iic/SenseVoiceSmall",
                vad_model="iic/speech_fsmn_vad_zh-cn-16k-common-pytorch",
                punc_model="iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch",
                disable_update=True,
                device="cpu"
            )
        print("[æ¨¡å‹] SenseVoiceåŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"[é”™è¯¯] SenseVoiceåŠ è½½å¤±è´¥: {e}")
        raise

# éªŒè¯æ¨¡å‹åŠŸèƒ½
print("[éªŒè¯] éªŒè¯ASRæ¨¡å‹åŠŸèƒ½...")
try:
    if hasattr(asr_model, 'generate') or hasattr(asr_model, '__call__'):
        print(f"[éªŒè¯] ASRåŠŸèƒ½å¯ç”¨ - {asr_mode.upper()}æ¨¡å‹å·²å°±ç»ª")
    elif hasattr(asr_model, 'model'):
        print(f"[éªŒè¯] ASRåŠŸèƒ½å¯ç”¨ - {asr_mode.upper()}æ¨¡å‹å¯¹è±¡å·²åŠ è½½")
    else:
        print("[éªŒè¯] ASRåŠŸèƒ½éªŒè¯å¤±è´¥ - æœªæ‰¾åˆ°é¢„æœŸçš„æ–¹æ³•")
        print(f"[éªŒè¯] æ¨¡å‹å¯¹è±¡å±æ€§: {dir(asr_model)[:10]}...")
except Exception as ve:
    print(f"[éªŒè¯] ASRåŠŸèƒ½éªŒè¯å¼‚å¸¸: {ve}")
    print("[éªŒè¯] ä½†æ¨¡å‹å·²åŠ è½½ï¼Œç»§ç»­å¯åŠ¨æœåŠ¡...")

print("model loaded")

# ğŸš€ æé€Ÿå“åº”ä¼˜åŒ–é…ç½®
param_dict = {
    # âœ… å¼€å¯ï¼ˆä¸å½±å“é€Ÿåº¦ï¼‰
    "use_itn": True,              # æ•°å­—å½’ä¸€åŒ–ï¼šä¸€åƒäºŒç™¾ä¸‰åå››â†’1234
    "sentence_timestamp": True,    # å¥å­æ—¶é—´æˆ³ï¼šè¿”å›æ¯å¥è¯çš„æ—¶é—´
    
    # âŒ ä¸å¼€å¯ï¼ˆå½±å“é€Ÿåº¦ï¼‰
    "word_timestamp": False,       # è¯çº§æ—¶é—´æˆ³ï¼šä¸éœ€è¦
    
    # ğŸ¯ æ‰¹é‡å¤§å°ä¼˜åŒ–
    "batch_size": 1,               # å•å¥å¤„ç†ï¼Œé™ä½å»¶è¿Ÿ
}

# ä½¿ç”¨è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç›¸å¯¹è·¯å¾„
script_dir = os.path.dirname(os.path.abspath(__file__))
hotword_path = os.path.join(script_dir, "data", "hotword.txt")
os.makedirs(os.path.dirname(hotword_path), exist_ok=True)  # åˆ›å»ºç›®å½•

try:
    with open(hotword_path, "r", encoding="utf-8") as f:
        lines = f.readlines()
        lines = [line.strip() for line in lines if line.strip()]  # è¿‡æ»¤ç©ºè¡Œ
    hotword = " ".join(lines)
    print(f"å·²åŠ è½½çƒ­è¯ï¼š{hotword}")
    param_dict["hotword"] = hotword
except Exception as e:
    print(f"åŠ è½½çƒ­è¯å¤±è´¥: {e}")
    # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªç©ºçš„çƒ­è¯æ–‡ä»¶
    if not os.path.exists(hotword_path):
        os.makedirs(os.path.dirname(hotword_path), exist_ok=True)
        with open(hotword_path, "w", encoding="utf-8") as f:
            f.write("çœ‹å‘—\nçœ‹å§\nçœ‹ä¸€ä¸‹\nçœ‹çœ‹\nä½ çœ‹\nä½ çœ‹å§\nä½ æ¥çœ‹\nä½ çœ‹ä¸€ä¸‹\nä½ è¿™æ ·çœ‹\nä½ æ…¢æ…¢çœ‹\nä½ å¿«ç‚¹çœ‹\nä½ å¿«çœ‹ä¸€ä¸‹\nçå¼€ä½ çš„çœ¼ç›\nåˆ«çœ‹äº†\né‚£ä½ åˆ«çœ‹äº†\né‚£å°±åˆ«çœ‹\né‚£å°±é—­ä¸Šçœ¼ç›\né—­çœ¼\nåˆ«çœ‹\n")
        print("å·²åˆ›å»ºé»˜è®¤çƒ­è¯æ–‡ä»¶")
    param_dict["hotword"] = ""

print(f"[ä¼˜åŒ–é…ç½®] use_itn={param_dict.get('use_itn')}, sentence_timestamp={param_dict.get('sentence_timestamp')}, batch_size={param_dict.get('batch_size')}")

websocket_users = {}
task_queue = asyncio.Queue()

async def ws_serve(websocket):
    """WebSocketå¤„ç†å‡½æ•° - é€‚é… websockets 16.0+ æ–°API"""
    global websocket_users
    # websockets 13.0+ ç§»é™¤äº†pathå‚æ•°ï¼Œéœ€è¦ä»websocketå¯¹è±¡è·å–
    try:
        path = websocket.request.path if hasattr(websocket, 'request') else "/"
    except:
        path = "/"
    
    user_id = id(websocket)
    websocket_users[user_id] = websocket
    print(f"[ASR_server] æ–°å®¢æˆ·ç«¯è¿æ¥: user_id={user_id}")
    try:
        async for message in websocket:
            print(f"[ASR_server] æ”¶åˆ°æ¶ˆæ¯: {message[:200] if isinstance(message, str) else f'bytes({len(message)})'}")
            if isinstance(message, str):
                try:
                    data = json.loads(message)
                    if 'url' in data:
                        print(f"[ASR_server] æ”¶åˆ°éŸ³é¢‘æ–‡ä»¶: {data['url']}")
                        await task_queue.put((websocket, data['url']))
                        print(f"[ASR_server] å·²åŠ å…¥å¤„ç†é˜Ÿåˆ—ï¼Œå½“å‰é˜Ÿåˆ—å¤§å°: {task_queue.qsize()}")
                    elif 'state' in data:
                        print(f"[ASR_server] çŠ¶æ€æ¶ˆæ¯: {data['state']}")
                except json.JSONDecodeError as e:
                    print(f"[ASR_server] JSONè§£æå¤±è´¥: {e}")
    except websockets.exceptions.ConnectionClosed as e:
        print(f"ğŸ”Œ [ASR_server] è¿æ¥å…³é—­: {e}")
    except Exception as e:
        print(f"âŒ [ASR_server] é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        print(f"[ASR_server] æ¸…ç†è¿æ¥: user_id={user_id}")
        if user_id in websocket_users:
            del websocket_users[user_id]
        try:
            await websocket.close()
        except:
            pass

async def _extract_voiceprint_features(audio_path: str) -> dict:
    """ğŸ”¥ SISIå£°çº¹è¯†åˆ«ç³»ç»Ÿ - åŸºäº3D-Speakerçš„ä¸“ä¸šå£°çº¹è¯†åˆ«
    å¢å¼ºï¼šVADç«¯ç‚¹è£å‰ª + æœ€çŸ­æœ‰æ•ˆè¯­éŸ³é—¨é™(2.5s) + çŸ­å¥æ—©é€šè¿‡(â‰¥2.0sä¸”simâ‰¥0.45)
    åªä½œç”¨äºâ€œå½“æ¬¡è¯†åˆ«éŸ³é¢‘â€ï¼Œä¸ä¿®æ”¹åº•åº“ã€‚
    """
    try:
        import sys
        import os
        import numpy as np
        import tempfile
        import torch  # ä¸ç”¨torchaudioï¼Œç”¨soundfileæ›¿ä»£

        # æœ€çŸ­æœ‰æ•ˆè¯­éŸ³é—¨é™ä¸æ—©é€šè¿‡é˜ˆå€¼ï¼ˆæ–¹æ¡ˆBï¼‰
        EFFECTIVE_SEC_MIN = 2.0
        EARLY_PASS_SEC = 1.0   # åŸä¸º2.0ï¼šâ‰¥1.0ç§’å…è®¸çŸ­å¥æå‰åˆ¤å®š
        EARLY_PASS_SIM = 0.45
        HIGH_CONF_SIM = 0.65   # åŸä¸º0.70ï¼šæçŸ­ä½†åˆ†æ•°å¾ˆé«˜æ—¶ç›´è¿‡

        # ç®€å•çš„è·¯å¾„è®¾ç½®
        smartsisi_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))
        if smartsisi_root not in sys.path:
            sys.path.insert(0, smartsisi_root)

        print(f"[ASRå£°çº¹] ä½¿ç”¨SISIå£°çº¹è¯†åˆ«ç³»ç»Ÿ")

        from core.speaker_recognition import get_sisi_speaker_recognition

        # ç®€å•è·å–å®ä¾‹
        recognizer = get_sisi_speaker_recognition()

        print(f"[ASRå£°çº¹] å·²æ³¨å†Œæ¡£æ¡ˆæ•°é‡: {len(recognizer.speaker_profiles)}")
        print(f"[ASRå£°çº¹] å½“å‰é˜ˆå€¼: {recognizer.similarity_threshold}")

        # 1) ç”¨soundfileåŠ è½½éŸ³é¢‘ï¼Œé¿å…torchcodecé—®é¢˜
        import soundfile as sf
        audio_data, sr = sf.read(audio_path)
        if len(audio_data.shape) > 1:
            audio_data = audio_data.mean(axis=1)  # è½¬å•å£°é“
        w = torch.from_numpy(audio_data).float().unsqueeze(0)
        
        # VADç«¯ç‚¹è£å‰ªï¼ˆèƒ½é‡é˜ˆå€¼æ³•ï¼‰å¹¶ç»Ÿè®¡æœ‰æ•ˆè¯­éŸ³æ—¶é•¿
        e = (w**2).mean(dim=0)
        thr = e.mean() * 0.15  # æ”¾å®½é˜ˆå€¼ï¼Œé¿å…è¿‡åº¦ä¸¢å¸§
        mask = e > thr
        voiced_sec_est = float(mask.sum() / sr)
        audio_for_spk = audio_path
        trimmed_sec = 0.0
        if mask.any():
            idx = torch.where(mask)[0]
            w2 = w[:, idx[0]:idx[-1] + 1]
            trimmed_sec = float(w2.shape[1] / sr)
            fd, trimmed = tempfile.mkstemp(suffix='.wav'); os.close(fd)
            sf.write(trimmed, w2.squeeze().numpy(), sr)
            audio_for_spk = trimmed
            print(f"[ASRå£°çº¹] æœ‰æ•ˆè¯­éŸ³(ä¼°è®¡): {voiced_sec_est:.2f}s | è£å‰ªåè¿ç»­æ®µ: {trimmed_sec:.2f}s")
        else:
            print(f"[ASRå£°çº¹] æœ‰æ•ˆè¯­éŸ³(ä¼°è®¡): {voiced_sec_est:.2f}s | æ— æ³•è£å‰ªï¼Œä½¿ç”¨åŸéŸ³é¢‘")
        # å°†åˆ¤å®šä¾æ®æ”¹ä¸ºâ€œè¿ç»­æœ‰æ•ˆæ®µæ—¶é•¿â€ï¼Œæ›´ç¬¦åˆç›´è§‰
        effective_sec = trimmed_sec if trimmed_sec > 0 else voiced_sec_est

        # 2) é¢„ä¼°Topç›¸ä¼¼åº¦ï¼ˆç”¨äºçŸ­å¥æ—©é€šè¿‡ï¼‰
        te = recognizer._extract_embedding(audio_for_spk)
        sim_top = 0.0
        if te is not None:
            te = te / np.linalg.norm(te)
            for sid in recognizer.speaker_profiles:
                ef = os.path.join(recognizer.cache_dir, f"{sid}_embedding.npy")
                if os.path.exists(ef):
                    se = np.load(ef)
                    n = np.linalg.norm(se)
                    se = se / n if n > 0 else se
                    sim_top = max(sim_top, float(np.dot(te, se)))
        print(f"[ASRå£°çº¹] é¢„ä¼°Topç›¸ä¼¼åº¦: {sim_top:.3f}")

        # 3) åˆ¤å®šç­–ç•¥ï¼ˆæ–¹æ¡ˆBï¼‰ï¼š
        #    - é«˜åˆ†çŸ­å¥ç›´è¿‡ï¼šsim_top>=0.65
        #    - æˆ– çŸ­å¥æ—©é€šè¿‡ï¼šeffective_sec>=1.0 ä¸” sim_top>=0.45
        #    - å¦åˆ™è‹¥ >=2.0s åˆ™æ­£å¸¸è¯†åˆ«
        #    - å†å¦åˆ™ç»§ç»­ç´¯è®¡
        if sim_top >= HIGH_CONF_SIM:
            print("[ASRå£°çº¹] é«˜åˆ†çŸ­å¥ç›´è¿‡")
            result = recognizer.identify_speaker(audio_for_spk)
        elif effective_sec >= EARLY_PASS_SEC and sim_top >= EARLY_PASS_SIM:
            print("[ASRå£°çº¹] çŸ­å¥æ—©é€šè¿‡")
            result = recognizer.identify_speaker(audio_for_spk)
        elif effective_sec >= EFFECTIVE_SEC_MIN:
            result = recognizer.identify_speaker(audio_for_spk)
        else:
            print(f"[ASRå£°çº¹] â³ éœ€è¦æ›´å¤šè¯­éŸ³(ç»§ç»­ç´¯è®¡) | å½“å‰è¿ç»­æ®µ: {effective_sec:.2f}s")
            result = {
                "speaker_id": "unknown",
                "confidence": 0.0,
                "is_registered": False,
                "encounter_count": 0,
                "username": None,
                "real_name": None,
                "role": "guest",
                "hint": "need_more_speech"
            }

        print(f"[ASRå£°çº¹] SISIè¯†åˆ«ç»“æœ: {result}")

        # ğŸ¯ æ„å»ºç»Ÿä¸€èº«ä»½å¯¹è±¡ï¼ˆSSOTï¼‰
        is_registered = result.get("is_registered", False)
        speaker_id = result.get("speaker_id", "unknown")
        username = result.get("username") or result.get("real_name")
        confidence = result.get("confidence", 0.0)

        # ç»Ÿä¸€èº«ä»½æ ‡ç­¾ï¼šownerï¼ˆå·²æ³¨å†Œä¸”ç½®ä¿¡åº¦é«˜ï¼‰æˆ– stranger
        if is_registered and confidence >= recognizer.similarity_threshold:
            identity_label = "owner"
            user_id = speaker_id
            display_name = username or "å·²æ³¨å†Œç”¨æˆ·"
        else:
            identity_label = "stranger"
            user_id = "stranger"
            display_name = "é™Œç”Ÿäºº"
            username = None

        return {
            # ç»Ÿä¸€èº«ä»½å¯¹è±¡ï¼ˆæ‰€æœ‰ä¸‹æ¸¸æ¨¡å—çš„SSOTï¼‰
            "identity": {
                "label": identity_label,
                "user_id": user_id,
                "username": username,
                "display_name": display_name,
                "is_registered": is_registered,
                "confidence": confidence,
                "profile": {"gender": "male", "age": 30} if identity_label == "owner" else None
            },
            # ç¯å¢ƒæ„ŸçŸ¥æ•°æ®
            "env": {
                "effective_sec": effective_sec,
                "sim_top": sim_top,
                "audio_file": audio_path
            },
            # å…¼å®¹æ—§æ ¼å¼ï¼ˆé€æ­¥åºŸå¼ƒï¼‰
            "speaker_id": speaker_id,
            "role": result.get("role", "guest"),
            "note": "SISIå£°çº¹è¯†åˆ«ç³»ç»Ÿ"
        }

    except Exception as e:
        print(f"[ASRå£°çº¹] âŒ SISIå£°çº¹è¯†åˆ«å¤±è´¥: {e}")
        import traceback
        print(f"[ASRå£°çº¹] è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return {"error": str(e), "speaker_id": "unknown", "confidence": 0.0}

async def worker():
    print("[ASR_server] Workerå¯åŠ¨ï¼Œç­‰å¾…å¤„ç†ä»»åŠ¡...")
    while True:
        websocket = None
        url = None
        try:
            print("[ASR_server] Workerç­‰å¾…ä»»åŠ¡...")
            websocket, url = await task_queue.get()
            print(f"[ASR_server] Workerå–å‡ºä»»åŠ¡: {url}")
            print(f"[ASR_server] å‡†å¤‡è°ƒç”¨process_wav_file...")
            # æ— è®ºè¿æ¥çŠ¶æ€å¦‚ä½•éƒ½å¤„ç†éŸ³é¢‘
            await process_wav_file(websocket, url)
            print(f"[ASR_server] process_wav_fileå®Œæˆ")
        except Exception as e:
            print(f"[ASR_server] Workerå¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
        finally:
            print(f"[ASR_server] Workerä»»åŠ¡å®Œæˆï¼Œæ ‡è®°task_done")
            task_queue.task_done()

async def process_wav_file(websocket, url):
    """å‡çº§ç‰ˆï¼šæ”¯æŒå®Œæ•´éŸ³é¢‘ä¸Šä¸‹æ–‡åˆ†æ"""
    wav_path = url
    print(f"[ASR_server] å¼€å§‹å¤„ç†éŸ³é¢‘: {wav_path}")
    try:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(wav_path):
            print(f"âŒ [ASR_server] éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {wav_path}")
            return
        
        print(f"[ASR_server] æ–‡ä»¶å­˜åœ¨ï¼Œå¤§å°: {os.path.getsize(wav_path)} bytes")
        
        # æ ¹æ®é…ç½®ä½¿ç”¨ä¸åŒçš„ASRæ¨¡å‹
        print(f"[ASR_server] è°ƒç”¨{asr_mode.upper()}æ¨¡å‹...")
        
        if asr_mode == "funasr":
            # FunASR Paraformer è°ƒç”¨æ–¹å¼ï¼ˆæé€Ÿä¼˜åŒ–ï¼‰
            res = asr_model.generate(
                input=wav_path,
                batch_size_s=60,  # é™ä½æ‰¹é‡å¤§å°ï¼ŒåŠ å¿«å“åº”
                **param_dict
            )
        else:
            # SenseVoice è°ƒç”¨æ–¹å¼
            res = asr_model.generate(
                input=wav_path,
                is_final=True,
                **param_dict
            )
        
        print(f"[ASR_server] {asr_mode.upper()}è¿”å›: {res}")

        # websockets 16.0+ å…¼å®¹æ€§æ£€æŸ¥
        def is_ws_open(ws):
            try:
                return ws.state.name == "OPEN" if hasattr(ws, 'state') else ws.open
            except:
                return False

        if res and is_ws_open(websocket):
            result = res[0]

            # ğŸ¯ æ„å»ºå®Œæ•´çš„éŸ³é¢‘ä¸Šä¸‹æ–‡æ•°æ®ï¼ˆå…¼å®¹SenseVoiceè¿”å›æ ¼å¼ï¼‰
            if isinstance(result, dict):
                text = result.get('text', '')
            else:
                text = str(result)

            # å¹¶è¡Œå¤„ç†ï¼šSenseVoice + ä¸“ä¸šå£°çº¹è¯†åˆ«ï¼ˆä½¿ç”¨çº¿ç¨‹æ± ï¼‰
            print("[ä¸»äº¤äº’] å¼€å§‹SenseVoice + å£°çº¹å¹¶è¡Œå¤„ç†")

            # SenseVoiceå¤„ç†å‡½æ•°ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
            def process_sensevoice_sync():
                """å¤„ç†SenseVoiceç»“æœï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼Œç”¨äºçº¿ç¨‹æ± ï¼‰"""
                print("[ä¸»äº¤äº’] SenseVoiceå¤„ç†å¼€å§‹")
                sensevoice_data = {
                    "text": text,
                    "has_bgm": '<|BGM|>' in text,
                    "emotion": "neutral",
                    "language": "zh" if '<|zh|>' in text else "unknown"
                }

                # æ¸…ç†SenseVoiceæ ‡ç­¾ï¼ˆé€šé…æ¸…é™¤ä¸€åˆ‡ <|...|> æ ‡è®°ï¼‰
                import re
                clean_text = re.sub(r'<\|[^>]*\|>', '', text)
                sensevoice_data["clean_text"] = clean_text.strip()

                print(f"[ä¸»äº¤äº’] SenseVoiceå¤„ç†å®Œæˆ: {clean_text[:20]}...")
                print(f"[ASRæ–‡æœ¬] é•¿åº¦: {len(clean_text)} ç‰‡æ®µ: {clean_text[:60]}")
                return sensevoice_data

            # ğŸ¯ å£°çº¹è¯†åˆ«å‡½æ•°ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
            def extract_voiceprint_sync():
                """å£°çº¹è¯†åˆ«ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼Œç”¨äºçº¿ç¨‹æ± ï¼‰"""
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    result = loop.run_until_complete(_extract_voiceprint_features(wav_path))
                    return result
                finally:
                    loop.close()

            print("[ä¸»äº¤äº’] å¯åŠ¨å¹¶è¡Œä»»åŠ¡: SenseVoice + å£°çº¹è¯†åˆ«")
            # çœŸæ­£çš„å¤šçº¿ç¨‹å¹¶è¡Œï¼ˆå‚è€ƒxiaozhiå®ç°ï¼‰
            try:
                with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
                    sensevoice_future = executor.submit(process_sensevoice_sync)
                    voiceprint_future = executor.submit(extract_voiceprint_sync)
                    
                    # ç­‰å¾…ä¸¤ä¸ªçº¿ç¨‹å®Œæˆ
                    try:
                        sensevoice_data = sensevoice_future.result(timeout=15)
                        print("[ä¸»äº¤äº’] SenseVoiceæ•°æ®æ­£å¸¸")
                    except Exception as e:
                        print(f"[ä¸»äº¤äº’] SenseVoiceå¤„ç†å¼‚å¸¸: {e}")
                        sensevoice_data = {"text": text, "has_bgm": False, "clean_text": text}
                    
                    try:
                        voiceprint_data = voiceprint_future.result(timeout=15)
                        print(f"[ä¸»äº¤äº’] å£°çº¹è¯†åˆ«æˆåŠŸ: {voiceprint_data.get('speaker_id', 'unknown')}")
                    except Exception as e:
                        print(f"[ä¸»äº¤äº’] å£°çº¹è¯†åˆ«å¼‚å¸¸: {e}")
                        voiceprint_data = {"speaker_id": "unknown", "confidence": 0.0}
                
                print("[ä¸»äº¤äº’] å¹¶è¡Œå¤„ç†å®Œæˆ")
            except Exception as e:
                print(f"[ä¸»äº¤äº’] çº¿ç¨‹æ± å¼‚å¸¸: {e}")
                sensevoice_data = {"text": text, "has_bgm": False, "clean_text": text}
                voiceprint_data = {"speaker_id": "unknown", "confidence": 0.0}

            print("[ä¸»äº¤äº’] å¼€å§‹æ„å»ºJSONæ•°æ®")
            audio_context = {
                "text": sensevoice_data["clean_text"],
                "sensevoice": sensevoice_data,
                "voiceprint": voiceprint_data,
                "confidence": 0.9,
                "timestamp": [],
                "audio_events": [],
                "file_path": wav_path
            }

            # ğŸ”¥ å‘é€å®Œæ•´çš„éŸ³é¢‘ä¸Šä¸‹æ–‡æ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰
            response_data = {
                "type": "audio_analysis",
                "text": audio_context["text"],
                "audio_context": audio_context
            }

            print("[ä¸»äº¤äº’] JSONæ•°æ®æ„å»ºå®Œæˆï¼Œå‘é€ç»™æ€æ€å¯¹è¯")
            await websocket.send(json.dumps(response_data, ensure_ascii=False))
            print("[ä¸»äº¤äº’] åªå‘é€JSONæ•°æ®ï¼Œé¿å…é‡å¤è§¦å‘")



    except Exception as e:
        print(f"âŒ [ASR_server] éŸ³é¢‘å¤„ç†å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        # å›é€€åˆ°åŸºç¡€ASR
        try:
            res = asr_model.generate(input=wav_path, is_final=True, **param_dict)
            def is_ws_open(ws):
                try:
                    return ws.state.name == "OPEN" if hasattr(ws, 'state') else ws.open
                except:
                    return False
            if res and 'text' in res[0] and is_ws_open(websocket):
                await websocket.send(res[0]['text'])
        except Exception as e2:
            print(f"âŒ [ASR_server] å›é€€ASRä¹Ÿå¤±è´¥: {e2}")
    finally:
        # ğŸ¯ ä¿®å¤ï¼šä¸åˆ é™¤éŸ³é¢‘æ–‡ä»¶ï¼Œè®©ä¸»ç¨‹åºç»Ÿä¸€æ¸…ç†
        # é¿å…éŸ³é¢‘åˆ†æå’ŒéŸ³ä¹è¯†åˆ«æ—¶æ–‡ä»¶å·²è¢«åˆ é™¤çš„é—®é¢˜
        pass  # æ–‡ä»¶ç”±main.pyçš„__clear_temp_files()ç»Ÿä¸€æ¸…ç†

async def main():
    print(f"[å¯åŠ¨] å¯åŠ¨FUNASR WebSocketæœåŠ¡...")
    print(f"[å¯åŠ¨] æœåŠ¡åœ°å€: {args.host}:{args.port}")
    print(f"[å¯åŠ¨] SenseVoiceæ¨¡å‹å·²å°±ç»ª")
    print(f"[å¯åŠ¨] çƒ­è¯å·²åŠ è½½: 20ä¸ª")
    print(f"[å¯åŠ¨] websocketsç‰ˆæœ¬: 16.0+ (æ–°API)")
    print("="*50)

    # websockets 13.0+ æ–°API: ä½¿ç”¨ async with æ¨¡å¼
    worker_task = asyncio.create_task(worker())
    
    async with websockets.serve(ws_serve, args.host, args.port, ping_interval=10) as server:
        print(f"[å¯åŠ¨] FUNASR WebSocketæœåŠ¡å¯åŠ¨æˆåŠŸ")
        print(f"[å¯åŠ¨] ç›‘å¬åœ°å€: ws://{args.host}:{args.port}")
        print(f"[å¯åŠ¨] ç­‰å¾…å®¢æˆ·ç«¯è¿æ¥...")
        print("="*50)
        
        try:
            await asyncio.Future()  # æ°¸ä¹…è¿è¡Œ
        except KeyboardInterrupt:
            print("\n[åœæ­¢] æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨å…³é—­æœåŠ¡...")
    
    worker_task.cancel()
    print("âœ… FUNASRæœåŠ¡å·²åœæ­¢")

if __name__ == "__main__":
    # ä½¿ç”¨ asyncio è¿è¡Œä¸»å‡½æ•°
    asyncio.run(main())
