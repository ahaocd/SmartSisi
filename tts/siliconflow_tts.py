import os
import json
import requests
import re
import time
import asyncio
import threading
from utils import util, config_util as cfg
from utils.pc_audio_stream import get_pc_stream

# å¯¼å…¥ç»Ÿä¸€çš„éŸ³é¢‘å·¥å…·
from utils.stream_util import AudioManagerUtil

def _write_pcm_to_pc_stream(pcm_data, sample_rate, channels, sample_width, frames_per_buffer=1024):
    if not pcm_data:
        return
    get_pc_stream().write_pcm(
        pcm_data,
        sample_rate=sample_rate,
        channels=channels,
        sample_width=sample_width,
        frames_per_buffer=frames_per_buffer,
    )

# æµå¼OPUS TTSå¼•æ“ï¼ˆå¯é€‰ï¼Œé™é»˜é™çº§ï¼‰
try:
    from .streaming_opus_tts import StreamingOpusTTS
    STREAMING_OPUS_AVAILABLE = True
except ImportError:
    STREAMING_OPUS_AVAILABLE = False

class SiliconFlowTTS:
    def __init__(self):
        self.api_key = cfg.siliconflow_api_key
        self.model = cfg.siliconflow_model
        self.voice_type = getattr(cfg, 'siliconflow_voice_type', None) or getattr(cfg, 'sisi_voice_uri', None)
        base_url = getattr(cfg, 'siliconflow_base_url', None)
        if base_url is None:
            base_url = "https://api.siliconflow.cn/v1"
        else:
            base_url = str(base_url).strip()
            if not base_url or base_url.lower() in ("none", "null", "nil"):
                base_url = "https://api.siliconflow.cn/v1"
        self.base_url = base_url
        self.__history_data = []

        # ğŸš€ åˆå§‹åŒ–æµå¼OPUS TTSå¼•æ“
        self.streaming_opus_tts = None
        if STREAMING_OPUS_AVAILABLE and self.api_key and self.voice_type:
            try:
                self.streaming_opus_tts = StreamingOpusTTS(
                    api_key=self.api_key,
                    voice_uri=self.voice_type,
                    debug=False
                )
                util.log(1, "[TTS] æµå¼OPUS TTSå¼•æ“åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                util.log(2, f"[TTS] æµå¼OPUS TTSå¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
                self.streaming_opus_tts = None

    def connect(self):
        """è¿æ¥æœåŠ¡"""
        if not self.api_key or not self.model or not self.voice_type:
            util.log(1, "[x] liusisié…ç½®ç¼ºå¤±ï¼Œè¯·æ£€æŸ¥system.confä¸­çš„siliconflowç›¸å…³é…ç½®")
            return False
        util.log(1, "liusisiå·²è¿æ¥")
        return True

    def _check_esp32_connection(self) -> bool:
        """æ£€æŸ¥ESP32è®¾å¤‡æ˜¯å¦è¿æ¥"""
        try:
            # æ£€æŸ¥ESP32æ˜¯å¦è¿æ¥
            import sys
            esp32_connected = False

            if 'esp32_liusisi.esp32_bridge' in sys.modules:
                esp32_bridge = sys.modules['esp32_liusisi.esp32_bridge']
                adapter = getattr(esp32_bridge, 'adapter_instance', None)

                if adapter and hasattr(adapter, 'clients') and adapter.clients:
                    # æ£€æŸ¥æ˜¯å¦æœ‰è¿æ¥çš„è®¾å¤‡
                    connected_devices = 0
                    for client_id in adapter.clients:
                        websocket = adapter.clients.get(client_id)
                        if websocket and not websocket.closed:
                            connected_devices += 1

                    if connected_devices > 0:
                        esp32_connected = True
                        util.log(1, f"[TTS] æ£€æµ‹åˆ°{connected_devices}ä¸ªESP32è®¾å¤‡è¿æ¥ï¼Œä½¿ç”¨å¹¶è¡Œæ¨¡å¼")
                    else:
                        util.log(1, f"[TTS] ESP32é€‚é…å™¨æ— æœ‰æ•ˆè®¾å¤‡è¿æ¥ï¼Œä½¿ç”¨PCæ¨¡å¼")
                else:
                    util.log(1, f"[TTS] ESP32é€‚é…å™¨æ— è®¾å¤‡è¿æ¥ï¼Œä½¿ç”¨PCæ¨¡å¼")
            else:
                util.log(1, f"[TTS] ESP32æ¡¥æ¥æ¨¡å—æœªåŠ è½½ï¼Œä½¿ç”¨PCæ¨¡å¼")

            return esp32_connected

        except Exception as e:
            util.log(2, f"[TTS] æ£€æŸ¥ESP32è¿æ¥å¤±è´¥: {e}")
            return False

    # ğŸ”¥ åˆ é™¤_try_direct_esp32_streamingæ–¹æ³•ï¼Œé¿å…é‡å¤æ’­æ”¾
    # æ‰€æœ‰éŸ³é¢‘ç»Ÿä¸€é€šè¿‡ESP32é€‚é…å™¨å¤„ç†

    # ğŸ”¥ åˆ é™¤_stream_wav_to_esp32_directæ–¹æ³•ï¼Œé¿å…é‡å¤æ’­æ”¾

    # ğŸ”¥ åˆ é™¤_send_opus_to_esp32_directæ–¹æ³•ï¼Œé¿å…é‡å¤æ’­æ”¾

    def _send_music_file_direct(self, music_file_path: str) -> bool:
        """ç›´å‘éŸ³ä¹æ–‡ä»¶åˆ°ESP32è®¾å¤‡"""
        try:
            util.log(1, f"[TTS] ğŸµ å¼€å§‹ç›´å‘éŸ³ä¹æ–‡ä»¶: {music_file_path}")

            # è·å–ESP32é€‚é…å™¨
            import importlib.util
            import os
            adapter_path = os.path.join(os.path.dirname(__file__), '..', 'esp32_liusisi', 'sisi.adapter.py')
            spec = importlib.util.spec_from_file_location("sisi_adapter", adapter_path)
            sisi_adapter = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(sisi_adapter)
            adapter = sisi_adapter.get_adapter_instance()

            if not adapter or not adapter.clients:
                util.log(2, f"[TTS] éŸ³ä¹ç›´å‘ï¼šæ— å¯ç”¨ESP32è®¾å¤‡")
                return False

            # è½¬æ¢éŸ³ä¹æ–‡ä»¶ä¸ºOPUSå¸§
            try:
                from esp32_liusisi.opus_helper import OpusConvertor
                # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨å•ä¾‹æ¨¡å¼ï¼Œé¿å…é‡å¤åˆå§‹åŒ–ç¼–ç å™¨
                if not hasattr(self, '_opus_converter'):
                    self._opus_converter = OpusConvertor()
                opus_helper = self._opus_converter
                opus_frames, duration = opus_helper.audio_to_opus_frames(music_file_path)
            except ImportError:
                util.log(2, f"[TTS] OpusHelperå¯¼å…¥å¤±è´¥")
                return False

            if not opus_frames:
                util.log(2, f"[TTS] éŸ³ä¹æ–‡ä»¶OPUSè½¬æ¢å¤±è´¥")
                return False

            util.log(1, f"[TTS] éŸ³ä¹æ–‡ä»¶OPUSè½¬æ¢å®Œæˆ: {len(opus_frames)}å¸§")

            # ç›´å‘åˆ°ESP32è®¾å¤‡
            music_name = os.path.splitext(os.path.basename(music_file_path))[0]
            success = self._send_opus_to_esp32_direct(opus_frames, f"ğŸµ {music_name}", adapter)

            if success:
                util.log(1, f"[TTS] âœ… éŸ³ä¹æ–‡ä»¶ç›´å‘æˆåŠŸ")
                return True
            else:
                util.log(2, f"[TTS] âŒ éŸ³ä¹æ–‡ä»¶ç›´å‘å¤±è´¥")
                return False

        except Exception as e:
            util.log(2, f"[TTS] éŸ³ä¹æ–‡ä»¶ç›´å‘å¼‚å¸¸: {e}")
            return False

    def _get_esp32_adapter(self):
        """è·å–ESP32é€‚é…å™¨å®ä¾‹"""
        try:
            # æ–¹æ³•1ï¼šä»sisi_booteræ¨¡å—è·å–
            try:
                from core import sisi_booter
                if hasattr(sisi_booter, 'esp32_adapter') and sisi_booter.esp32_adapter:
                    adapter = sisi_booter.esp32_adapter
                    if hasattr(adapter, 'clients'):
                        util.log(1, f"[TTS] ä»sisi_booterè·å–åˆ°ESP32é€‚é…å™¨")
                        return adapter
            except Exception as e:
                util.log(2, f"[TTS] ä»sisi_booterè·å–é€‚é…å™¨å¤±è´¥: {e}")

            # æ–¹æ³•2ï¼šä»å·²åŠ è½½çš„sisi_adapteræ¨¡å—è·å–
            try:
                import sys
                if 'sisi_adapter' in sys.modules:
                    sisi_adapter_module = sys.modules['sisi_adapter']
                    if hasattr(sisi_adapter_module, 'get_adapter_instance'):
                        adapter = sisi_adapter_module.get_adapter_instance()
                        if adapter and hasattr(adapter, 'clients'):
                            util.log(1, f"[TTS] ä»sisi_adapteræ¨¡å—è·å–åˆ°ESP32é€‚é…å™¨")
                            return adapter
                    elif hasattr(sisi_adapter_module, '_ADAPTER_INSTANCE') and sisi_adapter_module._ADAPTER_INSTANCE:
                        adapter = sisi_adapter_module._ADAPTER_INSTANCE
                        if hasattr(adapter, 'clients'):
                            util.log(1, f"[TTS] ä»sisi_adapterå…¨å±€å®ä¾‹è·å–åˆ°ESP32é€‚é…å™¨")
                            return adapter
            except Exception as e:
                util.log(2, f"[TTS] ä»sisi_adapteræ¨¡å—è·å–é€‚é…å™¨å¤±è´¥: {e}")

            # æ–¹æ³•3ï¼šä»å·²åŠ è½½çš„æ¨¡å—ä¸­æŸ¥æ‰¾é€‚é…å™¨å®ä¾‹
            try:
                import sys
                for module_name, module in sys.modules.items():
                    if 'sisi' in module_name.lower() and 'adapter' in module_name.lower():
                        if hasattr(module, '_ADAPTER_INSTANCE') and module._ADAPTER_INSTANCE:
                            adapter = module._ADAPTER_INSTANCE
                            if hasattr(adapter, 'clients'):
                                util.log(1, f"[TTS] ä»æ¨¡å— {module_name} è·å–åˆ°ESP32é€‚é…å™¨")
                                return adapter
            except Exception as e:
                util.log(2, f"[TTS] ä»å·²åŠ è½½æ¨¡å—è·å–é€‚é…å™¨å¤±è´¥: {e}")

            util.log(2, f"[TTS] æœªæ‰¾åˆ°ESP32é€‚é…å™¨å®ä¾‹")
            return None
        except Exception as e:
            util.log(2, f"[TTS] è·å–ESP32é€‚é…å™¨å¼‚å¸¸: {e}")
            return None

    def _stream_to_esp32_devices(self, params, esp32_adapter):
        """è®¾å¤‡ä¼˜å…ˆæµå¼æ’­æ”¾ï¼šå®æ—¶å‘é€TTSæµåˆ°ESP32è®¾å¤‡"""
        try:
            util.log(1, f"[TTS] ğŸš€ å¼€å§‹è®¾å¤‡ä¼˜å…ˆæµå¼æ’­æ”¾")

            # å‘é€TTSè¯·æ±‚
            response = self.__send_request("audio/speech", params, timeout=30)
            if not response:
                util.log(2, f"[TTS] æµå¼TTSè¯·æ±‚å¤±è´¥")
                return None

            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä½¿ç”¨æµå¼PCMç¼–ç ï¼Œä¿æŒç¼–ç å™¨çŠ¶æ€
            # é‡ç½®ç¼–ç å™¨çŠ¶æ€ä»¥ç¡®ä¿æ–°ä¼šè¯å¹²å‡€
            opus_helper.reset_encoder()

            # ğŸ”¥ è®¾å¤‡ä¼˜å…ˆæµå¼æ’­æ”¾ï¼šè¾¹æ¥æ”¶è¾¹è½¬æ¢è¾¹å‘é€
            util.log(1, f"[TTS] ğŸš€ å¼€å§‹è®¾å¤‡ä¼˜å…ˆæµå¼æ’­æ”¾ï¼ˆæŒä¹…ç¼–ç å™¨æ¨¡å¼ï¼‰...")

            # é€šçŸ¥è®¾å¤‡å¼€å§‹æ’­æ”¾
            self._notify_devices_tts_start(esp32_adapter)

            try:
                # æ”¶é›†æ‰€æœ‰PCMæ•°æ®
                complete_pcm = bytearray()
                chunk_count = 0
                sent_frames = []

                # æµå¼æ¥æ”¶å¹¶å®æ—¶å¤„ç†
                for chunk in response.iter_content(chunk_size=3200):  # ç²¾ç¡®åŒ¹é…100ms PCMæ•°æ®
                    if chunk:
                        chunk_count += 1

                        # ğŸ”¥ å…³é”®ï¼šç›´æ¥å¤„ç†PCMæ•°æ®æµï¼Œä¿æŒç¼–ç å™¨è¿ç»­æ€§
                        # å‡è®¾siliconflowè¿”å›çš„æ˜¯16kHz PCMæ•°æ®
                        pcm_data = chunk

                        # å¦‚æœæ˜¯WAVæ ¼å¼ï¼Œéœ€è¦è·³è¿‡44å­—èŠ‚å¤´éƒ¨ï¼ˆåªåœ¨ç¬¬ä¸€ä¸ªchunkï¼‰
                        if chunk_count == 1 and len(chunk) > 44:
                            # æ£€æŸ¥WAVå¤´éƒ¨æ ‡å¿—
                            if chunk[:4] == b'RIFF' and chunk[8:12] == b'WAVE':
                                util.log(1, f"[TTS] æ£€æµ‹åˆ°WAVå¤´éƒ¨ï¼Œè·³è¿‡44å­—èŠ‚")
                                pcm_data = chunk[44:]
                            else:
                                pcm_data = chunk

                        # ä½¿ç”¨æµå¼ç¼–ç ï¼ˆä¿æŒç¼–ç å™¨çŠ¶æ€ï¼‰
                        opus_frames = opus_helper.encode_pcm_stream(pcm_data, end_of_stream=False)

                        # ç«‹å³å‘é€æ–°ç”Ÿæˆçš„OPUSå¸§
                        if opus_frames:
                            self._send_opus_frames_async(opus_frames, esp32_adapter)
                            sent_frames.extend(opus_frames)
                            util.log(1, f"[TTS] å®æ—¶å‘é€ {len(opus_frames)} OPUSå¸§ (chunk #{chunk_count})")

                        # ç´¯ç§¯PCMæ•°æ®ç”¨äºä¿å­˜æ–‡ä»¶
                        complete_pcm.extend(pcm_data)

                # å¤„ç†æœ€åçš„å‰©ä½™æ•°æ®
                util.log(1, f"[TTS] æµå¼æ¥æ”¶å®Œæˆï¼Œæ€»è®¡ {chunk_count} ä¸ªchunkï¼Œ{len(complete_pcm)} å­—èŠ‚PCM")

                # åˆ·æ–°ç¼–ç å™¨ç¼“å†²åŒºï¼Œå¤„ç†å‰©ä½™æ•°æ®
                final_frames = opus_helper.encode_pcm_stream(b'', end_of_stream=True)
                if final_frames:
                    self._send_opus_frames_async(final_frames, esp32_adapter)
                    sent_frames.extend(final_frames)
                    util.log(1, f"[TTS] å‘é€æœ€å {len(final_frames)} OPUSå¸§")

                # é€šçŸ¥è®¾å¤‡æ’­æ”¾ç»“æŸ
                self._notify_devices_tts_stop(esp32_adapter)

                # ä¿å­˜å®Œæ•´éŸ³é¢‘æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
                if complete_pcm:
                    import wave
                    final_wav_path = os.path.join("samples", f"output_{int(time.time())}.wav")
                    with wave.open(final_wav_path, 'wb') as wav_file:
                        wav_file.setnchannels(1)  # å•å£°é“
                        wav_file.setsampwidth(2)  # 16bit
                        wav_file.setframerate(16000)  # 16000Hz
                        wav_file.writeframes(bytes(complete_pcm))

                    util.log(1, f"[TTS] âœ… æµå¼æ’­æ”¾å®Œæˆ: æ€»è®¡ {len(sent_frames)} å¸§, æ–‡ä»¶ä¿å­˜åˆ°: {final_wav_path}")
                    return final_wav_path
                else:
                    util.log(1, f"[TTS] âœ… æµå¼æ’­æ”¾å®Œæˆ: æ€»è®¡ {len(sent_frames)} å¸§")
                    return "STREAMING_COMPLETED"

            except Exception as stream_error:
                util.log(2, f"[TTS] æµå¼å¤„ç†å¼‚å¸¸: {stream_error}")
                # é€šçŸ¥è®¾å¤‡åœæ­¢æ’­æ”¾
                self._notify_devices_tts_stop(esp32_adapter)
                return None

        except Exception as e:
            util.log(2, f"[TTS] è®¾å¤‡ä¼˜å…ˆæµå¼æ’­æ”¾å¼‚å¸¸: {e}")
            return None

    def _send_opus_frames_async(self, opus_frames, esp32_adapter):
        """ç»Ÿä¸€é€šè·¯ï¼šä¸å†ç›´æ¥å†™socketï¼Œäº¤ç”±AudioOutputManager/é€‚é…å™¨å¤„ç†"""
        try:
            # å°†å¸§äº¤ç»™éŸ³é¢‘ç®¡ç†å™¨ï¼Œç”±é€‚é…å™¨çš„ data_callback ç»Ÿä¸€å…¥é˜Ÿå‘é€
            from esp32_liusisi.sisi_audio_output import AudioOutputManager
            audio_manager = AudioOutputManager.get_instance()
            if not audio_manager:
                util.log(2, f"[TTS] æœªæ‰¾åˆ°éŸ³é¢‘è¾“å‡ºç®¡ç†å™¨å®ä¾‹ï¼Œè·³è¿‡ç›´å‘")
                return
            # åˆå¹¶ä¸ºè¿ç»­PCMè½¬å‘ç”±ç°æœ‰æµå¼è·¯å¾„å¤„ç†ï¼›æ­¤å¤„ä¸å†å•ç‹¬ç›´å‘OPUSå¸§
            util.log(1, f"[TTS] ç»Ÿä¸€é€šè·¯å·²å¯ç”¨ï¼šè·³è¿‡ç›´å‘OPUSå¸§ï¼Œäº¤ç”±é€‚é…å™¨å‘é€")
        except Exception as e:
            util.log(2, f"[TTS] ç»Ÿä¸€é€šè·¯è½¬äº¤å¤±è´¥: {e}")

    def _notify_devices_tts_start(self, esp32_adapter):
        """ç»Ÿä¸€é€šè·¯ï¼šå¼€å§‹/åœæ­¢æ§åˆ¶äº¤ç”±é€‚é…å™¨è‡ªèº«ï¼Œä¸åœ¨TTSå±‚ç›´å‘"""
        util.log(1, "[TTS] ç»Ÿä¸€é€šè·¯ï¼šè·³è¿‡TTS startç›´å‘ï¼Œç”±é€‚é…å™¨ç»Ÿä¸€æ§åˆ¶")



    def _notify_devices_tts_stop(self, esp32_adapter):
        """ç»Ÿä¸€é€šè·¯ï¼šå¼€å§‹/åœæ­¢æ§åˆ¶äº¤ç”±é€‚é…å™¨è‡ªèº«ï¼Œä¸åœ¨TTSå±‚ç›´å‘"""
        util.log(1, "[TTS] ç»Ÿä¸€é€šè·¯ï¼šè·³è¿‡TTS stopç›´å‘ï¼Œç”±é€‚é…å™¨ç»Ÿä¸€æ§åˆ¶")

    def _real_streaming_playback(self, params, esp32_adapter):
        """ğŸ”¥ çœŸæ­£æµå¼æ’­æ”¾ï¼šç›´æ¥è½¬å‘WAVæµåˆ°éŸ³é¢‘ç®¡ç†å™¨"""
        try:
            util.log(1, f"[TTS] ğŸš€ å¼€å§‹çœŸæ­£æµå¼æ’­æ”¾ï¼ˆå®Œæ•´è½¬å‘ï¼‰")

            # ä½¿ç”¨WAVæ ¼å¼
            stream_params = params.copy()
            stream_params['response_format'] = 'wav'
            stream_params['sample_rate'] = 16000  # æ”¹ä¸º16kHzé‡‡æ ·ç‡ï¼Œä¸è®¾å¤‡ç«¯é…ç½®ä¿æŒä¸€è‡´

            # å‘é€æµå¼è¯·æ±‚
            response = self.__send_request("audio/speech", stream_params, timeout=30)
            if not response:
                util.log(2, f"[TTS] æµå¼è¯·æ±‚å¤±è´¥")
                return None

            # è·å–éŸ³é¢‘ç®¡ç†å™¨
            audio_manager = None
            try:
                from esp32_liusisi.sisi_audio_output import AudioOutputManager
                audio_manager = AudioOutputManager.get_instance()
                if not audio_manager:
                    util.log(2, f"[TTS] æœªæ‰¾åˆ°éŸ³é¢‘è¾“å‡ºç®¡ç†å™¨å®ä¾‹")
                    return None
            except Exception as e:
                util.log(2, f"[TTS] è·å–éŸ³é¢‘ç®¡ç†å™¨å¤±è´¥: {e}")
                return None

            # æ ¸å¿ƒä¿®å¤ï¼šç›´æ¥è½¬å‘æ‰€æœ‰æ•°æ®ï¼Œè®©éŸ³é¢‘ç®¡ç†å™¨å¤„ç†
            priority = 5
            chunk_count = 0
            total_bytes = 0
            wav_header_processed = False  # æ ‡è®°æ˜¯å¦å·²å¤„ç†WAVå¤´éƒ¨
            header_buffer = bytearray()  # ç”¨äºç´¯ç§¯å¤´éƒ¨æ•°æ®

            util.log(1, f"[TTS] ğŸŒŠ å¼€å§‹è½¬å‘WAVæµ")

            # æ”¹è¿›ï¼šä½¿ç”¨æ›´å°çš„å—å¤§å°ä»¥æé«˜å®æ—¶æ€§
            for network_chunk in response.iter_content(chunk_size=1024):  # æ”¹ä¸º1024å­—èŠ‚å—å¤§å°
                if not network_chunk:
                    continue

                chunk_count += 1
                total_bytes += len(network_chunk)

                # ğŸ”¥ ä¿®å¤ï¼šæ­£ç¡®å¤„ç†WAVæ•°æ®æµ
                if not wav_header_processed:
                    # ç´¯ç§¯æ•°æ®ä»¥æ£€æµ‹WAVå¤´éƒ¨
                    header_buffer.extend(network_chunk)
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„WAVå¤´éƒ¨ï¼ˆè‡³å°‘44å­—èŠ‚ï¼‰
                    if len(header_buffer) >= 44:
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«WAVå¤´éƒ¨ï¼ˆRIFFæ ‡è®°ï¼‰
                        if header_buffer[:4] == b'RIFF' and header_buffer[8:12] == b'WAVE':
                            # æ‰¾åˆ°WAVå¤´éƒ¨ï¼Œè·³è¿‡44å­—èŠ‚
                            pcm_data = header_buffer[44:]
                            wav_header_processed = True
                            util.log(1, f"[TTS] æ£€æµ‹åˆ°WAVå¤´éƒ¨ï¼Œå·²è·³è¿‡44å­—èŠ‚å¤´éƒ¨ï¼ŒPCMæ•°æ®å¤§å°: {len(pcm_data)} å­—èŠ‚")
                            
                            # å‘é€PCMæ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
                            if len(pcm_data) > 0:
                                audio_manager.add_stream_chunk(bytes(pcm_data), priority, is_final=False)
                        else:
                            # ä¸æ˜¯WAVæ ¼å¼ï¼Œå‘é€æ‰€æœ‰ç´¯ç§¯æ•°æ®
                            util.log(1, f"[TTS] æœªæ£€æµ‹åˆ°WAVæ ¼å¼ï¼Œå‘é€åŸå§‹æ•°æ®: {len(header_buffer)} å­—èŠ‚")
                            audio_manager.add_stream_chunk(bytes(header_buffer), priority, is_final=False)
                            wav_header_processed = True
                            
                        # æ¸…ç©ºç¼“å†²åŒº
                        header_buffer.clear()
                    elif chunk_count > 20:  # å¦‚æœç´¯ç§¯äº†å¤ªå¤šæ•°æ®ä»æœªæ‰¾åˆ°å¤´éƒ¨
                        # å¯èƒ½ä¸æ˜¯WAVæ ¼å¼ï¼Œå‘é€æ‰€æœ‰ç´¯ç§¯æ•°æ®
                        util.log(1, f"[TTS] æœªæ‰¾åˆ°WAVå¤´éƒ¨ï¼Œå‘é€ç´¯ç§¯æ•°æ®: {len(header_buffer)} å­—èŠ‚")
                        audio_manager.add_stream_chunk(bytes(header_buffer), priority, is_final=False)
                        wav_header_processed = True
                        header_buffer.clear()
                    # å¦åˆ™ç»§ç»­ç´¯ç§¯æ•°æ®ä»¥æ£€æµ‹å¤´éƒ¨
                else:
                    # å·²å¤„ç†å¤´éƒ¨ï¼Œç›´æ¥å‘é€åç»­æ•°æ®ï¼ˆPCMæ•°æ®ï¼‰
                    audio_manager.add_stream_chunk(network_chunk, priority, is_final=False)

                if chunk_count == 1:
                    util.log(1, f"[TTS] ğŸµ å¼€å§‹è½¬å‘æ•°æ®")
                elif chunk_count % 20 == 0:  # æ¯20å—è®°å½•ä¸€æ¬¡
                    util.log(1, f"[TTS] âœ… å·²è½¬å‘ {chunk_count} å—ï¼Œå…± {total_bytes} å­—èŠ‚")

            # å‘é€ç»“æŸæ ‡è®°
            if chunk_count > 0:
                audio_manager.add_stream_chunk(b'', priority, is_final=True)
                util.log(1, f"[TTS] ğŸ è½¬å‘å®Œæˆï¼š{chunk_count} å—ï¼Œ{total_bytes} å­—èŠ‚")

            util.log(1, f"[TTS] âœ… æµå¼æ’­æ”¾å®Œæˆ")
            return "STREAMING_COMPLETED"
        except Exception as e:
            util.log(2, f"[TTS] æµå¼æ’­æ”¾å¼‚å¸¸: {e}")
            return None

    def __get_history(self, voice_name, style, text):
        """è·å–å†å²åˆæˆè®°å½•"""
        for data in self.__history_data:
            if data[0] == voice_name and data[1] == style and data[2] == text:
                return data[3]
        return None

    def __get_emotion_params(self, text):
        """æ ¹æ®æ–‡æœ¬ä¸­çš„è¡¨æƒ…ç¬¦å·è·å–è¯­éŸ³å‚æ•°"""
        params = {
            "speed": 1.0,
            "gain": 0.0
        }
        
        # ç®€å•çš„è¡¨æƒ…æ˜ å°„,ä½¿ç”¨æ›´æ¸©å’Œçš„å‚æ•°
        if "ğŸ˜ " in text:  # ç”Ÿæ°”
            params.update({
                "speed": 0.8,  # ç¨å¿«
                "gain": 5   # ç¨å¤§å£°
            })
        elif "âš¡" in text:  # å¿«é€Ÿ
            params.update({
                "speed": 1.2,  # å¿«é€Ÿ
                "gain": 0.0   # æ­£å¸¸éŸ³é‡
            })
        elif "ğŸŒ" in text:  # æ…¢é€Ÿ
            params.update({
                "speed": 0.9,  # ç¨æ…¢
                "gain": 0.0   # æ­£å¸¸éŸ³é‡
            })
        elif "ğŸ¤«" in text:  # æ‚„æ‚„è¯
            params.update({
                "speed": 1.5, # æ¥è¿‘æ­£å¸¸
                "gain": -5  # ç¨å°å£°
            })
            
        return params

    def _extract_text_and_params(self, text, style=None):
        """æå–æ–‡æœ¬å’Œå‚æ•°ï¼Œå¤ç”¨ç°æœ‰é€»è¾‘"""
        # æ£€æŸ¥å¹¶å¤„ç†å…ƒç»„ç±»å‹çš„è¾“å…¥
        if isinstance(text, tuple) and len(text) >= 2:
            extracted_text = text[0]
            tuple_style = text[1] if len(text) > 1 else None
            final_style = tuple_style or style
        else:
            extracted_text = str(text)
            final_style = style

        # å¤„ç†é£æ ¼å‚æ•°
        speed = 1.0
        gain = -5

        if final_style:
            if final_style == "fast":
                speed = 1.3
            elif final_style == "slow":
                speed = 0.8
            elif final_style == "gentle":
                gain = -8
            elif final_style == "excited":
                speed = 1.2
                gain = -3

        return extracted_text, speed, gain

    def to_sample(self, text, style=None, pc_stream_sink=None, skip_effects=False):
        """
        å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³å¹¶ä¿å­˜ä¸ºéŸ³é¢‘æ–‡ä»¶

        Args:
            text: æ–‡æœ¬å†…å®¹æˆ–(æ–‡æœ¬,é£æ ¼)å…ƒç»„
            style: è¯­éŸ³é£æ ¼ï¼Œå¯é€‰

        Returns:
            str: ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None
        """
        print(f"[TTS] to_sampleè¾“å…¥æ–‡æœ¬: {text}")
        print(f"[TTS] to_sampleè¾“å…¥style: {style}")

        try:
            util.log(1, f"[TTS-Silicon] å¼€å§‹å¤„ç†è¯­éŸ³åˆæˆè¯·æ±‚...")



            # æ£€æŸ¥å¹¶å¤„ç†å…ƒç»„ç±»å‹çš„è¾“å…¥
            if isinstance(text, tuple):
                util.log(1, f"[TTS-Silicon] å¤„ç†å…ƒç»„ç±»å‹è¾“å…¥: {text[0][:30] if text and len(text) > 0 else 'ç©º'}")
                # æå–å…ƒç»„ä¸­çš„æ–‡æœ¬éƒ¨åˆ†
                orig_text = text[0] if text and len(text) > 0 else ""
                text = orig_text
            
            # ç¡®ä¿textæ˜¯å­—ç¬¦ä¸²ç±»å‹
            if not isinstance(text, str):
                text = str(text) if text is not None else ""
                util.log(1, f"[TTS-Silicon] å°†éå­—ç¬¦ä¸²è¾“å…¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²: {text[:30]}")
            
            # å¤„ç†styleå‚æ•°2025å¹´3.26ä½¿ç”¨
            speed = 1  # é»˜è®¤é€Ÿåº¦
            gain = -2  # é»˜è®¤å¢ç›Š
            
            if style == "angry":
                speed = 0.9  # æ„¤æ€’è¯­æ°”ç•¥å¿«
                gain = -1     # éŸ³é‡å¢å¼º
                print(f"[TTS] æ£€æµ‹åˆ°angryé£æ ¼ï¼Œè®¾ç½®speed={speed}, gain={gain}")
            elif style == "whisper":
                speed = 0.9  # ä½è¯­è¯­æ°”ç•¥æ…¢
                gain = -8    # éŸ³é‡é™ä½
                print(f"[TTS] æ£€æµ‹åˆ°whisperé£æ ¼ï¼Œè®¾ç½®speed={speed}, gain={gain}")
            elif style == "gentle":
                speed = 1  # æ¸©æŸ”è¯­æ°”æ­£å¸¸é€Ÿåº¦
                gain = -2    # æ­£å¸¸éŸ³é‡
                print(f"[TTS] æ£€æµ‹åˆ°gentleé£æ ¼ï¼Œè®¾ç½®speed={speed}, gain={gain}")
            else:
                print(f"[TTS] æœªæ£€æµ‹åˆ°ç‰¹å®šé£æ ¼ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°speed={speed}, gain={gain}")

            # Android remote playback path: clamp gain to reduce speaker clipping risk.
            # Keep local PC playback unchanged.
            try:
                from utils.android_output_hub import get_android_output_hub

                if get_android_output_hub().has_output_device() and gain > -5:
                    util.log(1, f"[TTS] remote output detected, clamp gain {gain} -> -5")
                    gain = -5
            except Exception:
                pass
            
            # 2025.3.26 ç‰¹æ®Šæ ‡è®°å¤„ç†é€»è¾‘ - å¤„ç†[laughter]å’Œ[breath]æ ‡è®°
            extracted_text = text  # é»˜è®¤ä½¿ç”¨åŸå§‹æ–‡æœ¬
            
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ£€æµ‹æ ‡è®°ï¼ŒåŒæ—¶æ”¯æŒæœ‰ç©ºæ ¼å’Œæ— ç©ºæ ¼çš„æ ¼å¼
            has_laughter = re.search(r'\[\s*laughter\s*\]', text) is not None
            has_breath = re.search(r'\[\s*breath\s*\]', text) is not None
            
            if has_laughter or has_breath:
                # å¤‡ä»½åŸå§‹æ–‡æœ¬
                original_text = text
                
                # æ ¹æ®æ ‡è®°é€‰æ‹©åˆé€‚çš„æç¤ºå‰ç¼€
                if has_laughter and has_breath:
                    prefix = "Can you add laughter and breathing sounds?"
                elif has_laughter:
                    prefix = "Can you add laughter?"
                elif has_breath:
                    prefix = "Can you add breathing sounds?"
                
                # æ·»åŠ å‰ç¼€å’Œåˆ†éš”ç¬¦
                extracted_text = f"{prefix} <|endofprompt|>{original_text}"
                print(f"[TTS] æ£€æµ‹åˆ°ç‰¹æ®Šæ ‡è®°ï¼Œæ·»åŠ æç¤ºå‰ç¼€: {prefix}")
                util.log(1, f"[TTS] æ·»åŠ ç‰¹æ®Šæ ‡è®°å¤„ç†: {prefix}")
            
            # åˆå§‹åŒ–é»˜è®¤å‚æ•°
            
            # å¤„ç†å¯èƒ½æ˜¯JSONçš„æƒ…å†µ
            if isinstance(text, str) and "{" in text and "}" in text:
                # ç§»é™¤è§£ææ—¥å¿—ï¼Œå‡å°‘è¾“å‡º
                
                try:
                    # 1. å°è¯•æ ‡å‡†JSONè§£æ
                    clean_text = text.strip()
                    json_data = json.loads(clean_text)
                    
                    # æå–æ–‡æœ¬å†…å®¹
                    if "text" in json_data:
                        extracted_text = json_data["text"]
                    
                    # æå–å…¶ä»–å‚æ•°
                    if "tone" in json_data:
                        tone = json_data.get("tone")
                        if tone == "angry":
                            speed = 0.8
                            gain = 0.0  # æ„¤æ€’éŸ³é‡è°ƒæ•´ä¸º0.0
                        elif tone == "gentle":
                            if "å°å£°" in extracted_text or "æ‚„æ‚„" in extracted_text or "ğŸ¤«" in extracted_text:
                                speed = 0.9
                                gain = -5.0  # æ‚„æ‚„è¯éŸ³é‡è°ƒæ•´ä¸º-5.0
                    
                    # ç›´æ¥æå–é€Ÿåº¦å’ŒéŸ³é‡
                    if "speed" in json_data:
                        speed = float(json_data["speed"])
                    if "gain" in json_data:
                        gain = float(json_data["gain"])
                    
                except json.JSONDecodeError as e:
                    util.log(1, f"[TTS] æ ‡å‡†JSONè§£æå¤±è´¥: {str(e)}, å°è¯•æ­£åˆ™è¡¨è¾¾å¼æå–")
                    
                    # 2. å°è¯•ä½¿ç”¨å¤šç§æ­£åˆ™è¡¨è¾¾å¼æå–æ–‡æœ¬
                    # æå–å¼•å·ä¸­çš„æ–‡æœ¬ï¼Œå¤„ç†å„ç§æ ¼å¼çš„å¼•å·
                    patterns = [
                        r'"text"\s*[:ï¼š]\s*"([^"]+)"',  # æ ‡å‡†æ ¼å¼
                        r'"text"\s*[:ï¼š]\s*"([^"]*)"',  # ç©ºæ–‡æœ¬
                        r'"text"[:ï¼š]\s*[""]([^""]+)[""]',  # ä¸­æ–‡å¼•å·
                        r'"text"\s*[:ï¼š]\s*[""]([^"]*)[""]',  # ä¸­æ–‡å¼•å·åŒ…å›´ç©ºæ–‡æœ¬
                        r'text"?\s*[:ï¼š]\s*"([^"]+)"',  # å°‘å¼•å·æ ¼å¼
                        r'"?text"?\s*[:ï¼š]\s*"?([^",\n}{]+)',  # å®½æ¾åŒ¹é…
                    ]
                    
                    for pattern in patterns:
                        match = re.search(pattern, text)
                        if match:
                            extracted_text = match.group(1)
                            util.log(1, f"[TTS] ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–åˆ°æ–‡æœ¬: {extracted_text}")
                            break
                    
                    # 3. æ ¹æ®æ–‡æœ¬å†…å®¹åˆ¤æ–­æƒ…ç»ªå¹¶è®¾ç½®å‚æ•°
                    if extracted_text:
                        if "ğŸ˜ " in text or "angry" in text.lower() or "æ„¤æ€’" in text:
                            speed = 0.8
                            gain = 0.0  # æ„¤æ€’éŸ³é‡è°ƒæ•´ä¸º0.0
                        elif "ğŸ¤«" in text or "æ‚„æ‚„" in text or "å°å£°" in text or "gentle" in text.lower():
                            speed = 0.9
                            gain = -5.0  # æ‚„æ‚„è¯éŸ³é‡è°ƒæ•´ä¸º-5.0
            
            # å¦‚æœæ— æ³•æå–æ–‡æœ¬ï¼Œä½¿ç”¨åŸå§‹è¾“å…¥
            if not extracted_text:
                extracted_text = text
                util.log(1, f"[TTS] æœªèƒ½æå–æœ‰æ•ˆæ–‡æœ¬ï¼Œä½¿ç”¨åŸå§‹è¾“å…¥")
                
            # ç¡®ä¿extracted_textæ˜¯å­—ç¬¦ä¸²ç±»å‹
            if isinstance(extracted_text, tuple):
                # å¦‚æœæ˜¯å…ƒç»„ï¼Œæå–ç¬¬ä¸€ä¸ªå…ƒç´ ä½œä¸ºæ–‡æœ¬
                extracted_text = extracted_text[0] if len(extracted_text) > 0 else ""
                util.log(1, f"[TTS] å¤„ç†å…ƒç»„ç±»å‹çš„è¾“å…¥ï¼Œæå–æ–‡æœ¬: {extracted_text[:30]}...")
            
            # å°†éå­—ç¬¦ä¸²ç±»å‹è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            extracted_text = str(extracted_text) if extracted_text is not None else ""

            # ğŸ”¥ é‡è¦ï¼šä»…æ£€æµ‹æ˜¯å¦éœ€è¦éŸ³æ•ˆåˆ†å—ã€‚{}è§¦å‘å·²ç”±Coreç»Ÿä¸€å…¥å£å¤„ç†ï¼Œé¿å…é‡å¤ã€‚
            should_use_chunked = False
            if not skip_effects:
                try:
                    from utils.emotion_trigger import should_use_chunked_processing
                    should_use_chunked = should_use_chunked_processing(extracted_text)
                except Exception as e:
                    util.log(2, f"[TTS] åˆ†å—å¤„ç†æ£€æµ‹å¤±è´¥: {str(e)}")

            if should_use_chunked:
                util.log(1, "[TTS] æ£€æµ‹åˆ°éœ€è¦éŸ³æ•ˆåˆ†å—ï¼Œåˆ‡æ¢ OPUS æ’å…¥æµç¨‹")
                return self.process_with_opus_insertion(extracted_text, style=style)

            # è¿›ä¸€æ­¥æ¸…ç†æ–‡æœ¬ - ç§»é™¤JSONç›¸å…³å­—ç¬¦å’Œæ ¼å¼
            if extracted_text.startswith('{') and '}' in extracted_text:
                # è¿™å¯èƒ½ä»ç„¶æ˜¯JSONæ ¼å¼ï¼Œéœ€è¦è¿›ä¸€æ­¥æå–
                util.log(1, f"[TTS] è­¦å‘Šï¼šæå–çš„æ–‡æœ¬ä»ç„¶æ˜¯JSONæ ¼å¼ï¼Œå°è¯•è¿›ä¸€æ­¥æ¸…ç†")

                # ç§»é™¤æ‰€æœ‰JSONç¬¦å·å’Œå¼•å·
                cleaned_text = re.sub(r'[{}\[\]",:]', ' ', extracted_text)
                # ç§»é™¤å¤šä½™ç©ºæ ¼
                cleaned_text = re.sub(r'\s+', ' ', cleaned_text).strip()

                if cleaned_text:
                    extracted_text = cleaned_text
                    util.log(1, f"[TTS] æ¸…ç†åçš„æ–‡æœ¬: {extracted_text}")

            # ç§»é™¤Markdownæ ¼å¼å’Œç‰¹æ®Šæ ‡è®°
            extracted_text = re.sub(r'\*\*([^*]+)\*\*', r'\1', extracted_text)  # å»é™¤åŠ ç²—æ ‡è®°
            extracted_text = re.sub(r'#+ ', '', extracted_text)  # å»é™¤æ ‡é¢˜æ ‡è®°

            # å»é™¤éŸ³ä¹æŒ‡ä»¤å’Œå…¶ä»–æ–¹æ‹¬å·æ ‡è®° - TTSä¸è¯»å‡º
            extracted_text = re.sub(r'\[MUSIC:[^\]]*\]', '', extracted_text)  # å»é™¤éŸ³ä¹æŒ‡ä»¤
            extracted_text = re.sub(r'\[[^\]]*\]', '', extracted_text)  # å»é™¤å…¶ä»–æ–¹æ‹¬å·æ ‡è®°
            extracted_text = re.sub(r'\s+', ' ', extracted_text).strip()  # æ¸…ç†å¤šä½™ç©ºæ ¼
            
            # ç¡®ä¿æ–‡æœ¬ä¸ä¸ºç©º
            if not extracted_text or extracted_text.strip() == "":
                util.log(1, "[TTS] è­¦å‘Š: æå–çš„æ–‡æœ¬ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤æ–‡æœ¬")
                extracted_text = "æˆ‘æ²¡æœ‰ç†è§£ä½ çš„æ„æ€ï¼Œè¯·å†è¯´ä¸€æ¬¡ã€‚"
            
            # æ·»åŠ å¿…è¦çš„æ ‡ç‚¹
            if not extracted_text.endswith(('.', 'ã€‚', '!', 'ï¼', '?', 'ï¼Ÿ')):
                extracted_text += '...'
            
            # æ„å»ºè¯·æ±‚å‚æ•°
            params = {
                "model": self.model,
                "voice": self.voice_type,
                "input": extracted_text,  # ä½¿ç”¨å¤„ç†åçš„æ–‡æœ¬
                "response_format": "wav",  # ğŸ”¥ ä½¿ç”¨WAVæ ¼å¼ï¼Œé¿å…OPUS 48000Hzé™åˆ¶
                "sample_rate": 16000,     # ğŸ”¥ æ”¹ä¸º16000Hzï¼Œä¸è®¾å¤‡ç«¯é…ç½®ä¿æŒä¸€è‡´
                "stream": True,  # å¼€å¯æµå¼åˆæˆ
                "speed": speed,
                "gain": gain
            }
            
            # è®°å½•æœ€ç»ˆå‘é€çš„æ–‡æœ¬
            print(f"[TTS] æœ€ç»ˆå‘é€çš„æ–‡æœ¬: {extracted_text[:100]}...")
            util.log(1, f"[TTS] æœ€ç»ˆè¯·æ±‚å‚æ•°: speed={speed}, gain={gain}")

            # è®¾å¤‡ä¼˜å…ˆæµå¼æ’­æ”¾ï¼šç»Ÿä¸€OPUSå•é€šè·¯ï¼ˆä¸‹çº¿WAVç›´è½¬å‘ï¼‰
            try:
                util.log(1, f"[TTS] ğŸ¯ è®¾å¤‡ä¼˜å…ˆæµå¼æ’­æ”¾æ¨¡å¼ï¼ˆOPUSå•é€šè·¯ï¼‰")

                # æ£€æŸ¥æ˜¯å¦æœ‰ESP32è®¾å¤‡è¿æ¥
                esp32_adapter = self._get_esp32_adapter()
                if esp32_adapter and esp32_adapter.clients:
                    util.log(1, f"[TTS] æ£€æµ‹åˆ° {len(esp32_adapter.clients)} ä¸ªESP32è®¾å¤‡ï¼Œèµ°OPUSç¼–ç å®æ—¶å‘é€")

                    # ç»Ÿä¸€ï¼šæ‹‰å–éŸ³é¢‘æµï¼ˆwavï¼‰ï¼Œè½¬PCMâ†’ç»Ÿä¸€é˜Ÿåˆ—ï¼ˆç”±AudioOutputManagerå†…éƒ¨åšOPUSä¸BP3ï¼‰
                    response = self.__send_request("audio/speech", params, timeout=30)
                    if not response:
                        util.log(2, f"[TTS] æµå¼è¯·æ±‚å¤±è´¥")
                        return None

                    import struct
                    import audioop

                    def _parse_wav_header(data: bytes):
                        if len(data) < 44 or data[:4] != b'RIFF' or data[8:12] != b'WAVE':
                            return None
                        fmt_pos = data.find(b'fmt ')
                        if fmt_pos == -1:
                            return None
                        fmt_size = struct.unpack('<I', data[fmt_pos+4:fmt_pos+8])[0]
                        fmt_data = data[fmt_pos+8:fmt_pos+8+fmt_size]
                        if len(fmt_data) < 16:
                            return None
                        audio_format, channels, sample_rate, byte_rate, block_align, bits_per_sample = struct.unpack('<HHIIHH', fmt_data[:16])
                        data_pos = data.find(b'data')
                        if data_pos == -1:
                            return None
                        audio_data_start = data_pos + 8
                        return {
                            'channels': channels,
                            'sample_rate': sample_rate,
                            'bits_per_sample': bits_per_sample,
                            'block_align': block_align,
                            'audio_data_start': audio_data_start
                        }

                    from esp32_liusisi.sisi_audio_output import AudioOutputManager
                    aom = AudioOutputManager.get_instance()
                    if not aom:
                        util.log(2, f"[TTS] æœªæ‰¾åˆ°AudioOutputManagerå®ä¾‹")
                        return None

                    header_buf = bytearray()
                    wav_header = None
                    in_channels = None
                    in_rate = None
                    in_width = None
                    pcm_pending = bytearray()
                    ratecv_state = None

                    def _push_pcm(pcm_bytes: bytes, is_final: bool = False):
                        nonlocal pcm_pending, ratecv_state, in_channels, in_width, in_rate
                        if not pcm_bytes and not is_final:
                            return
                        pcm_pending.extend(pcm_bytes)
                        if in_channels and in_width and in_rate:
                            frame_size_in = in_channels * in_width
                            process_len = (len(pcm_pending) // frame_size_in) * frame_size_in
                            if process_len > 0:
                                to_process = bytes(pcm_pending[:process_len])
                                pcm_pending = pcm_pending[process_len:]

                                data_conv = to_process
                                # å£°é“è½¬å•å£°é“
                                if in_channels == 2:
                                    try:
                                        data_conv = audioop.tomono(data_conv, in_width, 0.5, 0.5)
                                    except Exception:
                                        step = in_channels * in_width
                                        data_conv = b''.join([to_process[i:i+in_width] for i in range(0, len(to_process), step)])
                                elif in_channels != 1:
                                    step = in_channels * in_width
                                    data_conv = b''.join([to_process[i:i+in_width] for i in range(0, len(to_process), step)])

                                # ä½å®½è½¬16bit
                                if in_width != 2:
                                    try:
                                        data_conv = audioop.lin2lin(data_conv, in_width, 2)
                                    except Exception:
                                        data_conv = b''

                                # é‡‡æ ·ç‡è½¬16k
                                if in_rate != 16000 and data_conv:
                                    try:
                                        data_conv, ratecv_state = audioop.ratecv(data_conv, 2, 1, in_rate, 16000, ratecv_state)
                                    except Exception:
                                        data_conv = b''

                                if data_conv:
                                    aom.add_stream_chunk(data_conv, priority=5, is_final=False)

                        if is_final:
                            # flushä½™é‡
                            if in_channels and in_width and in_rate and len(pcm_pending) > 0:
                                frame_size_in2 = in_channels * in_width
                                tail_len = (len(pcm_pending) // frame_size_in2) * frame_size_in2
                                if tail_len > 0:
                                    tail = bytes(pcm_pending[:tail_len])
                                    pcm_pending = pcm_pending[tail_len:]
                                    try:
                                        data_conv = tail
                                        if in_channels == 2:
                                            data_conv = audioop.tomono(data_conv, in_width, 0.5, 0.5)
                                        elif in_channels != 1:
                                            step = in_channels * in_width
                                            data_conv = b''.join([tail[i:i+in_width] for i in range(0, len(tail), step)])
                                        if in_width != 2:
                                            data_conv = audioop.lin2lin(data_conv, in_width, 2)
                                        if in_rate != 16000:
                                            data_conv, ratecv_state = audioop.ratecv(data_conv, 2, 1, in_rate, 16000, ratecv_state)
                                        if data_conv:
                                            aom.add_stream_chunk(data_conv, priority=5, is_final=False)
                                    except Exception:
                                        pass
                            aom.add_stream_chunk(b'', priority=5, is_final=True)

                    # æµå¼è¯»å–å¹¶é€å—é€å…¥ç»Ÿä¸€é˜Ÿåˆ—
                    chunk_count = 0
                    for net_chunk in response.iter_content(chunk_size=2048):
                        if not net_chunk:
                            continue
                        chunk_count += 1
                        if not wav_header:
                            header_buf.extend(net_chunk)
                            if len(header_buf) >= 44 and header_buf[:4] == b'RIFF' and header_buf[8:12] == b'WAVE':
                                info = _parse_wav_header(bytes(header_buf))
                                if info:
                                    in_channels = info['channels']
                                    in_rate = info['sample_rate']
                                    in_width = max(1, info['bits_per_sample'] // 8)
                                    # é¦–æ‰¹å»å¤´åçš„PCM
                                    if len(header_buf) > info['audio_data_start']:
                                        pcm_part = bytes(header_buf[info['audio_data_start']:])
                                        if pcm_part:
                                            _push_pcm(pcm_part, is_final=False)
                                    header_buf.clear()
                                    wav_header = info
                                continue
                            elif len(header_buf) >= 44:
                                # éæ ‡å‡†å¤´ï¼ŒæŒ‰åŸå§‹PCMå¤„ç†ï¼Œé»˜è®¤å‚æ•°
                                if in_channels is None:
                                    in_channels = 1
                                    in_rate = 16000
                                    in_width = 2
                                _push_pcm(bytes(header_buf), is_final=False)
                                header_buf.clear()
                                wav_header = {'channels': in_channels, 'sample_rate': in_rate, 'bits_per_sample': in_width*8, 'audio_data_start': 0}
                                continue
                            else:
                                continue
                        else:
                            _push_pcm(net_chunk, is_final=False)

                    # ç»“æŸ
                    _push_pcm(b'', is_final=True)

                    util.log(1, f"[TTS] âœ… OPUSå•é€šè·¯æµå¼æ’­æ”¾å®Œæˆ")
                    return "STREAMING_COMPLETED"
                else:
                    util.log(1, f"[TTS] æ— ESP32è®¾å¤‡è¿æ¥ï¼Œä½¿ç”¨PCæ’­æ”¾æ¨¡å¼")

                # ğŸ”„ PCæ’­æ”¾æ¨¡å¼ï¼ˆæ— è®¾å¤‡æ—¶çš„å¤‡ç”¨æ–¹æ¡ˆï¼‰
                max_retries = 3
                retry_count = 0

                pc_queue = None
                if pc_stream_sink is None:
                    try:
                        from utils.pc_stream_queue import get_pc_stream_queue
                        pc_queue = get_pc_stream_queue()
                        pc_stream_sink = pc_queue.enqueue_stream(label="tts")
                    except Exception:
                        pc_stream_sink = None
                use_pc_queue = pc_stream_sink is not None

                while retry_count < max_retries:
                    try:
                        # ä½¿ç”¨ç»Ÿä¸€çš„è¯·æ±‚æ–¹æ³•
                        response = self.__send_request(
                            "audio/speech",
                            params,
                            timeout=30  # å¢åŠ è¶…æ—¶æ—¶é—´ï¼Œç¡®ä¿å¤§æ–‡æœ¬ä¹Ÿèƒ½å¤„ç†
                        )

                        if not response:
                            retry_count += 1
                            util.log(1, f"[TTS] APIè¯·æ±‚å¤±è´¥ - é‡è¯• {retry_count}/{max_retries}")
                            time.sleep(1)  # ç­‰å¾…1ç§’åé‡è¯•
                            continue

                        # ç¡®ä¿æµå¼å‚æ•°è¢«æ­£ç¡®è®¾ç½®
                        if not response.headers.get('Transfer-Encoding') == 'chunked':
                            util.log(1, f"[TTS] è­¦å‘Šï¼šéæµå¼å“åº”ï¼Œå¯èƒ½ä¼šå¯¼è‡´å¤§æ–‡æœ¬å¤„ç†è¶…æ—¶")
                        
                        # ğŸ”¥ 2025-08-15 ä¿®å¤ï¼šå®ç°çœŸæ­£çš„å¹¶è¡Œæµå¼TTS
                        output_file = os.path.join("samples", f"output_{int(time.time())}.wav")
                        os.makedirs("samples", exist_ok=True)

                        # ğŸ”¥ åˆå§‹åŒ–PCå®æ—¶æ’­æ”¾å¤„ç†
                        # åˆå§‹åŒ– PC å®æ—¶æ’­æ”¾ç¼“å†²
                        complete_audio = b""
                        pc_audio_buffer = b""
                        chunk_count = 0
                        header_parsed = False
                        pcm_cfg = None

                        # å¢é‡é‡é‡‡æ ·åˆ° PC è¾“å‡º
                        import audioop
                        ratecv_state = None
                        pcm_pending = bytearray()

                        def _convert_pcm_chunk(raw, cfg):
                            nonlocal ratecv_state
                            if not raw or not cfg:
                                return b''
                            sample_rate, channels, sample_width = cfg
                            data_conv = raw
                            if channels == 2:
                                data_conv = audioop.tomono(data_conv, sample_width, 0.5, 0.5)
                            elif channels != 1:
                                step = channels * sample_width
                                data_conv = b''.join([data_conv[i:i+sample_width] for i in range(0, len(data_conv), step)])
                            if sample_width != 2:
                                try:
                                    data_conv = audioop.lin2lin(data_conv, sample_width, 2)
                                except Exception:
                                    data_conv = b''
                            if sample_rate != 16000 and data_conv:
                                try:
                                    data_conv, ratecv_state = audioop.ratecv(data_conv, 2, 1, sample_rate, 16000, ratecv_state)
                                except Exception:
                                    data_conv = b''
                            return data_conv

                        def _push_converted(data_conv):
                            if not data_conv:
                                return
                            pcm_pending.extend(data_conv)
                            while len(pcm_pending) >= 1024:
                                chunk_out = bytes(pcm_pending[:1024])
                                del pcm_pending[:1024]
                                if use_pc_queue:
                                    pc_stream_sink.push(chunk_out)
                                else:
                                    _write_pcm_to_pc_stream(
                                        chunk_out,
                                        sample_rate=16000,
                                        channels=1,
                                        sample_width=2,
                                    )

                        for chunk in response.iter_content(chunk_size=1024):  # 1KB åˆ†å—è¯»å–
                            if not chunk:
                                continue
                            complete_audio += chunk
                            pc_audio_buffer += chunk
                            chunk_count += 1

                            if not header_parsed and len(pc_audio_buffer) >= 44:
                                try:
                                    sample_rate = int.from_bytes(pc_audio_buffer[24:28], 'little')
                                    channels = int.from_bytes(pc_audio_buffer[22:24], 'little')
                                    sample_width = int.from_bytes(pc_audio_buffer[34:36], 'little') // 8
                                    header_parsed = True
                                    pcm_cfg = (sample_rate, channels, sample_width)
                                    util.log(1, f"[TTS] 2025-08-15 âœ… PCéŸ³é¢‘æµå‚æ•°: {sample_rate}Hz, {channels}ch")

                                    audio_data_start = pc_audio_buffer[44:]
                                    if audio_data_start:
                                        data_conv = _convert_pcm_chunk(audio_data_start, pcm_cfg)
                                        _push_converted(data_conv)
                                    pc_audio_buffer = b''
                                except Exception as e:
                                    util.log(2, f"[TTS] 2025-08-15 WAVå¤´è§£æå¤±è´¥: {str(e)}")

                            if header_parsed and pcm_cfg and len(pc_audio_buffer) >= 1024:
                                try:
                                    data_conv = _convert_pcm_chunk(pc_audio_buffer[:1024], pcm_cfg)
                                    _push_converted(data_conv)
                                    pc_audio_buffer = pc_audio_buffer[1024:]
                                except Exception as e:
                                    util.log(2, f"[TTS] 2025-08-15 PCæµå¤„ç†å¤±è´¥: {str(e)}")

                        if header_parsed and pcm_cfg and pc_audio_buffer:
                            try:
                                data_conv = _convert_pcm_chunk(pc_audio_buffer, pcm_cfg)
                                _push_converted(data_conv)
                                util.log(1, "[TTS] 2025-08-15 âœ… PCå°¾åŒ…å·²å¤„ç†")
                            except Exception as e:
                                util.log(2, f"[TTS] 2025-08-15 PCå°¾åŒ…å¤„ç†å¤±è´¥: {str(e)}")

                        if pcm_pending:
                            if use_pc_queue:
                                pc_stream_sink.push(bytes(pcm_pending))
                            else:
                                _write_pcm_to_pc_stream(
                                    bytes(pcm_pending),
                                    sample_rate=16000,
                                    channels=1,
                                    sample_width=2,
                                )
                            pcm_pending = bytearray()

                        if use_pc_queue:
                            try:
                                pc_stream_sink.finish()
                            except Exception:
                                pass

                        with open(output_file, "wb") as f:
                            f.write(complete_audio)
                            f.flush()
                            os.fsync(f.fileno())
                        
                        # éªŒè¯æ–‡ä»¶æ˜¯å¦æˆåŠŸåˆ›å»ºå¹¶å¯è®¿é—®
                        if os.path.exists(output_file) and os.path.getsize(output_file) > 0:
                            util.log(1, f"[TTS] ğŸ”Š å¹¶è¡ŒTTSå®Œæˆ: {output_file}")
                            util.log(1, f"[TTS] ğŸ“Š å¤„ç†ç»Ÿè®¡: {chunk_count}å—, æ€»å¤§å°: {len(complete_audio)}å­—èŠ‚")

                            # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„ï¼Œç¡®ä¿å…¶ä»–æ¨¡å—èƒ½æ­£ç¡®è®¿é—®
                            abs_output_file = os.path.abspath(output_file)

                            # âœ… å¹¶è¡Œå¤„ç†å®Œæˆï¼ŒPCå®æ—¶æ’­æ”¾+æ–‡ä»¶ä¿å­˜ï¼ˆè®¾å¤‡æ’­æ”¾ç»Ÿä¸€ç”±æ’­æ”¾é˜Ÿåˆ—çº¿ç¨‹å¤„ç†ï¼‰
                            util.log(1, f"[TTS] âœ… å¹¶è¡Œå¤„ç†å®Œæˆï¼ŒPCå®æ—¶æ’­æ”¾+æ–‡ä»¶ä¿å­˜")
                            return abs_output_file
                        else:
                            util.log(1, f"[TTS] âŒ éŸ³é¢‘æ–‡ä»¶åˆ›å»ºå¤±è´¥æˆ–ä¸ºç©º: {output_file}")
                            return None
                        
                    except Exception as e:
                        retry_count += 1
                        util.log(1, f"[TTS] è¯·æ±‚å¼‚å¸¸ï¼Œé‡è¯• {retry_count}/{max_retries}: {str(e)}")
                        if retry_count >= max_retries:
                            util.log(1, f"[TTS] é‡è¯•{max_retries}æ¬¡åä»å¤±è´¥")
                            return None
                        time.sleep(1)
                
                # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
                if retry_count >= max_retries:
                    util.log(1, f"[TTS] è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè¯·æ±‚å¤±è´¥")
                    return None
                
            except Exception as e:
                util.log(1, f"[TTS] æœªé¢„æœŸçš„å¼‚å¸¸: {str(e)}")
                import traceback
                util.log(1, f"[TTS] å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
                return None

        except Exception as e:
            util.log(1, f"[TTS] å¤„ç†è¯­éŸ³åˆæˆè¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            print(f"[TTS] é”™è¯¯: {str(e)}")
            return None

    def __send_request(self, endpoint, params, timeout=60):
        """å‘é€è¯·æ±‚åˆ°SiliconFlow API"""
        url = f"{self.base_url}/{endpoint}"
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # å¤„ç†ä»£ç†é…ç½®
        proxies = None
        if hasattr(cfg, 'proxy_config') and cfg.proxy_config:
            if cfg.proxy_config.startswith('http'):
                proxies = {
                    "http": cfg.proxy_config,
                    "https": cfg.proxy_config
                }
                util.log(1, f"[TTS] ä½¿ç”¨ä»£ç†: {cfg.proxy_config}")
        
        try:
            response = requests.post(
                url,
                headers=headers,
                json=params,
                proxies=proxies,
                timeout=timeout,
                stream=True
            )
            
            # é”™è¯¯å¤„ç†
            if response.status_code != 200:
                if response.status_code == 401:
                    util.log(1, f"[é”™è¯¯] APIè®¤è¯å¤±è´¥: æ— æ•ˆçš„tokenï¼Œè¯·æ£€æŸ¥system.confä¸­çš„siliconflow_api_keyæ˜¯å¦æ­£ç¡®")
                else:
                    util.log(1, f"[é”™è¯¯] APIè¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}")
                return None
                
            return response
        except requests.exceptions.RequestException as e:
            util.log(1, f"[é”™è¯¯] è¯·æ±‚å¼‚å¸¸: {str(e)}")
            return None

    def close(self):
        """å…³é—­è¿æ¥"""
        pass

    def generate_opening_audio(self, text):
        """ç”Ÿæˆå¼€åœºç™½éŸ³é¢‘å¹¶ç¼“å­˜"""
        util.log(1, f"å‡†å¤‡ç”Ÿæˆå¼€åœºç™½éŸ³é¢‘: {text}")
        file_url = f'./samples/sample-opening_{hash(text)}_opening.wav'
        
        # æ£€æŸ¥ç¼“å­˜
        if os.path.exists(file_url):
            util.log(1, f"æ‰¾åˆ°ç¼“å­˜çš„å¼€åœºç™½éŸ³é¢‘: {file_url}")
            return file_url

        # ç”ŸæˆéŸ³é¢‘
        return self.to_sample(text, style="opening")

    def process_text_with_sound_effects(self, text, **kwargs):
        """
        å¤„ç†å¸¦æœ‰éŸ³æ•ˆæ ‡è®°çš„æ–‡æœ¬ï¼Œæ”¯æŒåœ¨TTSä¸­æ’å…¥éŸ³æ•ˆ

        Args:
            text: å¸¦æœ‰éŸ³æ•ˆæ ‡è®°çš„æ–‡æœ¬ï¼Œå¦‚"å‰é¢{å—æ— é˜¿å¼¥é™€ä½›_ç”µéŸ³DJéŸ³æ•ˆ}åé¢"
            **kwargs: TTSåˆæˆå‚æ•°

        Returns:
            list: éŸ³é¢‘æ–‡ä»¶åˆ—è¡¨ï¼ŒæŒ‰é¡ºåºæ’­æ”¾ [(ç±»å‹, æ–‡ä»¶è·¯å¾„), ...]
        """
        import re
        from utils.emotion_trigger import EMOTION_TRIGGER_MAP

        # éŸ³æ•ˆæ ‡è®°æ­£åˆ™è¡¨è¾¾å¼
        effect_pattern = re.compile(r'(\{([A-Za-z0-9_\u4e00-\u9fff]+)\})')

        # åˆ†å‰²æ–‡æœ¬
        audio_files = []
        last_end = 0

        for match in effect_pattern.finditer(text):
            # å¤„ç†éŸ³æ•ˆå‰çš„æ–‡æœ¬
            if match.start() > last_end:
                text_before = text[last_end:match.start()].strip()
                if text_before:
                    # TTSåˆæˆ
                    tts_file = self.to_sample(text_before, **kwargs)
                    if tts_file:
                        audio_files.append(("tts", tts_file))

            # å¤„ç†éŸ³æ•ˆ
            effect_name = match.group(2)  # æå–éŸ³æ•ˆåç§°
            effect_config = EMOTION_TRIGGER_MAP.get(effect_name)

            if effect_config and effect_config.get("type") == "sound_effect":
                audio_file = effect_config.get("audio_file")
                if audio_file:
                    # æ„å»ºå®Œæ•´è·¯å¾„
                    import os
                    if not os.path.isabs(audio_file):
                        audio_file = os.path.abspath(audio_file)

                    if os.path.exists(audio_file):
                        audio_files.append(("effect", audio_file))
                        util.log(1, f"[TTSåˆ†å—] âœ… æ·»åŠ éŸ³æ•ˆ: {effect_name}")
                    else:
                        util.log(2, f"[TTSåˆ†å—] âŒ éŸ³æ•ˆæ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")

            last_end = match.end()

        # å¤„ç†æœ€åä¸€æ®µæ–‡æœ¬
        if last_end < len(text):
            text_after = text[last_end:].strip()
            if text_after:
                tts_file = self.to_sample(text_after, **kwargs)
                if tts_file:
                    audio_files.append(("tts", tts_file))

        util.log(1, f"[TTSåˆ†å—] å¤„ç†å®Œæˆï¼Œå…±{len(audio_files)}ä¸ªéŸ³é¢‘ç‰‡æ®µ")
        return audio_files

    def process_with_opus_insertion(self, text, **kwargs):
        """
        ä½¿ç”¨OPUSå¸§æ’å…¥æ–¹å¼å¤„ç†éŸ³æ•ˆ - çœŸæ­£çš„ä¸­é—´æ’å…¥

        Args:
            text: å¸¦æœ‰éŸ³æ•ˆæ ‡è®°çš„æ–‡æœ¬
            **kwargs: TTSåˆæˆå‚æ•°

        Returns:
            str: åˆå¹¶åçš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        """
        import re
        from utils.emotion_trigger import EMOTION_TRIGGER_MAP

        util.log(1, f"[OPUSæ’å…¥] å¼€å§‹å¤„ç†: {text}")

        # ğŸ”¥ ä¿®å¤1ï¼šæ›´ç²¾ç¡®çš„æ–‡æœ¬æ¸…ç†å’Œä½ç½®æ˜ å°„
        effect_pattern = re.compile(r'\{([A-Za-z0-9_\u4e00-\u9fff]+)\}')
        effects = []

        # å»ºç«‹åŸæ–‡æœ¬åˆ°æ¸…ç†æ–‡æœ¬çš„ä½ç½®æ˜ å°„
        clean_text = ""
        char_mapping = []  # è®°å½•æ¸…ç†æ–‡æœ¬ä¸­æ¯ä¸ªå­—ç¬¦åœ¨åŸæ–‡æœ¬ä¸­çš„ä½ç½®

        last_pos = 0
        for match in effect_pattern.finditer(text):
            effect_name = match.group(1)
            effect_config = EMOTION_TRIGGER_MAP.get(effect_name)

            # æ”¯æŒéŸ³æ•ˆå’ŒéŸ³ä¹æ’­æ”¾ä¸¤ç§ç±»å‹
            if effect_config and effect_config.get("type") in ["sound_effect", "music_play"]:
                # æ·»åŠ æ ‡è®°å‰çš„æ–‡æœ¬
                before_text = text[last_pos:match.start()]
                clean_text += before_text

                # è®°å½•å­—ç¬¦æ˜ å°„
                for i, char in enumerate(before_text):
                    char_mapping.append(last_pos + i)

                # ğŸ”¥ ä¿®å¤ï¼šæ›´ç²¾ç¡®çš„æ’å…¥ä½ç½®è®¡ç®—
                # åŸºäºå‰é¢æ–‡æœ¬çš„å­—ç¬¦æ•°ï¼Œè€Œä¸æ˜¯æ€»é•¿åº¦æ¯”ä¾‹
                insert_position_in_clean = len(clean_text)

                # éªŒè¯éŸ³æ•ˆæ–‡ä»¶å­˜åœ¨æ€§
                effect_file = effect_config.get("audio_file")
                if effect_file and not os.path.isabs(effect_file):
                    effect_file = os.path.abspath(effect_file)

                if effect_file and os.path.exists(effect_file):
                    effects.append({
                        'name': effect_name,
                        'file': effect_file,
                        'insert_position_in_clean': insert_position_in_clean,
                        'type': effect_config.get("type"),
                        'before_text_length': len(before_text)  # æ–°å¢ï¼šå‰é¢æ–‡æœ¬é•¿åº¦
                    })
                    util.log(1, f"[OPUSæ’å…¥] âœ… éŸ³æ•ˆæ–‡ä»¶éªŒè¯é€šè¿‡: {effect_name} -> {effect_file}")
                else:
                    util.log(2, f"[OPUSæ’å…¥] âŒ éŸ³æ•ˆæ–‡ä»¶ä¸å­˜åœ¨: {effect_name} -> {effect_file}")

                last_pos = match.end()

        # æ·»åŠ æœ€åä¸€æ®µæ–‡æœ¬
        if last_pos < len(text):
            remaining_text = text[last_pos:]
            clean_text += remaining_text
            for i, char in enumerate(remaining_text):
                char_mapping.append(last_pos + i)

        # ğŸ”¥ ä¿®å¤2ï¼šç¡®ä¿æ¸…ç†æ–‡æœ¬å®Œå…¨å»é™¤æ ‡è®°
        # å†æ¬¡æ¸…ç†å¯èƒ½é—æ¼çš„æ ‡è®°
        clean_text = re.sub(r'\{[A-Za-z0-9_\u4e00-\u9fff]+\}', '', clean_text)

        util.log(1, f"[OPUSæ’å…¥] æ¸…ç†åæ–‡æœ¬: {clean_text}")
        util.log(1, f"[OPUSæ’å…¥] æ£€æµ‹åˆ°{len(effects)}ä¸ªæ’å…¥ç‚¹")

        # 2. TTSåˆæˆæ¸…ç†åçš„æ–‡æœ¬
        main_audio = self.to_sample(clean_text, **kwargs)

        if not main_audio:
            util.log(2, f"[OPUSæ’å…¥] TTSåˆæˆå¤±è´¥")
            return None

        # ğŸ”¥ ä¿®å¤ï¼šæµå¼TTSå®Œæˆåï¼Œä¸æ”¯æŒOPUSæ’å…¥ï¼Œæ”¹ä¸ºå¼‚æ­¥æ’­æ”¾éŸ³ä¹
        if main_audio == "STREAMING_COMPLETED":
            util.log(1, f"[OPUSæ’å…¥] æµå¼TTSå·²å®Œæˆï¼ŒéŸ³ä¹å°†åœ¨TTSåå¼‚æ­¥æ’­æ”¾")
            # è§¦å‘éŸ³ä¹å¼‚æ­¥æ’­æ”¾ - ç­‰å¾…AudioManagerç©ºé—²åæ’­æ”¾
            def wait_and_play_music():
                try:
                    from esp32_liusisi.sisi_audio_output import AudioOutputManager
                    import time
                    
                    aom = AudioOutputManager.get_instance()
                    if not aom:
                        util.log(2, "[OPUSæ’å…¥] AudioManagerä¸å¯ç”¨ï¼Œè·³è¿‡éŸ³ä¹æ’­æ”¾")
                        return
                    
                    # ç­‰å¾…AudioManagerç©ºé—²ï¼ˆæœ€å¤šç­‰10ç§’ï¼‰
                    max_wait = 10
                    waited = 0
                    while waited < max_wait:
                        if aom.is_idle():
                            util.log(1, f"[OPUSæ’å…¥] AudioManagerå·²ç©ºé—²ï¼Œå¼€å§‹æ’­æ”¾éŸ³ä¹")
                            break
                        time.sleep(0.1)
                        waited += 0.1
                    
                    if waited >= max_wait:
                        util.log(2, f"[OPUSæ’å…¥] ç­‰å¾…AudioManagerç©ºé—²è¶…æ—¶ï¼Œè·³è¿‡éŸ³ä¹æ’­æ”¾")
                        return
                    
                    # æ’­æ”¾éŸ³ä¹
                    for effect in effects:
                        effect_name = effect['name']
                        util.log(1, f"[OPUSæ’å…¥] è§¦å‘éŸ³ä¹æ’­æ”¾: {effect_name}")
                        from utils.emotion_trigger import _execute_music_play, EMOTION_TRIGGER_MAP
                        if effect_name in EMOTION_TRIGGER_MAP:
                            trigger_config = EMOTION_TRIGGER_MAP[effect_name]
                            _execute_music_play(effect_name, trigger_config)
                            # ç­‰å¾…å½“å‰éŸ³ä¹æ’­æ”¾å®Œæˆ
                            aom.wait_until_idle(timeout=15.0)
                
                except Exception as e:
                    util.log(2, f"[OPUSæ’å…¥] éŸ³ä¹æ’­æ”¾å¼‚å¸¸: {e}")
            
            import threading
            threading.Thread(target=wait_and_play_music, daemon=True).start()
            return main_audio

        if not effects:
            return main_audio

        # 3. OPUSå¸§çº§æ’å…¥ï¼ˆè¿™é‡Œè¿”å›åŸéŸ³é¢‘ï¼Œå®é™…æ’å…¥åœ¨æ’­æ”¾æ—¶å¤„ç†ï¼‰
        util.log(1, f"[OPUSæ’å…¥] æ£€æµ‹åˆ°{len(effects)}ä¸ªéŸ³æ•ˆæ’å…¥ç‚¹")

        # 4. å®ç°çœŸæ­£çš„OPUSå¸§æ’å…¥
        try:
            # å¯¼å…¥OPUSè½¬æ¢å™¨
            from esp32_liusisi.opus_helper import OpusConvertor
            opus_helper = OpusConvertor()

            # è½¬æ¢ä¸»éŸ³é¢‘ä¸ºOPUSå¸§
            main_frames, duration = opus_helper.audio_to_opus_frames(main_audio)
            if not main_frames:
                util.log(2, f"[OPUSæ’å…¥] ä¸»éŸ³é¢‘è½¬æ¢å¤±è´¥")
                return main_audio

            util.log(1, f"[OPUSæ’å…¥] ä¸»éŸ³é¢‘è½¬æ¢æˆåŠŸ: {len(main_frames)}å¸§, æ—¶é•¿{duration:.2f}ç§’")

            # è®¡ç®—æ’å…¥ä½ç½®å¹¶æ’å…¥éŸ³æ•ˆå¸§
            final_frames = main_frames.copy()

            for effect in effects:
                effect_file = effect['file']
                if not effect_file or not os.path.exists(os.path.abspath(effect_file)):
                    continue

                # è½¬æ¢éŸ³æ•ˆä¸ºOPUSå¸§
                effect_frames, effect_duration = opus_helper.audio_to_opus_frames(os.path.abspath(effect_file))
                if not effect_frames:
                    continue

                # ğŸ”¥ ä¿®å¤3ï¼šæ›´ç²¾ç¡®çš„æ’å…¥ä½ç½®è®¡ç®—
                # åŸºäºå‰é¢æ–‡æœ¬çš„å®é™…é•¿åº¦ï¼Œè€Œä¸æ˜¯æ¯”ä¾‹
                before_text_length = effect.get('before_text_length', 0)
                clean_text_length = len(clean_text)

                if clean_text_length > 0 and before_text_length >= 0:
                    # ä½¿ç”¨å‰é¢æ–‡æœ¬çš„å®é™…æ¯”ä¾‹
                    position_ratio = before_text_length / clean_text_length
                    insert_frame_pos = int(len(main_frames) * position_ratio)

                    # ç¡®ä¿æ’å…¥ä½ç½®åœ¨æœ‰æ•ˆèŒƒå›´å†…
                    insert_frame_pos = max(0, min(insert_frame_pos, len(main_frames)))
                else:
                    insert_frame_pos = 0

                util.log(1, f"[OPUSæ’å…¥] {effect['name']}: å‰æ–‡é•¿åº¦={before_text_length}, æ€»é•¿åº¦={clean_text_length}, æ¯”ä¾‹={position_ratio:.2f}, å¸§ä½ç½®={insert_frame_pos}/{len(main_frames)}")

                # æ’å…¥éŸ³æ•ˆå¸§
                final_frames = (final_frames[:insert_frame_pos] +
                              effect_frames +
                              final_frames[insert_frame_pos:])

                util.log(1, f"[OPUSæ’å…¥] åœ¨ç¬¬{insert_frame_pos}å¸§æ’å…¥éŸ³æ•ˆ: {effect['name']}")

            # ğŸ”§ æ­£ç¡®ç­–ç•¥ï¼šä¸ä¿å­˜éŸ³é¢‘æ–‡ä»¶ï¼Œç›´æ¥ç¼“å­˜OPUSå¸§ä¾›å‘é€ç«¯ä½¿ç”¨
            merged_audio_path = main_audio.replace('.wav', '_with_effects.wav')

            # å°†åˆå¹¶åçš„OPUSå¸§ç¼“å­˜ï¼Œä¾›ESP32å‘é€ç«¯ç›´æ¥ä½¿ç”¨
            if not hasattr(self, '_opus_frames_cache'):
                self._opus_frames_cache = {}
            self._opus_frames_cache[merged_audio_path] = final_frames

            # ğŸ”¥ ä¿®å¤ï¼šç”Ÿæˆå®é™…çš„éŸ³é¢‘æ–‡ä»¶è€Œä¸æ˜¯æ ‡è®°æ–‡ä»¶
            try:
                # ç®€å•æ–¹æ¡ˆï¼šå¤åˆ¶åŸéŸ³é¢‘æ–‡ä»¶ä½œä¸ºåˆå¹¶æ–‡ä»¶ï¼ˆéŸ³æ•ˆé€šè¿‡OPUSå¸§å‘é€ï¼‰
                import shutil
                shutil.copy2(main_audio, merged_audio_path)
                util.log(1, f"[OPUSæ’å…¥] å·²ç”Ÿæˆåˆå¹¶éŸ³é¢‘æ–‡ä»¶: {merged_audio_path}")
                util.log(1, f"[OPUSæ’å…¥] OPUSå¸§å·²ç¼“å­˜: {len(final_frames)}å¸§")
            except Exception as e:
                util.log(2, f"[OPUSæ’å…¥] ç”ŸæˆéŸ³é¢‘æ–‡ä»¶å¤±è´¥: {str(e)}")
                return main_audio

            util.log(1, f"[OPUSæ’å…¥] åˆå¹¶å®Œæˆ: {len(final_frames)}å¸§ï¼Œå·²ç¼“å­˜ä¾›ç›´æ¥å‘é€")
            return merged_audio_path

        except Exception as e:
            util.log(2, f"[OPUSæ’å…¥] å¤„ç†å¤±è´¥: {str(e)}")
            return main_audio


# ä¸ºäº†ä¸ç°æœ‰æ¥å£ä¿æŒä¸€è‡´ï¼Œæ·»åŠ Speechç±»ä½œä¸ºSiliconFlowTTSçš„åˆ«å
class Speech(SiliconFlowTTS):
    """Speechç±»ä½œä¸ºSiliconFlowTTSçš„åˆ«åï¼Œä¿æŒä¸å…¶ä»–TTSæ¨¡å—æ¥å£ä¸€è‡´"""
    pass


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    tts = SiliconFlowTTS()
    print("SiliconFlowTTS class defined successfully")
