# 后端对齐与日志映射（SmartSisi WebUI）

这份文档解决两件事：
1) 你贴出来的 **ASR / 主程序日志** 每一段在前端应该对应什么；
2) 你遇到的 **`opening handshake failed … expected GET got POST`** 到底是什么原因、怎么改。

---

## 1) ASR_server（ws://0.0.0.0:10197）字段说明

你日志里这段：

- `{"vad_need": false, "state": "StartTranscription", "hotwords": [...]}`  
  - `state=StartTranscription`：开始一次识别会话  
  - `vad_need`：是否需要服务端做 VAD（是否让服务端自己判定语音起止）  
  - `hotwords`：热词列表（你的“你好/思思/柳思思/喂/说话…”）

- `{"vad_need": false, "state": "StopTranscription"}`  
  - 停止本次识别会话（不代表有结果，只是停止）

- `{"url": "E:\\...\\tmpxxxx.wav"}`  
  - **关键**：你现在的 ASR 协议不是“实时音频流”，而是“传本地 wav 文件路径让 ASR 去读”。

ASR 返回：

- `text`：识别文本
- `timestamp` / `sentence_info`：分词/分句时间戳（可用于“前端显示字幕对齐/高亮”）

---

## 2) 主程序交互日志 → 前端应该怎么映射

你主程序日志已经把整条链路写出来了，建议前端最终用一套固定 stage 名称映射到：
- 聊天气泡下方 `FlowChips`（发生才出现→完成后淡出）
- 左侧“事件/日志”列表（永远留痕，便于排查）

建议 stage（与你日志对应）：

- `LISTEN`：`[User] 聆听中...`
- `ASR`：`[User] 语音处理中...`、`[FunASR] 收到音频上下文数据`
- `WAKE`：`[!] 待唤醒！`、`[唤醒判定] ...`、`唤醒成功！`、`[预唤醒拼接] ...`
- `AUDIO_CTX`：`[本地录音] ...`、`[音频环境分析] ...`
- `BRAIN_BG`：`[前脑系统] ... 异步任务已提交 ...`
- `ROUTE`：`[系统路由] 当前模式: sisi/liuye`
- `LLM`：`[NLP] ...`、`[GPT] ...`
- `INTENT`：`[意图分析] ...`
- `MEMORY`：`Mem0 ...` / `统一历史 ...`
- `TTS/PLAY`：`[Core] 开始TTS处理` / `跳过TTS处理` / ESP32 播放

前端当前已落地的载体：
- **顶部状态灯**：`StatusBar.vue`（空闲/聆听/思考/说话）
- **流程条**：`FlowChips.vue`（mock 模式已能演示“发生→淡出”）
- **事件/日志**：左侧 Dock → “事件/日志”页（`LeftDrawer.vue`）

> 下一阶段要做的是真实 WS/HTTP 事件把上述 stage 推进 trace，而不是 mock 的定时器。

---

## 3) 你现在的握手错误是什么（必修复）

你报错：

- `opening handshake failed`
- `ValueError: unsupported HTTP method; expected GET; got POST`

这不是“LLM 模型坏了”，而是 **你把 HTTP POST 发到了 WebSocket 服务器**。

从你贴的日志能直接定位到原因：

- 你系统里启动了 **WebSocket 服务**：`ws://0.0.0.0:8000/sisi/v1/`（SiSi 设备/桥接协议）
- 但你配置里把 `gpt_base_url` 指到了 `http://127.0.0.1:8000/v1`（或者某段代码实际把 LLM 请求打到了 8000）
- 结果：websockets 服务器只接受 **GET + Upgrade** 的握手；你却用 `requests.post(...)` 去打它 → 就会出现 “expected GET got POST”。

### 3.1 你应该怎么改（最短路径）

1) **不要用 8000 当 LLM API 端口**  
   8000 已被你系统的 WebSocket（SiSi 协议/ESP32桥接）占用。

2) 给 grok2API / CLIProxyAPI 换一个端口（比如 8006 / 8317），然后把 `gpt_base_url` 指向那个 HTTP 服务：
   - 例如：`http://127.0.0.1:8006/v1`
   - 或者直接用 SmartSisi 自带的 OpenAI 兼容入口（Flask 5000）：`http://127.0.0.1:5000/v1`

3) 验证端口到底跑的是什么协议（看它是不是 HTTP）：
   - `netstat -ano | findstr :8000`
   - `curl http://127.0.0.1:8000/`（如果它是 WS 服务，HTTP 会异常或返回不对）
   - `curl http://127.0.0.1:5000/v1/models`（Flask 这个应该能通）

---

## 4) 前端怎么用 “real” 对齐你后端（当前版本）

1) 启动后端（Flask 5000）与 WS 10003（你现有启动脚本即可）。
2) 前端启动：
   - `cd SmartSisi/gui/frontend`
   - `npm run dev`
3) 前端左侧 Dock → **工具**：
   - `数据源` 选 `real`
   - `HTTP Base` 填 `http://127.0.0.1:5000`
   - `WS URL` 填 `ws://127.0.0.1:10003`
4) 左侧 Dock → **音频**：
   - 看底部 tip：WS 是否已连接、deviceList/voiceList 数量是否变化
5) 文本发送（real 模式）：
   - 现在会调用 `/api/send`，并把结果写进“事件/日志”
   - 真实的回复/设备状态需要靠 WS `panelReply/deviceList/voiceList/liveState` 来补齐（下一阶段继续对齐到聊天流/FlowChips）。

