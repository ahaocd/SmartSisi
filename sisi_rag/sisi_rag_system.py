#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Sisi RAGç³»ç»Ÿ - ä½¿ç”¨å‰è„‘ç³»ç»Ÿé…ç½®
åŠŸèƒ½ï¼šçŸ¥è¯†æ£€ç´¢å¢å¼ºç”Ÿæˆï¼Œä½¿ç”¨æ‚¨é…ç½®çš„Qwen/Qwen3-30B-A3Bæ¨¡å‹
"""

import json
import time
import logging
import configparser
from typing import Dict, Any, List, Optional
from pathlib import Path
import requests

# è®¾ç½®æ—¥å¿—
rag_logger = logging.getLogger(__name__)

class SisiRAGSystem:
    """ğŸ” Sisi RAGç³»ç»Ÿ - ä½¿ç”¨å‰è„‘ç³»ç»Ÿé…ç½®"""
    
    def __init__(self, config_path: str = "system.conf"):
        self.logger = rag_logger
        
        # è¯»å–å‰è„‘ç³»ç»Ÿé…ç½®
        self.config = configparser.ConfigParser()
        self.config.read(config_path, encoding='utf-8')
        
        # ä»system.confè¯»å–RAGç³»ç»Ÿé…ç½®
        self.api_key = self.config.get('key', 'rag_llm_api_key', fallback='')
        self.base_url = self.config.get('key', 'rag_llm_base_url', fallback='https://api.siliconflow.cn/v1')
        self.model = self.config.get('key', 'rag_llm_model', fallback='Qwen/Qwen3-30B-A3B')
        self.embedding_model = self.config.get('key', 'rag_embedding_model', fallback='Qwen/Qwen3-Embedding-8B')
        
        # RAGç³»ç»Ÿé…ç½®
        self.temperature = 0.2
        self.max_tokens = 3000
        
        # åˆå§‹åŒ–å‘é‡æ•°æ®åº“ - ğŸ”§ ä¿®å¤è·¯å¾„å†²çªï¼Œä½¿ç”¨ç‹¬ç«‹çš„RAGæ•°æ®åº“
        self.vector_db_path = Path(__file__).parent.parent / "sisi_rag" / "data" / "rag_chroma_db"
        self.vector_db_path.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–çŠ¶æ€
        self.initialized = False
        self.collection = None
        
        self._init_vector_db()
        
        self.logger.info(f"âœ… Sisi RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ - æ¨¡å‹: {self.model}")
    
    def _init_vector_db(self):
        """åˆå§‹åŒ–å‘é‡æ•°æ®åº“"""
        try:
            import chromadb
            from chromadb.config import Settings
            
            # åˆ›å»ºChromaDBå®¢æˆ·ç«¯
            self.client = chromadb.PersistentClient(
                path=str(self.vector_db_path),
                settings=Settings(
                    anonymized_telemetry=False,
                    allow_reset=True
                )
            )
            
            # è·å–æˆ–åˆ›å»ºé›†åˆ
            self.collection = self.client.get_or_create_collection(
                name="sisi_knowledge",
                metadata={"description": "SisiçŸ¥è¯†åº“"}
            )
            
            self.initialized = True
            self.logger.info("âœ… ChromaDBå‘é‡æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
            
        except ImportError:
            self.logger.warning("âš ï¸ ChromaDBæœªå®‰è£…ï¼ŒRAGåŠŸèƒ½å°†å—é™")
            self.initialized = False
        except Exception as e:
            self.logger.error(f"âŒ ChromaDBåˆå§‹åŒ–å¤±è´¥: {e}")
            self.initialized = False
    
    def retrieve_context(self, query: str, speaker_id: str = None, top_k: int = 5) -> Dict[str, Any]:
        """æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡"""
        try:
            if not self.initialized:
                return self._fallback_context(query)
            
            # æ£€ç´¢ç›¸å…³æ–‡æ¡£
            results = self.collection.query(
                query_texts=[query],
                n_results=top_k,
                include=['documents', 'metadatas', 'distances']
            )
            
            if not results['documents'] or not results['documents'][0]:
                return self._fallback_context(query)
            
            # æ„å»ºä¸Šä¸‹æ–‡
            context_docs = []
            for i, doc in enumerate(results['documents'][0]):
                metadata = results['metadatas'][0][i] if results['metadatas'][0] else {}
                distance = results['distances'][0][i] if results['distances'][0] else 1.0
                
                context_docs.append({
                    'content': doc,
                    'metadata': metadata,
                    'relevance_score': 1.0 - distance,
                    'source': metadata.get('source', 'unknown')
                })
            
            return {
                'query': query,
                'context_documents': context_docs,
                'total_results': len(context_docs),
                'retrieval_time': time.time()
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ä¸Šä¸‹æ–‡æ£€ç´¢å¤±è´¥: {e}")
            return self._fallback_context(query)
    
    def generate_rag_response(self, query: str, context: Dict[str, Any], speaker_id: str = None) -> str:
        """åŸºäºæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ç”Ÿæˆå›ç­”"""
        try:
            # æ„å»ºRAGæç¤ºè¯
            rag_prompt = self._build_rag_prompt(query, context, speaker_id)
            
            # è°ƒç”¨å‰è„‘ç³»ç»Ÿé…ç½®çš„æ¨¡å‹
            response = self._call_llm(rag_prompt)
            
            return response
            
        except Exception as e:
            self.logger.error(f"âŒ RAGå›ç­”ç”Ÿæˆå¤±è´¥: {e}")
            return "æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•åŸºäºçŸ¥è¯†åº“å›ç­”è¿™ä¸ªé—®é¢˜ã€‚"
    
    def _build_rag_prompt(self, query: str, context: Dict[str, Any], speaker_id: str = None) -> str:
        """æ„å»ºRAGæç¤ºè¯ - ç¬¦åˆäººç±»å‰è„‘ç‰¹å¾"""
        
        # æ•´ç†ä¸Šä¸‹æ–‡æ–‡æ¡£
        context_text = ""
        if context.get('context_documents'):
            for i, doc in enumerate(context['context_documents'], 1):
                relevance = doc.get('relevance_score', 0.0)
                source = doc.get('source', 'unknown')
                content = doc.get('content', '')
                
                context_text += f"""
æ–‡æ¡£{i} (ç›¸å…³åº¦: {relevance:.2f}, æ¥æº: {source}):
{content}

"""
        
        # ä¸ªæ€§åŒ–ä¿¡æ¯
        user_context = ""
        if speaker_id:
            user_context = f"ç”¨æˆ·ID: {speaker_id}\n"
        
        # æ„å»ºç¬¦åˆäººç±»å‰è„‘ç‰¹å¾çš„RAGæç¤ºè¯
        prompt = f"""ä½ æ˜¯Sisiçš„çŸ¥è¯†æ•´åˆä¸“å®¶ï¼Œå…·å¤‡äººç±»å‰è„‘çš„çŸ¥è¯†å¤„ç†ç‰¹å¾ã€‚

### ğŸ§  äººç±»å‰è„‘çŸ¥è¯†å¤„ç†ç‰¹å¾
1. **çŸ¥è¯†å…³è”**: è‡ªç„¶åœ°å°†å¤šä¸ªçŸ¥è¯†ç‚¹å…³è”èµ·æ¥
2. **ä¸ªæ€§åŒ–è¡¨è¾¾**: ç”¨Sisiçš„è¯­è¨€é£æ ¼è¡¨è¾¾çŸ¥è¯†
3. **ä¸ç¡®å®šæ€§å¤„ç†**: è¯šå®è¡¨è¾¾çŸ¥è¯†è¾¹ç•Œå’Œä¸ç¡®å®šæ€§
4. **æƒ…æ„Ÿå…±é¸£**: ç†è§£ç”¨æˆ·çš„æƒ…æ„Ÿéœ€æ±‚ï¼Œæä¾›æ¸©æš–çš„å›åº”
5. **è®°å¿†æ•´åˆ**: å°†æ–°çŸ¥è¯†ä¸å·²æœ‰è®°å¿†è‡ªç„¶æ•´åˆ

### ğŸ“š æ£€ç´¢åˆ°çš„ç›¸å…³çŸ¥è¯†
{context_text}

### ğŸ‘¤ ç”¨æˆ·ä¿¡æ¯
{user_context}

### â“ ç”¨æˆ·é—®é¢˜
{query}

### ğŸ“ å›ç­”è¦æ±‚
è¯·åŸºäºä»¥ä¸ŠçŸ¥è¯†ï¼Œç”¨Sisiçš„äººæ€§åŒ–é£æ ¼å›ç­”ç”¨æˆ·é—®é¢˜ï¼š
- å¦‚æœçŸ¥è¯†å……åˆ†ï¼Œç»™å‡ºè¯¦ç»†å‡†ç¡®çš„å›ç­”
- å¦‚æœçŸ¥è¯†ä¸è¶³ï¼Œè¯šå®è¯´æ˜å¹¶æä¾›å¯èƒ½çš„æ–¹å‘
- ä¿æŒSisiçš„æ¸©æš–ã€ç†è§£ã€å…±æƒ…çš„ç‰¹è´¨
- è‡ªç„¶åœ°æ•´åˆå¤šä¸ªçŸ¥è¯†ç‚¹ï¼Œé¿å…ç”Ÿç¡¬çš„åˆ—ä¸¾
- é€‚å½“è¡¨è¾¾ä¸ç¡®å®šæ€§ï¼Œå¦‚"æˆ‘è§‰å¾—"ã€"å¯èƒ½æ˜¯"ã€"æ®æˆ‘äº†è§£"

è¯·å›ç­”ï¼š"""
        
        return prompt
    
    def _call_llm(self, prompt: str) -> str:
        """è°ƒç”¨å‰è„‘ç³»ç»Ÿé…ç½®çš„LLM"""
        
        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': self.model,
            'messages': [
                {
                    'role': 'system',
                    'content': 'ä½ æ˜¯Sisiçš„çŸ¥è¯†æ•´åˆä¸“å®¶ï¼Œæ“…é•¿å°†æ£€ç´¢åˆ°çš„çŸ¥è¯†ç”¨äººæ€§åŒ–çš„æ–¹å¼è¡¨è¾¾ç»™ç”¨æˆ·ã€‚'
                },
                {
                    'role': 'user',
                    'content': prompt
                }
            ],
            'temperature': self.temperature,
            'max_tokens': self.max_tokens
        }
        
        response = requests.post(
            f"{self.base_url}/chat/completions",
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            return result['choices'][0]['message']['content']
        else:
            raise Exception(f"APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
    
    def _fallback_context(self, query: str) -> Dict[str, Any]:
        """å¤‡ç”¨ä¸Šä¸‹æ–‡"""
        return {
            'query': query,
            'context_documents': [],
            'total_results': 0,
            'retrieval_time': time.time(),
            'fallback': True
        }
    
    def add_knowledge(self, content: str, metadata: Dict[str, Any] = None) -> bool:
        """æ·»åŠ çŸ¥è¯†åˆ°å‘é‡æ•°æ®åº“"""
        try:
            if not self.initialized:
                self.logger.warning("âš ï¸ å‘é‡æ•°æ®åº“æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ·»åŠ çŸ¥è¯†")
                return False
            
            # ç”Ÿæˆå”¯ä¸€ID
            doc_id = f"doc_{int(time.time() * 1000)}"
            
            # æ·»åŠ åˆ°é›†åˆ
            self.collection.add(
                documents=[content],
                metadatas=[metadata or {}],
                ids=[doc_id]
            )
            
            self.logger.info(f"âœ… çŸ¥è¯†æ·»åŠ æˆåŠŸ: {doc_id}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ çŸ¥è¯†æ·»åŠ å¤±è´¥: {e}")
            return False
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–RAGç³»ç»ŸçŠ¶æ€"""
        status = {
            'initialized': self.initialized,
            'model': self.model,
            'embedding_model': self.embedding_model,
            'vector_db_path': str(self.vector_db_path),
            'api_base_url': self.base_url
        }
        
        if self.initialized and self.collection:
            try:
                count = self.collection.count()
                status['knowledge_count'] = count
            except:
                status['knowledge_count'] = 'unknown'
        
        return status

# å…¨å±€å®ä¾‹
_rag_system = None

def get_rag_system() -> SisiRAGSystem:
    """è·å–RAGç³»ç»Ÿå®ä¾‹"""
    global _rag_system
    if _rag_system is None:
        _rag_system = SisiRAGSystem()
    return _rag_system

def rag_retrieve_and_generate(query: str, speaker_id: str = None) -> str:
    """ä¾¿æ·å‡½æ•°ï¼šæ£€ç´¢å¹¶ç”Ÿæˆå›ç­”"""
    rag = get_rag_system()
    context = rag.retrieve_context(query, speaker_id)
    return rag.generate_rag_response(query, context, speaker_id)

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    rag = get_rag_system()
    
    # æµ‹è¯•çŠ¶æ€
    status = rag.get_status()
    print(f"ğŸ“Š RAGç³»ç»ŸçŠ¶æ€: {json.dumps(status, indent=2, ensure_ascii=False)}")
    
    # æµ‹è¯•æ£€ç´¢
    test_query = "å¦‚ä½•å¤„ç†å™ªéŸ³ç¯å¢ƒä¸­çš„å¯¹è¯"
    context = rag.retrieve_context(test_query)
    print(f"ğŸ” æ£€ç´¢ç»“æœ: {json.dumps(context, indent=2, ensure_ascii=False)}")
    
    # æµ‹è¯•ç”Ÿæˆ
    response = rag.generate_rag_response(test_query, context)
    print(f"ğŸ’¬ ç”Ÿæˆå›ç­”: {response}")
