#!/usr/bin/env python3
"""
è°ƒè¯•è„šæœ¬ï¼šæ£€æŸ¥æŠ–éŸ³è§†é¢‘é¡µé¢HTMLä¸­è¯„è®ºçš„çœŸå®DOMç»“æ„
"""
import asyncio
import aiohttp
import json
import re

async def main():
    # è¿æ¥mcp-chrome
    mcp_url = "http://127.0.0.1:12306/mcp"

    async with aiohttp.ClientSession() as session:
        # 1. è·å–session
        async with session.post(f"{mcp_url}/session/init") as resp:
            data = await resp.json()
            session_id = data.get('sessionId')
            print(f"Session: {session_id}")

        # 2. è·å–å½“å‰é¡µé¢HTML
        async with session.post(
            f"{mcp_url}/call",
            json={
                "sessionId": session_id,
                "method": "chrome_get_web_content",
                "params": {"selector": "body", "htmlContent": True}
            }
        ) as resp:
            result = await resp.json()

        # è§£æHTML
        html_content = ""
        if isinstance(result, dict) and 'content' in result:
            text_str = result['content'][0].get('text', '')
            if text_str.startswith('{'):
                data = json.loads(text_str)
                html_content = data.get('htmlContent', '')

        print(f"HTMLé•¿åº¦: {len(html_content)}")

        # ä¿å­˜HTMLåˆ°æ–‡ä»¶
        with open("debug_video_page.html", "w", encoding="utf-8") as f:
            f.write(html_content)
        print("HTMLå·²ä¿å­˜åˆ° debug_video_page.html")

        # 3. æŸ¥æ‰¾è¯„è®ºç›¸å…³çš„å±æ€§
        print("\n=== æœç´¢è¯„è®ºç›¸å…³å±æ€§ ===")

        # æœç´¢æ‰€æœ‰data-e2eå±æ€§
        data_e2e_attrs = re.findall(r'data-e2e="([^"]+)"', html_content)
        unique_attrs = sorted(set(data_e2e_attrs))
        print(f"æ‰¾åˆ° {len(unique_attrs)} ä¸ªå”¯ä¸€çš„ data-e2e å±æ€§:")
        for attr in unique_attrs:
            if 'comment' in attr.lower():
                print(f"  ğŸ”¥ {attr}")
            else:
                print(f"     {attr}")

        # æœç´¢classä¸­åŒ…å«commentçš„
        print("\n=== æœç´¢ class åŒ…å« 'comment' ===")
        comment_classes = re.findall(r'class="([^"]*comment[^"]*)"', html_content, re.IGNORECASE)
        unique_classes = sorted(set(comment_classes[:20]))
        for cls in unique_classes:
            print(f"  {cls[:100]}")

        # æœç´¢ç”¨æˆ·é“¾æ¥
        print("\n=== æœç´¢ç”¨æˆ·ä¸»é¡µé“¾æ¥ ===")
        user_links = re.findall(r'href="(/user/[^"]+)"', html_content)
        print(f"æ‰¾åˆ° {len(user_links)} ä¸ªç”¨æˆ·é“¾æ¥")
        for link in user_links[:10]:
            print(f"  {link}")

        # æœç´¢æ½œåœ¨çš„è¯„è®ºæ–‡æœ¬æ¨¡å¼
        print("\n=== æœç´¢è¯„è®ºæ–‡æœ¬å®¹å™¨ ===")
        # æŸ¥æ‰¾åŒ…å«ä¸­æ–‡æ–‡æœ¬çš„span/div
        text_patterns = re.findall(
            r'<(span|div)[^>]*class="[^"]*"[^>]*>([^<]{10,100})</\1>',
            html_content
        )
        print(f"æ‰¾åˆ° {len(text_patterns)} ä¸ªæ–‡æœ¬å®¹å™¨ï¼ˆæ˜¾ç¤ºå‰10ä¸ªï¼‰:")
        for tag, text in text_patterns[:10]:
            print(f"  <{tag}>: {text[:60]}...")

if __name__ == "__main__":
    asyncio.run(main())
