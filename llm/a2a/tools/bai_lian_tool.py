"""
ç™¾ç‚¼å·¥å…· - æä¾›ä¸ç™¾ç‚¼APIäº¤äº’çš„åŸºæœ¬åŠŸèƒ½ (æ ‡å‡†A2Aå®ç°)
å¢å¼ºç¤¾äº¤åª’ä½“æœç´¢èƒ½åŠ›ï¼ŒåŒ…æ‹¬æŠ–éŸ³ã€å°çº¢ä¹¦ã€YouTubeç­‰å¹³å°å†…å®¹
æ”¯æŒä¸zudaoå·¥å…·åä½œï¼Œé’ˆå¯¹åº—é“ºå’ŒæŠ€å¸ˆè¿›è¡Œæ›´ç²¾å‡†æœç´¢
"""

import os
import json
import time
import logging
import asyncio
import re
import random
from typing import Dict, Any, List, Optional, Union, Generator, Tuple
from http import HTTPStatus

# å¯¼å…¥æ ‡å‡†A2Aå·¥å…·åŸºç±» - ä¿®æ”¹ä¸ºç»å¯¹å¯¼å…¥
from SmartSisi.llm.a2a.base_a2a_tool import StandardA2ATool

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger("BaiLianTool")

# å¯¼å…¥DashScope SDK
try:
    from dashscope import Application
    import dashscope
    DASHSCOPE_AVAILABLE = True
    logger.info("DashScope SDKå·²åŠ è½½")
except ImportError:
    DASHSCOPE_AVAILABLE = False
    logger.warning("DashScope SDKæœªæ‰¾åˆ°ï¼Œè¯·å®‰è£…ï¼špip install dashscope")

class BaiLianTool(StandardA2ATool):
    """ç™¾ç‚¼APIå·¥å…· - æ ‡å‡†A2Aå®ç°ï¼Œä¼˜å…ˆæœç´¢ç¤¾äº¤åª’ä½“å†…å®¹"""

    # é»˜è®¤APIå¯†é’¥å’Œåº”ç”¨ID
    DEFAULT_API_KEY = "sk-cda8f8d44c3042da82ee9700f388e9b4"
    DEFAULT_APP_ID = "3355af3f65fd4323b617b80f59c349b5"

    # ç¤¾äº¤åª’ä½“å¹³å°å…³é”®è¯ - ä¸“æ³¨æŠ–éŸ³å¿«æ‰‹ç­‰å®æ—¶å¹³å°
    SOCIAL_PLATFORMS = [
        "æŠ–éŸ³", "å¿«æ‰‹", "å¾®åš", "çŸ­è§†é¢‘", "ç¤¾äº¤åª’ä½“", "ç›´æ’­å¹³å°"
    ]

    # è¶³æµ´æŠ€å¸ˆç›¸å…³å…³é”®è¯
    MASSAGE_TECHNICIAN_KEYWORDS = [
        "æŠ€å¸ˆ", "å°å¦¹", "æœåŠ¡", "ç‰¹è‰²", "é¢œå€¼", "ä½“éªŒ",
        "æ‰‹æ³•", "æŒ‰æ‘©", "88å·", "ä¸“ä¸š", "æ€åº¦", "ä»‹ç»"
    ]

    # è¡¥å……æŸ¥è¯¢å’ŒéªŒè¯æŸ¥è¯¢æ„å›¾å…³é”®è¯
    COMPLEMENTARY_INTENT_KEYWORDS = ["æ›´å¤š", "è¯¦æƒ…", "è¯„ä»·", "çœŸå®", "å…·ä½“"]
    VERIFICATION_INTENT_KEYWORDS = ["é è°±å—", "æ€ä¹ˆæ ·", "å¥½ä¸å¥½", "å¦‚ä½•", "çœŸçš„å—", "å€¼å¾—"]

    def __init__(self, api_key: Optional[str] = None, app_id: Optional[str] = None):
        """
        åˆå§‹åŒ–ç™¾ç‚¼å·¥å…·

        å‚æ•°:
            api_key: ç™¾ç‚¼APIå¯†é’¥ï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡è·å–
            app_id: ç™¾ç‚¼åº”ç”¨ID
        """
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–æ–¹æ³•
        super().__init__(
            name="bai_lian",
            description="ç™¾ç‚¼æœç´¢å·¥å…·ï¼Œæä¾›æ™ºèƒ½æœç´¢å’Œä¿¡æ¯æŸ¥è¯¢æœåŠ¡ï¼Œä¼˜å…ˆæœç´¢ç¤¾äº¤åª’ä½“å†…å®¹ï¼Œæ”¯æŒå¯¹ç‰¹å®šåº—é“ºå’ŒæœåŠ¡è¿›è¡Œæ·±å…¥åˆ†æ",
            version="1.0.0"
        )

        # è·å–APIå¯†é’¥
        self.api_key = api_key or os.getenv("DASHSCOPE_API_KEY") or self.DEFAULT_API_KEY

        # è®¾ç½®åº”ç”¨ID
        self.app_id = app_id or os.getenv("DASHSCOPE_APP_ID") or self.DEFAULT_APP_ID

        # è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œä»¥ä¾¿DashScope SDKä½¿ç”¨
        os.environ["DASHSCOPE_API_KEY"] = self.api_key

        # ç›´æ¥è®¾ç½®DashScope SDKçš„APIå¯†é’¥
        if DASHSCOPE_AVAILABLE:
            dashscope.api_key = self.api_key
            logger.info(f"å·²ç›´æ¥è®¾ç½®DashScope SDKçš„APIå¯†é’¥")

        # æ£€æŸ¥SDKæ˜¯å¦å¯ç”¨
        if not DASHSCOPE_AVAILABLE:
            logger.warning("DashScope SDKä¸å¯ç”¨ï¼Œéƒ¨åˆ†åŠŸèƒ½å°†å—é™")

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "total_tokens": 0,
            "start_time": time.time()
        }

        # è®¢é˜…çŠ¶æ€è·Ÿè¸ª
        self.subscription_id = None
        self.last_subscription_time = 0

        # æ·»åŠ 24å°æ—¶ç¼“å­˜æœºåˆ¶
        self.search_cache = {}  # æ ¼å¼: {store_name: {"result": "...", "timestamp": time.time()}}
        self.cache_duration = 24 * 60 * 60  # 24å°æ—¶ç¼“å­˜

        # åˆå§‹åŒ–transit_station
        try:
            from llm.transit_station import get_transit_station
            self.transit_station = get_transit_station()
            logger.info(f"ç™¾ç‚¼å·¥å…·å·²åˆå§‹åŒ–transit_station")
        except Exception as e:
            logger.warning(f"ç™¾ç‚¼å·¥å…·åˆå§‹åŒ–transit_stationå¤±è´¥: {str(e)}")
            self.transit_station = None

        logger.info(f"ç™¾ç‚¼å·¥å…·åˆå§‹åŒ–å®Œæˆï¼Œåº”ç”¨ID: {self.app_id}")

        # ä¸åœ¨åˆå§‹åŒ–æ—¶ç«‹å³è®¢é˜…ï¼Œé¿å…é‡å¤è®¢é˜…
        # æ”¹ä¸ºåœ¨é¦–æ¬¡éœ€è¦æ—¶å»¶è¿Ÿè®¢é˜…

    def _is_cache_valid(self, store_name: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆï¼ˆ24å°æ—¶å†…ï¼‰"""
        if store_name not in self.search_cache:
            return False

        cache_time = self.search_cache[store_name].get("timestamp", 0)
        current_time = time.time()

        return (current_time - cache_time) < self.cache_duration

    def _get_cached_result(self, store_name: str) -> Optional[str]:
        """è·å–ç¼“å­˜çš„æœç´¢ç»“æœ"""
        if self._is_cache_valid(store_name):
            return self.search_cache[store_name].get("result")
        return None

    def _cache_result(self, store_name: str, result: str):
        """ç¼“å­˜æœç´¢ç»“æœ"""
        self.search_cache[store_name] = {
            "result": result,
            "timestamp": time.time()
        }
        logger.info(f"[ç¼“å­˜] å·²ç¼“å­˜åº—é“º {store_name} çš„æœç´¢ç»“æœ")

    def set_app_id(self, app_id: str) -> None:
        """
        è®¾ç½®åº”ç”¨ID

        å‚æ•°:
            app_id: ç™¾ç‚¼åº”ç”¨ID
        """
        self.app_id = app_id
        logger.info(f"åº”ç”¨IDå·²è®¾ç½®ä¸º: {app_id}")

    async def process_query(self, query: str) -> str:
        """
        å®ç°æ ‡å‡†A2AåŸºç±»çš„process_queryæ–¹æ³•

        å‚æ•°:
            query: ç”¨æˆ·æŸ¥è¯¢

        è¿”å›:
            str: æœç´¢ç»“æœæ–‡æœ¬
        """
        try:
            # ä»æŸ¥è¯¢ä¸­æå–ä¸Šä¸‹æ–‡
            text_query, context = self._parse_query_argument(query)

            # ç”Ÿæˆéšæœºä¼šè¯ID
            session_id = f"session_{int(time.time())}"

            # è°ƒç”¨æœç´¢æ–¹æ³•
            result = await self._async_search(text_query, session_id=session_id, has_thoughts=True, context=context)

            # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
            if "error" in result:
                error_msg = f"æœç´¢å¤±è´¥: {result['error'].get('message', 'æœªçŸ¥é”™è¯¯')}"
                logger.error(f"[A2Aè°ƒç”¨] {error_msg}")
                return error_msg

            # æå–ç»“æœæ–‡æœ¬
            if "output" in result and "text" in result["output"]:
                response_text = result["output"]["text"]
                logger.info(f"[A2Aè°ƒç”¨] è¿”å›ç»“æœ: {response_text[:50]}..." if len(response_text) > 50 else f"[A2Aè°ƒç”¨] è¿”å›ç»“æœ: {response_text}")
                return response_text
            else:
                # å°è¯•å°†æ•´ä¸ªç»“æœè½¬ä¸ºå­—ç¬¦ä¸²è¿”å›
                logger.warning("[A2Aè°ƒç”¨] æ— æ³•æå–æ–‡æœ¬ç»“æœï¼Œè¿”å›æ•´ä¸ªç»“æœ")
                return f"æœç´¢ç»“æœ: {json.dumps(result, ensure_ascii=False)}"

        except Exception as e:
            error_msg = f"å¤„ç†æœç´¢è¯·æ±‚æ—¶å‡ºé”™: {str(e)}"
            logger.error(f"[A2Aè°ƒç”¨] {error_msg}")
            return error_msg

    async def _async_search(self, query: str, session_id: Optional[str] = None,
                    memory_id: Optional[str] = None, has_thoughts: bool = True,
                    rag_options: Optional[Dict[str, Any]] = None,
                    context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œå¼‚æ­¥æœç´¢ - å†…éƒ¨æ–¹æ³•

        å‚æ•°:
            query: æœç´¢æŸ¥è¯¢
            session_id: ä¼šè¯ID
            memory_id: é•¿æœŸè®°å¿†ID
            has_thoughts: æ˜¯å¦åŒ…å«æ€è€ƒè¿‡ç¨‹
            rag_options: æ£€ç´¢é€‰é¡¹
            context: ä¸Šä¸‹æ–‡

        è¿”å›:
            Dict: æœç´¢ç»“æœ
        """
        # å¢åŠ è¯¦ç»†æ—¥å¿—ï¼Œç‰¹åˆ«æ˜¯å¯¹äºåº—é“ºæœç´¢
        if context and "zudao_result" in context:
            logger.info(f"[åº—é“ºæœç´¢] å¼€å§‹ä¸ºåº—é“ºæœç´¢è¯„ä»·: {query}, ä¸Šä¸‹æ–‡åŒ…å«zudaoç»“æœ")

        self.stats["total_requests"] += 1

        if not DASHSCOPE_AVAILABLE:
            error_msg = "DashScope SDKä¸å¯ç”¨ï¼Œæ— æ³•æ‰§è¡Œæœç´¢"
            logger.error(error_msg)
            return {
                "error": {
                    "code": "SDK_NOT_AVAILABLE",
                    "message": error_msg
                }
            }

        try:
            # å¢å¼ºæŸ¥è¯¢ä»¥ä¼˜å…ˆæœç´¢ç¤¾äº¤åª’ä½“å†…å®¹ï¼Œè€ƒè™‘ä¸Šä¸‹æ–‡
            enhanced_query = self._enhance_for_social_media(query, context)

            # æ„å»ºå‚æ•° - ä¿®æ”¹ä¸ºä¸zudao.pyä¸­ä¸€è‡´çš„æ ¼å¼
            kwargs = {
                "api_key": self.api_key,
                "app_id": self.app_id,
                "prompt": enhanced_query,
                "parameters": {"has_thoughts": has_thoughts}
            }

            # æ·»åŠ ä¼šè¯ID
            if session_id:
                kwargs["session_id"] = session_id

            # æ·»åŠ é•¿æœŸè®°å¿†ID
            if memory_id:
                kwargs["memory_id"] = memory_id

            # æ·»åŠ æ£€ç´¢çŸ¥è¯†åº“é€‰é¡¹
            if rag_options:
                if "parameters" not in kwargs:
                    kwargs["parameters"] = {}
                kwargs["parameters"]["rag_options"] = rag_options

            logger.info(f"æ‰§è¡Œæœç´¢: '{enhanced_query}', ä¼šè¯ID: {session_id or 'æ— '}")

            # ä½¿ç”¨SDKè°ƒç”¨
            response = Application.call(**kwargs)

            # æ£€æŸ¥å“åº”
            if response.status_code == HTTPStatus.OK:
                self.stats["successful_requests"] += 1

                # å¤„ç†å“åº”ç»“æœ
                result = self._process_response(response)

                # æ›´æ–°tokenç»Ÿè®¡
                if hasattr(response, 'usage') and hasattr(response.usage, 'models'):
                    for model in response.usage.models:
                        input_tokens = getattr(model, 'input_tokens', 0)
                        output_tokens = getattr(model, 'output_tokens', 0)
                        self.stats["total_tokens"] += (input_tokens + output_tokens)

                # å®Œæˆæœç´¢åæ·»åŠ æ—¥å¿—
                if "output" in result and "text" in result["output"]:
                    if context and "zudao_result" in context:
                        logger.info(f"[åº—é“ºæœç´¢å®Œæˆ] ä¸ºåº—é“ºæœç´¢è¯„ä»·å®Œæˆ: {query[:30]}..., ç»“æœé•¿åº¦:{len(result['output']['text'])}")

                return result
            else:
                self.stats["failed_requests"] += 1
                error_msg = f"æœç´¢è¯·æ±‚å¤±è´¥: çŠ¶æ€ç ={response.status_code}, æ¶ˆæ¯={response.message if hasattr(response, 'message') else 'æœªçŸ¥é”™è¯¯'}"
                logger.error(error_msg)
                return {
                    "error": {
                        "code": response.status_code,
                        "message": response.message if hasattr(response, 'message') else "æœªçŸ¥é”™è¯¯"
                    }
                }
        except Exception as e:
            self.stats["failed_requests"] += 1
            error_msg = f"æœç´¢è¯·æ±‚å¼‚å¸¸: {str(e)}"
            logger.error(error_msg)
            return {
                "error": {
                    "code": 500,
                    "message": error_msg
                }
            }

    def _parse_query_argument(self, query: Any) -> Tuple[str, Optional[Dict[str, Any]]]:
        """
        è§£ææŸ¥è¯¢å‚æ•°ï¼Œæå–æŸ¥è¯¢æ–‡æœ¬å’Œä¸Šä¸‹æ–‡

        å‚æ•°:
            query: æŸ¥è¯¢å‚æ•°ï¼Œå¯èƒ½æ˜¯å­—ç¬¦ä¸²ã€å­—å…¸æˆ–åŒ…å«JSONçš„å­—ç¬¦ä¸²

        è¿”å›:
            (æŸ¥è¯¢æ–‡æœ¬, ä¸Šä¸‹æ–‡å­—å…¸)
        """
        text_query = ""
        context = None

        try:
            # å¤„ç†å­—å…¸ç±»å‹æŸ¥è¯¢
            if isinstance(query, dict):
                # æå–æŸ¥è¯¢æ–‡æœ¬
                if "query" in query:
                    text_query = query["query"]
                elif "text" in query:
                    text_query = query["text"]
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°æŸ¥è¯¢æ–‡æœ¬ï¼Œè½¬ä¸ºå­—ç¬¦ä¸²
                    text_query = str(query)

                # æå–ä¸Šä¸‹æ–‡ä¿¡æ¯
                context = {}
                if "context" in query:
                    context = query["context"]
                if "zudao_result" in query:
                    context["zudao_result"] = query["zudao_result"]

            # å¤„ç†å¯èƒ½æ˜¯JSONå­—ç¬¦ä¸²çš„æŸ¥è¯¢
            elif isinstance(query, str):
                # å°è¯•è§£æä¸ºJSON
                if query.strip().startswith("{"):
                    try:
                        query_data = json.loads(query)
                        return self._parse_query_argument(query_data)  # é€’å½’å¤„ç†è§£æåçš„å­—å…¸
                    except json.JSONDecodeError:
                        # è§£æå¤±è´¥ï¼Œå°†æ•´ä¸ªå­—ç¬¦ä¸²è§†ä¸ºæŸ¥è¯¢
                        text_query = query
                else:
                    # ä¸æ˜¯JSONæ ¼å¼ï¼Œå°†æ•´ä¸ªå­—ç¬¦ä¸²è§†ä¸ºæŸ¥è¯¢
                    text_query = query
            else:
                # å…¶ä»–ç±»å‹ï¼Œè½¬ä¸ºå­—ç¬¦ä¸²ä½œä¸ºæŸ¥è¯¢
                text_query = str(query)

        except Exception as e:
            logger.error(f"è§£ææŸ¥è¯¢å‚æ•°æ—¶å‡ºé”™: {str(e)}")
            text_query = str(query)  # å¤±è´¥æ—¶å›é€€åˆ°å­—ç¬¦ä¸²è½¬æ¢

        # ç¡®ä¿æŸ¥è¯¢æ–‡æœ¬ä¸ä¸ºç©º
        if not text_query or text_query.strip() == "":
            text_query = "ç™¾åº¦ä¸€ä¸‹" # é»˜è®¤æŸ¥è¯¢

        return text_query, context

    # ä¿ç•™åŸæœ‰çš„APIçŠ¶æ€è·å–åŠŸèƒ½
    def get_api_status(self) -> Dict[str, Any]:
        """
        è·å–APIçŠ¶æ€

        è¿”å›:
            APIçŠ¶æ€ä¿¡æ¯
        """
        return {
            "api_key_set": bool(self.api_key),
            "app_id_set": bool(self.app_id),
            "dashscope_available": DASHSCOPE_AVAILABLE,
            "stats": {
                "total_requests": self.stats["total_requests"],
                "successful_requests": self.stats["successful_requests"],
                "failed_requests": self.stats["failed_requests"],
                "total_tokens": self.stats["total_tokens"],
                "uptime_seconds": int(time.time() - self.stats["start_time"])
            }
        }

    # ä¿ç•™åŸæœ‰çš„åŠŸèƒ½ï¼Œåªæ˜¯ä¸å†å¯¹å¤–æš´éœ²
    def _extract_topic_interests(self, query: str) -> List[str]:
        """
        ä»æŸ¥è¯¢ä¸­æå–ä¸»é¢˜å…´è¶£

        å‚æ•°:
            query: ç”¨æˆ·æŸ¥è¯¢

        è¿”å›:
            ä¸»é¢˜å…´è¶£åˆ—è¡¨
        """
        # äº§å“ç±»ä¸»é¢˜è¯†åˆ«
        product_categories = ["æ‰‹æœº", "ç”µè„‘", "ç›¸æœº", "å¹³æ¿", "è€³æœº", "æ‰‹è¡¨", "å®¶ç”µ",
                             "æŠ¤è‚¤", "å½©å¦†", "æœè£…", "é‹å­", "åŒ…åŒ…", "é£Ÿå“", "é¥®æ–™"]

        # æœåŠ¡ç±»ä¸»é¢˜è¯†åˆ«
        service_categories = ["é…’åº—", "é¤å…", "æŒ‰æ‘©", "è¶³æµ´", "ç¾å‘", "ç¾ç”²", "å¥èº«",
                             "æ—…æ¸¸", "å­¦ä¹ ", "åŒ»ç–—", "åŸ¹è®­"]

        # è¯†åˆ«å‡ºç°åœ¨æŸ¥è¯¢ä¸­çš„ä¸»é¢˜
        interests = []
        for category in product_categories + service_categories:
            if category in query:
                interests.append(category)

        return interests

    def _detect_intent_type(self, query: str) -> str:
        """
        æ£€æµ‹æŸ¥è¯¢æ„å›¾ç±»å‹

        å‚æ•°:
            query: ç”¨æˆ·æŸ¥è¯¢

        è¿”å›:
            æ„å›¾ç±»å‹: "complementary"(è¡¥å……), "verification"(éªŒè¯) æˆ– "general"(ä¸€èˆ¬)
        """
        if any(keyword in query for keyword in self.COMPLEMENTARY_INTENT_KEYWORDS):
            return "complementary"

        if any(keyword in query for keyword in self.VERIFICATION_INTENT_KEYWORDS):
            return "verification"

        return "general"

    def _extract_stores_from_zudao(self, zudao_result: str) -> List[Dict[str, Any]]:
        """
        ä»zudaoå·¥å…·è¿”å›çš„ç»“æœä¸­æå–åº—é“ºä¿¡æ¯

        å‚æ•°:
            zudao_result: zudaoå·¥å…·è¿”å›çš„æ•°æ®ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–åº—é“ºåˆ—è¡¨

        è¿”å›:
            åº—é“ºä¿¡æ¯åˆ—è¡¨
        """
        stores = []

        # æ£€æŸ¥è¾“å…¥
        if not zudao_result:
            logger.warning("_extract_stores_from_zudao: è¾“å…¥ä¸ºç©º")
            return stores

        try:
            # 1. å¦‚æœè¾“å…¥å·²ç»æ˜¯å­—å…¸åˆ—è¡¨ï¼Œç›´æ¥ä½¿ç”¨
            if isinstance(zudao_result, list):
                logger.info("è¾“å…¥å·²ç»æ˜¯åˆ—è¡¨ï¼Œç›´æ¥æå–åº—é“ºä¿¡æ¯")
                for item in zudao_result:
                    if isinstance(item, dict) and "name" in item:
                        stores.append(item)
                return stores

            # 2. å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå¯èƒ½éœ€è¦è§£æJSON
            if isinstance(zudao_result, str):
                try:
                    # å°è¯•è§£æJSON
                    parsed_data = json.loads(zudao_result)

                    # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œå°è¯•æå–åº—é“ºä¿¡æ¯
                    if isinstance(parsed_data, list):
                        for item in parsed_data:
                            if isinstance(item, dict) and "name" in item:
                                stores.append(item)
                        if stores:
                            return stores
                except json.JSONDecodeError:
                    # ä¸æ˜¯æœ‰æ•ˆçš„JSONï¼Œä½¿ç”¨æ–‡æœ¬è§£æ
                    pass
                except Exception as e:
                    logger.error(f"è§£æJSONæ—¶å‡ºé”™: {str(e)}")

                # 3. ä½¿ç”¨æ–‡æœ¬æ¨¡å¼æ­£åˆ™æå–
                # å°è¯•ä½¿ç”¨å¸¸è§åº—é“ºåˆ—è¡¨æ ¼å¼æå–
                # ä¾‹å¦‚ "1. åº—åA", "2. åº—åB" æˆ– "### 1. åº—åA"
                store_pattern = r'(?:^|\n)(?:#{1,3}\s*)?(\d+)\.\s+([^\n]+)'
                matches = re.finditer(store_pattern, zudao_result)

                for match in matches:
                    store_number = match.group(1)
                    store_name = match.group(2).strip()

                    # åˆ›å»ºåº—é“ºä¿¡æ¯
                    store_info = {"name": store_name}
                    stores.append(store_info)

            logger.info(f"ä»zudaoç»“æœä¸­æå–åˆ° {len(stores)} ä¸ªåº—é“ºä¿¡æ¯")

        except Exception as e:
            logger.error(f"æå–åº—é“ºä¿¡æ¯æ—¶å‡ºé”™: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())

        return stores

    def _build_enhanced_query(self, query: str, stores: List[Dict[str, Any]], intent_type: str) -> str:
        """
        åŸºäºåº—é“ºä¿¡æ¯å’Œæ„å›¾æ„å»ºå¢å¼ºæŸ¥è¯¢

        å‚æ•°:
            query: åŸå§‹æŸ¥è¯¢
            stores: ä»zudaoç»“æœæå–çš„åº—é“ºä¿¡æ¯
            intent_type: æŸ¥è¯¢æ„å›¾ç±»å‹

        è¿”å›:
            å¢å¼ºåçš„æŸ¥è¯¢
        """
        if not stores:
            return query

        # å–å‰ä¸¤å®¶åº—é“ºæ„å»ºæŸ¥è¯¢
        target_stores = stores[:2]
        store_names = [store["name"] for store in target_stores if "name" in store]

        if not store_names:
            return query

        # æ ¹æ®æ„å›¾ç±»å‹æ„å»ºä¸åŒçš„æŸ¥è¯¢
        if intent_type == "verification":
            # éªŒè¯ç±»æŸ¥è¯¢ï¼Œå…³æ³¨çœŸå®æ€§å’Œè¯„ä»·
            store_str = 'å’Œ'.join(store_names)
            return f"å®æ—¶æœç´¢å…¨ç½‘å…³äº{store_str}çš„æŠ€å¸ˆ ç¾å¥³ å°å¦¹ æ¨¡ç‰¹ æ¼”å‘˜ï¼Œé‡ç‚¹æŸ¥æ‰¾æŠ–éŸ³å¿«æ‰‹ç­‰çŸ­è§†é¢‘å¹³å°åŠå¹´å†…çš„çœŸå®è¯„ä»·å’Œç”¨æˆ·ä½“éªŒ"

        elif intent_type == "complementary":
            # è¡¥å……ç±»æŸ¥è¯¢ï¼Œå¯»æ‰¾æ›´å¤šè¯¦æƒ…
            store_str = 'æˆ–'.join(store_names)
            return f"å®æ—¶æœç´¢å…¨ç½‘å…³äº{store_str}çš„æŠ€å¸ˆ ç¾å¥³ å°å¦¹ æ¨¡ç‰¹ æ¼”å‘˜è¯¦ç»†ä¿¡æ¯ï¼Œé‡ç‚¹å…³æ³¨æŠ–éŸ³å¿«æ‰‹ç­‰å¹³å°åŠå¹´å†…çš„æœåŠ¡ç‰¹è‰²ã€é¢œå€¼è¯„ä»·å’Œç”¨æˆ·å®é™…ä½“éªŒ"

        else:
            # ä¸€èˆ¬æŸ¥è¯¢ï¼Œè·å–ç»¼åˆä¿¡æ¯
            store_str = 'å’Œ'.join(store_names)
            return f"å®æ—¶æœç´¢å…¨ç½‘å…³äº{store_str}çš„æŠ€å¸ˆ ç¾å¥³ å°å¦¹ æ¨¡ç‰¹ æ¼”å‘˜ï¼ŒæŸ¥è¯¢æŠ–éŸ³å¿«æ‰‹ç­‰å¹³å°åŠå¹´å†…çš„æœåŠ¡é¡¹ç›®ã€é¢œå€¼ä»‹ç»å’Œç”¨æˆ·çœŸå®ä½“éªŒ"

    def _enhance_for_social_media(self, query: str, context: Optional[Dict[str, Any]] = None) -> str:
        """
        å¢å¼ºæŸ¥è¯¢ä»¥ä¼˜å…ˆæœç´¢ç¤¾äº¤åª’ä½“å†…å®¹ï¼Œå¦‚æœæ˜¯ä»zudaoè¿‡æ¥çš„æŸ¥è¯¢ä¼šæ·»åŠ é¢å¤–ä¿¡æ¯

        Args:
            query: åŸå§‹æŸ¥è¯¢
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¯èƒ½åŒ…å«zudao_resultæˆ–ç®€åŒ–çš„store_name
        """
        # è®°å½•åŸå§‹æŸ¥è¯¢
        original_query = query
        enhanced_query = query

        # æ£€æŸ¥ä¸Šä¸‹æ–‡ - æ”¯æŒæ–°çš„ç®€åŒ–ç‰ˆcontextæ ¼å¼
        store_context = False
        if context:
            if "zudao_result" in context and context["zudao_result"]:
                store_context = True
            elif "store_name" in context and context["store_name"]:
                store_context = True

        # å¦‚æœæŸ¥è¯¢æ¥è‡ªäºå•†åº—è¯„ä»·
        if store_context:
            # ç¡®ä¿åŒ…å«ç¤¾äº¤åª’ä½“å’Œè¯„ä»·å…³é”®è¯
            # å…ˆæ£€æŸ¥æ˜¯å¦å·²ç»åŒ…å«äº†è¯„ä»·å…³é”®è¯
            has_review_term = any(term in query.lower() for term in ["è¯„ä»·", "æ€ä¹ˆæ ·", "å¥½ä¸å¥½", "ä½“éªŒ"])

            if not has_review_term:
                enhanced_query = f"{query} çœŸå®è¯„ä»·"

            # æ·»åŠ ç¤¾äº¤åª’ä½“å¹³å°å…³é”®è¯ï¼Œä¼˜å…ˆæœç´¢ç¤¾äº¤åª’ä½“å†…å®¹
            platforms = random.sample(self.SOCIAL_PLATFORMS, min(2, len(self.SOCIAL_PLATFORMS)))
            if not any(platform in enhanced_query for platform in self.SOCIAL_PLATFORMS):
                enhanced_query = f"{enhanced_query} {platforms[0]}"

        # 1. é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰ä¸Šä¸‹æ–‡ï¼Œå¹¶ä¸”ä¸Šä¸‹æ–‡ä¸­åŒ…å«zudaoç»“æœ
        if context and "zudao_result" in context:
            zudao_result = context["zudao_result"]

            # è°ƒè¯•è¾“å‡º
            logger.info(f"[å¢å¼ºæŸ¥è¯¢] æ¥æ”¶åˆ°zudaoç»“æœç±»å‹: {type(zudao_result)}")

            # æå–åº—é“ºä¿¡æ¯
            stores = self._extract_stores_from_zudao(zudao_result)

            # æ‰“å°æå–ç»“æœ
            if stores:
                logger.info(f"[å¢å¼ºæŸ¥è¯¢] æˆåŠŸæå–{len(stores)}å®¶åº—é“º: {[s.get('name', 'æœªçŸ¥') for s in stores]}")
            else:
                logger.info("[å¢å¼ºæŸ¥è¯¢] æœªä»ä¸Šä¸‹æ–‡æå–åˆ°åº—é“ºä¿¡æ¯")

            # å¦‚æœæ‰¾åˆ°åº—é“ºä¿¡æ¯ï¼ŒåŸºäºåº—é“ºæ„å»ºå¢å¼ºæŸ¥è¯¢
            if stores:
                # è¯†åˆ«æŸ¥è¯¢æ„å›¾ç±»å‹
                intent_type = self._detect_intent_type(query)

                # æ„å»ºå¢å¼ºæŸ¥è¯¢
                enhanced_query = self._build_enhanced_query(query, stores, intent_type)

                logger.info(f"åŸºäºzudaoä¸Šä¸‹æ–‡å¢å¼ºæŸ¥è¯¢: '{query}' -> '{enhanced_query}'")
                return enhanced_query

        # 2. æ£€æŸ¥æŸ¥è¯¢æ˜¯å¦å·²ç»åŒ…å«ç¤¾äº¤åª’ä½“å…³é”®è¯
        has_social_keyword = any(platform in query for platform in self.SOCIAL_PLATFORMS)

        # å¦‚æœå·²åŒ…å«ç¤¾äº¤åª’ä½“å…³é”®è¯ï¼Œæ— éœ€å¢å¼º
        if has_social_keyword:
            return query

        # 3. æ£€æŸ¥æ˜¯å¦åŒ…å«è¶³æµ´æŠ€å¸ˆç›¸å…³å…³é”®è¯
        has_technician_keyword = any(keyword in query for keyword in self.MASSAGE_TECHNICIAN_KEYWORDS)
        if has_technician_keyword:
            social_platforms = "æŠ–éŸ³å¿«æ‰‹ç­‰çŸ­è§†é¢‘å¹³å°"
            tech_enhanced_query = f"å®æ—¶æœç´¢å…¨ç½‘å…³äº{query}çš„æŠ€å¸ˆ ç¾å¥³ å°å¦¹ æ¨¡ç‰¹ æ¼”å‘˜ï¼Œé‡ç‚¹æŸ¥æ‰¾{social_platforms}åŠå¹´å†…çš„çœŸå®ç”¨æˆ·è¯„ä»·å’Œä½“éªŒ"
            logger.info(f"æŠ€å¸ˆæœåŠ¡æŸ¥è¯¢å¢å¼º: '{query}' -> '{tech_enhanced_query}'")
            return tech_enhanced_query

        # 4. åˆ†ææŸ¥è¯¢æ„å›¾ï¼Œåˆ¤æ–­æ˜¯å¦é€‚åˆç¤¾äº¤åª’ä½“æœç´¢
        info_seeking_keywords = ["æ€ä¹ˆæ ·", "å¦‚ä½•", "æ•™ç¨‹", "æ¨è", "è¯„ä»·", "ä½“éªŒ", "æ•ˆæœ", "åˆ†äº«", "å¿ƒå¾—"]
        trend_keywords = ["æµè¡Œ", "çƒ­é—¨", "è¶‹åŠ¿", "æœ€è¿‘", "æœ€æ–°", "æ½®æµ", "ç½‘çº¢"]

        is_info_seeking = any(keyword in query for keyword in info_seeking_keywords)
        is_trend_related = any(keyword in query for keyword in trend_keywords)

        # å¦‚æœæ˜¯ä¿¡æ¯æŸ¥è¯¢æˆ–è¶‹åŠ¿ç›¸å…³æŸ¥è¯¢ï¼Œå¢å¼ºä¸ºç¤¾äº¤åª’ä½“æœç´¢
        if is_info_seeking or is_trend_related:
            social_platforms = "æŠ–éŸ³å¿«æ‰‹ç­‰çŸ­è§†é¢‘å¹³å°"
            enhanced_query = f"å®æ—¶æœç´¢{query}åœ¨{social_platforms}åŠå¹´å†…çš„ç›¸å…³å†…å®¹"
            logger.info(f"æŸ¥è¯¢å¢å¼º: '{query}' -> '{enhanced_query}'")
            return enhanced_query

        # 5. æå–ä¸»é¢˜å…´è¶£ï¼Œå°è¯•æ„å»ºæ›´ç²¾ç¡®çš„æŸ¥è¯¢
        interests = self._extract_topic_interests(query)
        if interests:
            topic_str = 'ã€'.join(interests)
            social_platforms = "æŠ–éŸ³å¿«æ‰‹ç­‰çŸ­è§†é¢‘å¹³å°"
            topic_enhanced_query = f"å®æ—¶æœç´¢{query}å…³äº{topic_str}åœ¨{social_platforms}åŠå¹´å†…çš„ç›¸å…³å†…å®¹"
            logger.info(f"ä¸»é¢˜å…´è¶£æŸ¥è¯¢å¢å¼º: '{query}' -> '{topic_enhanced_query}'")
            return topic_enhanced_query

        return query

    def _process_response(self, response) -> Dict[str, Any]:
        """
        å¤„ç†APIå“åº”

        å‚æ•°:
            response: APIå“åº”å¯¹è±¡

        è¿”å›:
            å¤„ç†åçš„ç»“æœ
        """
        # ä»å¯¹è±¡è½¬ä¸ºå­—å…¸
        result = {
            "output": {},
            "request_id": response.request_id if hasattr(response, 'request_id') else None
        }

        # å¤„ç†è¾“å‡º
        if hasattr(response, 'output'):
            if hasattr(response.output, 'text'):
                result["output"]["text"] = response.output.text
            if hasattr(response.output, 'thoughts'):
                result["output"]["thoughts"] = response.output.thoughts
            if hasattr(response.output, 'doc_references'):
                result["output"]["doc_references"] = response.output.doc_references
            if hasattr(response.output, 'finish_reason'):
                result["output"]["finish_reason"] = response.output.finish_reason
            if hasattr(response.output, 'session_id'):
                result["output"]["session_id"] = response.output.session_id

        # å¤„ç†ä½¿ç”¨ä¿¡æ¯
        if hasattr(response, 'usage'):
            result["usage"] = {}
            if hasattr(response.usage, 'models'):
                result["usage"]["models"] = []
                for model in response.usage.models:
                    model_info = {}
                    if hasattr(model, 'model_id'):
                        model_info["model_id"] = model.model_id
                    if hasattr(model, 'input_tokens'):
                        model_info["input_tokens"] = model.input_tokens
                    if hasattr(model, 'output_tokens'):
                        model_info["output_tokens"] = model.output_tokens
                    result["usage"]["models"].append(model_info)

        return result

    # å®ç°A2Aæ ‡å‡†èƒ½åŠ›æ–¹æ³•
    def get_capabilities(self) -> List[str]:
        """è·å–å·¥å…·èƒ½åŠ›åˆ—è¡¨

        Returns:
            List[str]: èƒ½åŠ›åˆ—è¡¨
        """
        return [
            "æ™ºèƒ½æœç´¢",
            "ç¤¾äº¤åª’ä½“å†…å®¹ä¼˜å…ˆ",
            "åº—é“ºå’ŒæœåŠ¡åˆ†æ",
            "ç”¨æˆ·è¯„ä»·æå–",
            "ä¸Šä¸‹æ–‡å¢å¼ºæœç´¢"
        ]

    def get_examples(self) -> List[str]:
        """è·å–å·¥å…·ç¤ºä¾‹åˆ—è¡¨

        Returns:
            List[str]: ç¤ºä¾‹åˆ—è¡¨
        """
        return [
            "iPhone 15æœ€æ–°è¯„ä»·",
            "åŒ—äº¬æœ€å¥½çš„ç«é”…åº—æ¨è", 
            "æŠ–éŸ³ä¸Šæœ€ç«çš„å‡è‚¥äº§å“",
            "å¿«æ‰‹çƒ­é—¨ç¾å¦†è¾¾äººæ¨è",
            "å®æ—¶æœç´¢æŠ€å¸ˆæœåŠ¡è¯„ä»·"
        ]

    def _subscribe_to_zudao_events(self):
        """è®¢é˜…è¶³é“å·¥å…·äº‹ä»¶ - ä½¿ç”¨æ ‡å‡†A2Aåè®®"""
        # é˜²æ­¢é‡å¤è®¢é˜… - å¦‚æœæœ€è¿‘10ç§’å†…å·²è®¢é˜…è¿‡ï¼Œè·³è¿‡
        current_time = time.time()
        if self.subscription_id and (current_time - self.last_subscription_time) < 10:
            logger.info(f"[BaiLianTool] è·³è¿‡é‡å¤è®¢é˜…ï¼Œæœ€è¿‘è®¢é˜…ID: {self.subscription_id}")
            return self.subscription_id

        # åœ¨è®¢é˜…å‰å…ˆæ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨æœ‰æ•ˆè®¢é˜…
        try:
            from SmartSisi.llm.agent.a2a_notification import check_subscriptions
            subs = check_subscriptions()

            # æ£€æŸ¥ç™¾ç‚¼å·¥å…·æ˜¯å¦å·²è®¢é˜…store_infoäº‹ä»¶
            for sub_info in subs.get("details", {}).get("bai_lian", []):
                if sub_info.get("method") == "event.store_info":
                    self.subscription_id = sub_info.get("id")
                    self.last_subscription_time = current_time
                    logger.info(f"[BaiLianTool] æ£€æµ‹åˆ°å·²æœ‰store_infoè®¢é˜…ï¼Œä½¿ç”¨ç°æœ‰ID: {self.subscription_id}")
                    return self.subscription_id
        except Exception as e:
            logger.warning(f"[BaiLianTool] æ£€æŸ¥è®¢é˜…çŠ¶æ€æ—¶å‡ºé”™: {str(e)}")

        # å°è¯•è®¢é˜…
        try:
            # å¼•å…¥å¿…è¦çš„ä¾èµ–
            from SmartSisi.llm.agent.a2a_notification import subscribe

            # å®šä¹‰è¦è®¢é˜…çš„äº‹ä»¶åˆ—è¡¨
            events = ["event.store_info"]  # ç›®å‰åªè®¢é˜…åº—é“ºä¿¡æ¯

            # è®°å½•æ—¥å¿—
            logger.info(f"[BaiLianTool] å¼€å§‹è®¢é˜…äº‹ä»¶: {events}")

            # åˆ›å»ºæœ‰æ•ˆçš„å›è°ƒå‡½æ•°
            async def store_info_callback(task):
                # ä½¿ç”¨A2Aå·¥å…·å¤„ç†ä»»åŠ¡
                await self._handle_a2a_task(task)

            # è®¢é˜…ç¬¬ä¸€ä¸ªäº‹ä»¶
            subscription_id = subscribe("bai_lian", events[0], store_info_callback)

            if subscription_id:
                # æ›´æ–°è®¢é˜…çŠ¶æ€
                self.subscription_id = subscription_id
                self.last_subscription_time = current_time

                # è®°å½•æˆåŠŸè®¢é˜…
                logger.info(f"[BaiLianTool] å·²æˆåŠŸè®¢é˜… '{events[0]}', ID: {subscription_id}")

                # ä¸å†å‘é€ç¡®è®¤é€šçŸ¥ï¼Œé¿å…é‡å¤SmartSisiæ ¸å¿ƒæœªæ³¨å†Œé”™è¯¯
                logger.info("[BaiLianTool] å·²æˆåŠŸè®¢é˜…åº—é“ºä¿¡æ¯äº‹ä»¶ï¼Œå¯ä»¥æ¥æ”¶åº—é“ºæ•°æ®")

                return subscription_id
            else:
                logger.error("[BaiLianTool] è®¢é˜…å¤±è´¥ï¼Œæ— è®¢é˜…IDè¿”å›")
                return None

        except Exception as e:
            # è®¢é˜…è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸
            logger.error(f"[BaiLianTool] è®¢é˜…è¿‡ç¨‹å‡ºé”™: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            return None

    def resubscribe(self):
        """é‡æ–°è®¢é˜…äº‹ä»¶ - å¯¹åº”A2Açš„tasks/resubscribeæ–¹æ³•

        ç³»ç»Ÿå¯åŠ¨æˆ–é‡æ–°åˆå§‹åŒ–åè°ƒç”¨æ­¤æ–¹æ³•é‡å»ºè®¢é˜…å…³ç³»
        """
        logger.info("[BaiLianTool] å°è¯•é‡æ–°è®¢é˜…äº‹ä»¶...")

        # ç¡®ä¿å·¥å…·ç®¡ç†å™¨å·²åˆå§‹åŒ–å¹¶æ³¨å†Œå·¥å…·
        try:
            from SmartSisi.llm.agent.a2a_notification import get_tool_manager
            manager = get_tool_manager()

            # æ£€æŸ¥ç®¡ç†å™¨æ˜¯å¦è¿è¡Œ
            if not manager._running:
                logger.warning("[BaiLianTool] å·¥å…·ç®¡ç†å™¨å°šæœªè¿è¡Œï¼Œå°è¯•å¯åŠ¨...")
                manager.start()
                time.sleep(1)  # ç»™å·¥å…·ç®¡ç†å™¨ä¸€äº›æ—¶é—´å¯åŠ¨

                if not manager._running:
                    logger.error("[BaiLianTool] å·¥å…·ç®¡ç†å™¨æ— æ³•å¯åŠ¨ï¼Œé‡è®¢é˜…å°†å¤±è´¥")

            # é‡æ–°æ³¨å†Œå·¥å…·
            manager.register_tool("bai_lian", self)
            logger.info("[BaiLianTool] å·²é‡æ–°æ³¨å†Œåˆ°å·¥å…·ç®¡ç†å™¨")
        except Exception as e:
            logger.error(f"[BaiLianTool] é‡æ–°æ³¨å†Œåˆ°å·¥å…·ç®¡ç†å™¨å¤±è´¥: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())

        # å°è¯•é‡æ–°è®¢é˜…
        sub_id = self._subscribe_to_zudao_events()

        if sub_id:
            logger.info(f"[BaiLianTool] é‡æ–°è®¢é˜…æˆåŠŸï¼ŒID: {sub_id}")
            return True
        else:
            logger.error("[BaiLianTool] é‡æ–°è®¢é˜…å¤±è´¥")
            return False

    async def _handle_a2a_task(self, task):
        """å¤„ç†ä»A2Aæ¡†æ¶æ¥æ”¶åˆ°çš„ä»»åŠ¡"""
        try:
            # è·å–ä¸­è½¬ç«™å®ä¾‹
            try:
                from SmartSisi.llm.transit_station import get_transit_station
                self.transit_station = get_transit_station()

                if self.transit_station:
                    # è·å–ä¸­è½¬ç«™ä¼šè¯IDï¼Œç”¨äºè®°å½•
                    logger.info(f"[BaiLianTool] è·å–åˆ°ä¸­è½¬ç«™å®ä¾‹ï¼Œä¼šè¯ID: {self.transit_station.session_id if hasattr(self.transit_station, 'session_id') else 'æœªçŸ¥'}")

                    # æ£€æŸ¥SmartSisiæ ¸å¿ƒæ˜¯å¦æ³¨å†Œ
                    has_sisi_core = hasattr(self.transit_station, 'sisi_core') and self.transit_station.sisi_core is not None
                    logger.info(f"[BaiLianTool] ä¸­è½¬ç«™SmartSisiæ ¸å¿ƒçŠ¶æ€: {'å·²æ³¨å†Œ' if has_sisi_core else 'æœªæ³¨å†Œ'}")
                else:
                    # æ— æ³•è·å–ä¸­è½¬ç«™å®ä¾‹
                    self.transit_station = None
                    return
            except Exception as e:
                # è·å–ä¸­è½¬ç«™å¤±è´¥
                logger.error(f"[BaiLianTool] è·å–ä¸­è½¬ç«™å®ä¾‹å¤±è´¥: {str(e)}")
                self.transit_station = None
                return

            # æ£€æŸ¥ä¸­è½¬ç«™å®ä¾‹
            if not self.transit_station:
                logger.warning(f"[BaiLianTool] ä¸­è½¬ç«™å®ä¾‹ä¸å¯ç”¨ï¼Œè·³è¿‡å¤„ç†é€šçŸ¥")
                return

            # è¯¦ç»†è®°å½•
            task_id = task.get("id", "æ— ID")
            source = task.get("source", "æœªçŸ¥")
            method = task.get("method", "æœªçŸ¥æ–¹æ³•")

            logger.info(f"[BaiLianTool] æ¥æ”¶åˆ°A2Aä»»åŠ¡: {method}")
            logger.info(f"[BaiLianTool] ä»»åŠ¡æ¥æº: {source}, ID: {task_id}")

            # è®°å½•ä»»åŠ¡æ¥æºä¿¡æ¯
            if source:
                logger.info(f"[BaiLianTool] ä»»åŠ¡æ¥æº: {source}")
            else:
                logger.info(f"[BaiLianTool] ä»»åŠ¡æ¥æº: æœªæŒ‡å®š")

            # æ ¹æ®æ–¹æ³•è·¯ç”±åˆ°å¯¹åº”å¤„ç†å‡½æ•°
            if method == "event.store_info":
                # è®°å½•è¯¦ç»†çš„å‚æ•°ä¿¡æ¯
                params = task.get("params", {})
                logger.info(f"[BaiLianTool] æ”¶åˆ°åº—é“ºä¿¡æ¯äº‹ä»¶ï¼Œå‚æ•°é•¿åº¦: {len(str(params))}")

                # è®¾ç½®æ ‡è®°ï¼Œè¡¨ç¤ºæ­£åœ¨å¤„ç†æ¥è‡ªzudaoçš„åº—é“ºä¿¡æ¯
                # è¿™å¯ä»¥é˜²æ­¢åœ¨ä¸€ä¸ªä¼šè¯ä¸­é‡å¤å¤„ç†ç›¸åŒåº—é“ºä¿¡æ¯
                session_id = task.get("session_id", None) or task_id

                # åˆ›å»ºä¸€ä¸ªå¤„ç†é”å®šé”®ï¼Œç¡®ä¿æ¯ä¸ªä¼šè¯åªå¤„ç†ä¸€æ¬¡
                import hashlib
                params_hash = hashlib.md5(str(params).encode()).hexdigest()[:8]
                processing_key = f"store_info_{session_id}_{params_hash}"

                # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨å¤„ç†è¯¥åº—é“ºé›†åˆ
                if hasattr(self, '_processing_store_keys') and processing_key in self._processing_store_keys:
                    logger.warning(f"[BaiLianTool] å·²åœ¨å¤„ç†è¯¥åº—é“ºé›†åˆï¼Œè·³è¿‡é‡å¤å¤„ç†: {processing_key}")
                    return {"success": False, "error": "é‡å¤å¤„ç†è¢«é˜»æ­¢", "already_processing": True}

                # å­˜å‚¨å¤„ç†é”®
                if not hasattr(self, '_processing_store_keys'):
                    self._processing_store_keys = set()
                self._processing_store_keys.add(processing_key)

                try:
                    # æå–åº—é“ºæ•°æ®ä»¥ä¾¿è®°å½•
                    stores = None
                    try:
                        params = task.get("params", {})
                        stores = params.get("stores", [])  # ç›´æ¥ä»paramsè·å–stores
                    except Exception as e:
                        logger.error(f"è·å–åº—é“ºåˆ—è¡¨å¤±è´¥: {str(e)}")
                        return {"success": False, "error": str(e)}

                    # ç¡®ä¿è·å–åˆ°äº†åº—é“ºåˆ—è¡¨
                    if not stores or len(stores) == 0:
                        logger.warning(f"æ²¡æœ‰æ¥æ”¶åˆ°åº—é“ºä¿¡æ¯")
                        return {"success": False, "error": "æ²¡æœ‰åº—é“ºä¿¡æ¯"}

                    # è·å–åº—é“ºåç§°åˆ—è¡¨
                    store_names = []
                    for store in stores:  # å¤„ç†æ‰€æœ‰åº—é“º
                        if isinstance(store, dict) and "name" in store:
                            store_names.append(store.get("name", "æœªçŸ¥åº—é“º"))

                    if not store_names:
                        logger.warning(f"åº—é“ºä¿¡æ¯ä¸­æ²¡æœ‰åº—é“ºåç§°")
                        return {"success": False, "error": "æ²¡æœ‰æœ‰æ•ˆçš„åº—é“ºåç§°"}

                    logger.info(f"æ”¶åˆ°åº—é“ºä¿¡æ¯: {', '.join(store_names)}")

                    # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨æ‰¹é‡å¤„ç†ä»£æ›¿ä¸€æ¡ä¸€æ¡æœç´¢
                    await self._batch_process_store_reviews(stores)

                    return {"success": True, "message": f"å·²å¯åŠ¨æ‰¹é‡å¤„ç†{len(store_names)}å®¶åº—é“ºçš„è¯„ä»·ä¿¡æ¯"}
                finally:
                    # æ— è®ºæˆåŠŸä¸å¦ï¼Œå¤„ç†å®Œæ¯•åç§»é™¤å¤„ç†é”®
                    self._processing_store_keys.discard(processing_key)
            else:
                # è¯¦ç»†è®°å½•æœªçŸ¥æ–¹æ³•
                logger.warning(f"[BaiLianTool] æ”¶åˆ°æœªçŸ¥æ–¹æ³•: {method}ï¼Œæ— æ³•å¤„ç†")
                logger.warning(f"[BaiLianTool] ä»»åŠ¡è¯¦æƒ…: {json.dumps(task, ensure_ascii=False)[:200]}")
                return {"success": False, "error": f"ä¸æ”¯æŒçš„æ–¹æ³•: {method}"}

        except Exception as e:
            # æ•è·å¹¶è®°å½•æ‰€æœ‰å¼‚å¸¸
            logger.error(f"[BaiLianTool] å¤„ç†A2Aä»»åŠ¡å¼‚å¸¸: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())

            # è¿”å›é”™è¯¯å“åº”
            return {
                "success": False,
                "error": str(e),
                "task_id": task.get("id", "æ— ID")
            }

    async def _handle_store_info_task(self, task):
        """å¤„ç†æ¥æ”¶åˆ°çš„åº—é“ºä¿¡æ¯ä»»åŠ¡

        Args:
            task: æ¥è‡ªzudao_toolçš„åº—é“ºä¿¡æ¯ä»»åŠ¡

        Returns:
            Dict: å¤„ç†ç»“æœ
        """
        try:
            # æå–åº—é“ºæ•°æ®
            params = task.get("params", {})
            stores = params.get("stores", [])

            # ç¡®ä¿è·å–åˆ°äº†åº—é“ºåˆ—è¡¨
            if not stores or len(stores) == 0:
                logger.warning(f"æ²¡æœ‰æ¥æ”¶åˆ°åº—é“ºä¿¡æ¯")
                return {"success": False, "error": "æ²¡æœ‰åº—é“ºä¿¡æ¯"}

            # æå–åº—é“ºåç§°
            store_names = []
            for store in stores:
                if isinstance(store, dict) and "name" in store:
                    store_names.append(store.get("name", "æœªçŸ¥åº—é“º"))

            if not store_names:
                logger.warning(f"åº—é“ºä¿¡æ¯ä¸­æ²¡æœ‰åº—é“ºåç§°")
                return {"success": False, "error": "æ²¡æœ‰æœ‰æ•ˆçš„åº—é“ºåç§°"}

            # æ‰¹é‡å¤„ç†åº—é“ºè¯„ä»· - æ–°å¢åŠŸèƒ½
            await self._batch_process_store_reviews(stores)

            return {"success": True}

        except Exception as e:
            logger.error(f"å¤„ç†åº—é“ºä¿¡æ¯ä»»åŠ¡å¤±è´¥: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            return {"success": False, "error": str(e)}

    async def _batch_process_store_reviews(self, stores):
        """ä¸€æ¬¡æ€§æ±‡æ€»æœç´¢æ‰€æœ‰åº—é“ºçš„è¯„ä»·ä¿¡æ¯

        Args:
            stores: åº—é“ºåˆ—è¡¨
        """
        try:
            # æå–åº—é“ºåç§°
            store_names = [store.get("name", "æœªçŸ¥åº—é“º") for store in stores if isinstance(store, dict) and "name" in store]

            # æ£€æŸ¥ç¼“å­˜ï¼Œè¿‡æ»¤æ‰å·²ç¼“å­˜çš„åº—é“º
            uncached_stores = []
            cached_stores = []
            cached_results = []

            for store in stores:
                store_name = store.get("name", "æœªçŸ¥åº—é“º")
                cached_result = self._get_cached_result(store_name)
                if cached_result:
                    cached_stores.append(store_name)
                    cached_results.append(cached_result)
                    logger.info(f"[ç¼“å­˜å‘½ä¸­] åº—é“º {store_name} ä½¿ç”¨ç¼“å­˜ç»“æœ")
                else:
                    uncached_stores.append(store)

            # å¦‚æœæ‰€æœ‰åº—é“ºéƒ½å·²ç¼“å­˜ï¼Œæ±‡æ€»ç¼“å­˜ç»“æœå¹¶å‘é€
            if not uncached_stores:
                logger.info("[ç¼“å­˜ä¼˜åŒ–] æ‰€æœ‰åº—é“ºéƒ½å·²ç¼“å­˜ï¼Œæ±‡æ€»ç¼“å­˜ç»“æœ")
                combined_cached_result = f"ä¸ºæ‚¨æ‰¾åˆ°ä»¥ä¸‹{len(cached_stores)}å®¶åº—é“ºçš„è¯„ä»·ä¿¡æ¯ï¼š\n\n" + "\n\n".join([
                    f"===== {name}çš„è¯„ä»· =====\n{result}"
                    for name, result in zip(cached_stores, cached_results)
                ])
                await self._send_combined_result(combined_cached_result, cached_stores)
                return

            # ä¸€æ¬¡æ€§æ±‡æ€»æœç´¢æ‰€æœ‰æœªç¼“å­˜çš„åº—é“º
            uncached_names = [store.get("name", "æœªçŸ¥åº—é“º") for store in uncached_stores]

            # æ„å»ºä¸€æ¬¡æ€§æ±‡æ€»æŸ¥è¯¢
            combined_query = f"ä¸€æ¬¡æ€§æ±‡æ€»æœç´¢ä»¥ä¸‹æ‰€æœ‰åº—é“ºçš„è¯„ä»·ä¿¡æ¯ï¼Œè¦æ±‚æ¯å®¶åº—é“ºéƒ½è¦æœ‰è¯¦ç»†åˆ†æ: {', '.join(uncached_names)}"

            # æ‰§è¡Œä¸€æ¬¡æ€§æ±‡æ€»æŸ¥è¯¢
            logger.info(f"[ä¸€æ¬¡æ€§æ±‡æ€»] æ‰§è¡Œæ±‡æ€»æŸ¥è¯¢: {combined_query}")
            simplified_context = {
                "store_names": uncached_names,
                "store_ids": [s.get("id", "") for s in uncached_stores if "id" in s],
                "batch_query": True,
                "one_time_search": True  # æ ‡è®°ä¸ºä¸€æ¬¡æ€§æœç´¢
            }

            # æ‰§è¡ŒæŸ¥è¯¢
            result = await self._async_search(combined_query, simplified_context)

            # å¤„ç†æœç´¢ç»“æœ
            if result and isinstance(result, dict) and "output" in result and "text" in result["output"]:
                search_result = result["output"]["text"]

                # ç¼“å­˜æ‰€æœ‰æœç´¢çš„åº—é“ºç»“æœ
                for store in uncached_stores:
                    store_name = store.get("name", "æœªçŸ¥åº—é“º")
                    self._cache_result(store_name, search_result)

                # åˆå¹¶ç¼“å­˜ç»“æœå’Œæ–°æœç´¢ç»“æœ
                if cached_results:
                    # æœ‰ç¼“å­˜ç»“æœï¼Œéœ€è¦åˆå¹¶
                    cached_part = "\n\n".join([
                        f"===== {name}çš„è¯„ä»· =====\n{result}"
                        for name, result in zip(cached_stores, cached_results)
                    ])
                    combined_result = f"ä¸ºæ‚¨æ‰¾åˆ°ä»¥ä¸‹{len(store_names)}å®¶åº—é“ºçš„è¯„ä»·ä¿¡æ¯ï¼š\n\n{cached_part}\n\n===== æ–°æœç´¢ç»“æœ =====\n{search_result}"
                else:
                    # æ²¡æœ‰ç¼“å­˜ç»“æœï¼Œç›´æ¥ä½¿ç”¨æœç´¢ç»“æœ
                    combined_result = f"ä¸ºæ‚¨æ‰¾åˆ°ä»¥ä¸‹{len(uncached_names)}å®¶åº—é“ºçš„è¯„ä»·ä¿¡æ¯ï¼š\n\n{search_result}"

                # å‘é€åˆå¹¶ç»“æœ
                await self._send_combined_result(combined_result, store_names)
            else:
                logger.warning(f"[ä¸€æ¬¡æ€§æ±‡æ€»] æ±‡æ€»æŸ¥è¯¢æœªè¿”å›æœ‰æ•ˆç»“æœ")

                # ğŸ”¥ ä¿®å¤ï¼šå½“æœç´¢å¤±è´¥æ—¶ï¼Œç”Ÿæˆé»˜è®¤çš„è¡¥å……ä¿¡æ¯
                if cached_results:
                    # æœ‰ç¼“å­˜ç»“æœï¼Œä½¿ç”¨ç¼“å­˜ç»“æœ
                    cached_part = "\n\n".join([
                        f"===== {name}çš„è¯„ä»· =====\n{result}"
                        for name, result in zip(cached_stores, cached_results)
                    ])
                    combined_result = f"ä¸ºæ‚¨æ‰¾åˆ°ä»¥ä¸‹{len(cached_stores)}å®¶åº—é“ºçš„è¯„ä»·ä¿¡æ¯ï¼š\n\n{cached_part}"
                else:
                    # æ²¡æœ‰ç¼“å­˜ç»“æœï¼Œç”Ÿæˆé»˜è®¤çš„è¡¥å……ä¿¡æ¯
                    store_list = ', '.join(store_names)
                    combined_result = f"å“å‘€ï¼Œåˆšæ‰æœç´¢è¿™äº›åº—é“ºçš„è¯¦ç»†è¯„ä»·æ—¶é‡åˆ°äº†ç‚¹é—®é¢˜ï¼š{store_list}ã€‚ä¸è¿‡æˆ‘åˆšæ‰å·²ç»å¸®ä½ æ‰¾åˆ°äº†è¿™äº›åº—é“ºçš„åŸºæœ¬ä¿¡æ¯ï¼Œå»ºè®®ä½ å¯ä»¥ç›´æ¥è”ç³»åº—é“ºå’¨è¯¢å…·ä½“æœåŠ¡å’Œä»·æ ¼ï¼Œæˆ–è€…æŸ¥çœ‹å…¶ä»–è¯„ä»·å¹³å°è·å–æ›´å¤šç”¨æˆ·åé¦ˆå“¦~"

                # å‘é€åˆå¹¶ç»“æœ
                await self._send_combined_result(combined_result, store_names)

        except Exception as e:
            logger.error(f"[ä¸€æ¬¡æ€§æ±‡æ€»] æ‰¹é‡å¤„ç†åº—é“ºè¯„ä»·å¤±è´¥: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())

    async def _send_combined_result(self, combined_result: str, store_names: list):
        """å‘é€åˆå¹¶çš„æœç´¢ç»“æœåˆ°ä¸­è½¬ç«™"""
        try:
            import time  # ğŸ”¥ ä¿®å¤ï¼šåœ¨å‡½æ•°å¼€å§‹å°±å¯¼å…¥time
            import threading

            logger.info(f"[BaiLianTool] ğŸ”¥ _send_combined_resultæ–¹æ³•è¢«è°ƒç”¨ï¼Œåº—é“ºæ•°é‡: {len(store_names)}")

            # æ„å»ºå®Œæ•´é€šçŸ¥
            notification = {
                "content": combined_result,
                "source_tool": self.name,
                "content_type": "text",
                "is_tool_notification": True,
                "for_optimization": True,
                "metadata": {
                    "store_names": store_names,
                    "query_type": "one_time_batch_review",
                    "timestamp": time.time()
                }
            }

            logger.info(f"[BaiLianTool] ğŸ”¥ é€šçŸ¥æ„å»ºå®Œæˆï¼Œå‡†å¤‡æ£€æŸ¥LGç³»ç»ŸçŠ¶æ€")
            # ğŸ”¥ ç®€å•æ–¹æ¡ˆï¼šæ£€æµ‹LGç³»ç»Ÿå…³é—­åå»¶è¿Ÿ10ç§’å‘é€
            def wait_for_lg_close_and_delay():
                """ç­‰å¾…LGç³»ç»Ÿå…³é—­å¹¶å»¶è¿Ÿ10ç§’åå‘é€"""

                def delayed_send():
                    try:
                        # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„LGç³»ç»ŸçŠ¶æ€æ£€æµ‹æ–¹æ³•
                        max_wait = 15  # æœ€å¤šç­‰å¾…15ç§’LGç³»ç»Ÿå…³é—­
                        check_interval = 1  # æ¯1ç§’æ£€æŸ¥ä¸€æ¬¡
                        waited = 0

                        while waited < max_wait:
                            lg_system_running = False
                            try:
                                from core import sisi_booter
                                if hasattr(sisi_booter, 'sisi_core') and hasattr(sisi_booter.sisi_core, 'chatting'):
                                    lg_system_running = sisi_booter.sisi_core.chatting
                                else:
                                    # å¤‡ç”¨æ£€æµ‹æ–¹æ³•
                                    lg_system_running = bool(self.transit_station and self.transit_station.intermediate_states)
                            except Exception as e:
                                logger.error(f"[BaiLianTool] æ£€æµ‹LGç³»ç»ŸçŠ¶æ€å¼‚å¸¸: {str(e)}")
                                lg_system_running = False

                            if not lg_system_running:
                                # LGç³»ç»Ÿå·²å…³é—­
                                logger.info(f"[BaiLianTool] âœ… æ£€æµ‹åˆ°LGç³»ç»Ÿå·²å…³é—­ï¼Œå»¶è¿Ÿ15ç§’åå‘é€è¡¥å……ä¿¡æ¯")
                                time.sleep(15)  # å»¶è¿Ÿ15ç§’
                                break

                            time.sleep(check_interval)
                            waited += check_interval
                            logger.info(f"[BaiLianTool] ç­‰å¾…LGç³»ç»Ÿå’ŒTTSå®Œå…¨ç»“æŸ... ({waited}s/{max_wait}s)")

                        if waited >= max_wait:
                            logger.warning(f"[BaiLianTool] ç­‰å¾…è¶…æ—¶ï¼Œç›´æ¥å‘é€è¡¥å……ä¿¡æ¯")

                        # å‘é€é€šçŸ¥
                        if self.transit_station:
                            res = self.transit_station.add_intermediate_state(notification, self.name, process_immediately=True)
                            if res:
                                logger.info(f"[ä¸€æ¬¡æ€§æ±‡æ€»] âœ… å·²å°†æ±‡æ€»è¯„ä»·ç»“æœå‘é€åˆ°ä¸­è½¬ç«™ï¼Œå…±{len(store_names)}å®¶åº—é“º")
                            else:
                                logger.warning(f"[ä¸€æ¬¡æ€§æ±‡æ€»] âŒ å‘é€åˆ°ä¸­è½¬ç«™å¤±è´¥")
                        else:
                            logger.warning(f"[ä¸€æ¬¡æ€§æ±‡æ€»] âŒ ä¸­è½¬ç«™æœªåˆå§‹åŒ–")

                    except Exception as e:
                        logger.error(f"[BaiLianTool] å»¶è¿Ÿå‘é€å¼‚å¸¸: {str(e)}")

                # å¯åŠ¨å»¶è¿Ÿå‘é€çº¿ç¨‹
                threading.Thread(target=delayed_send, daemon=True).start()
                logger.info(f"[BaiLianTool] ğŸš€ å·²å¯åŠ¨å»¶è¿Ÿå‘é€çº¿ç¨‹ï¼Œç­‰å¾…LGç³»ç»Ÿå…³é—­+10ç§’å»¶è¿Ÿ")

            # å‘é€é€šçŸ¥åˆ°ä¸­è½¬ç«™
            if self.transit_station:
                logger.info(f"[BaiLianTool] ğŸ”¥ ä¸­è½¬ç«™å·²åˆå§‹åŒ–ï¼Œæ£€æŸ¥LGç³»ç»ŸçŠ¶æ€")

                # æ£€æµ‹LGç³»ç»Ÿå’ŒTTSçŠ¶æ€
                lg_system_running = False
                tts_playing = False

                try:
                    from core import sisi_booter
                    # æ£€æµ‹LGç³»ç»Ÿæ˜¯å¦å…³é—­
                    if hasattr(sisi_booter, 'sisi_core') and hasattr(sisi_booter.sisi_core, 'chatting'):
                        lg_system_running = sisi_booter.sisi_core.chatting
                        logger.info(f"[BaiLianTool] LGç³»ç»ŸchattingçŠ¶æ€: {lg_system_running}")
                    else:
                        logger.warning(f"[BaiLianTool] æ— æ³•è·å–LGç³»ç»ŸchattingçŠ¶æ€ï¼Œä½¿ç”¨å¤‡ç”¨æ£€æµ‹")
                        lg_system_running = len(self.transit_station.intermediate_states) > 0
                        logger.info(f"[BaiLianTool] å¤‡ç”¨æ£€æµ‹intermediate_statesæ•°é‡: {len(self.transit_station.intermediate_states)}")

                    # æ£€æµ‹TTSæ˜¯å¦è¿˜åœ¨æ’­æ”¾
                    if hasattr(sisi_booter, 'sisi_core'):
                        # æ£€æŸ¥æ˜¯å¦æ­£åœ¨æ’­æ”¾éŸ³é¢‘
                        if hasattr(sisi_booter.sisi_core, 'speaking'):
                            tts_playing = sisi_booter.sisi_core.speaking

                        # æ£€æŸ¥éŸ³é¢‘é˜Ÿåˆ—æ˜¯å¦è¿˜æœ‰å†…å®¹
                        if hasattr(sisi_booter.sisi_core, 'sound_query') and not sisi_booter.sisi_core.sound_query.empty():
                            tts_playing = True

                        logger.info(f"[BaiLianTool] TTSæ’­æ”¾çŠ¶æ€: {tts_playing}")

                except Exception as e:
                    logger.error(f"[BaiLianTool] æ£€æµ‹ç³»ç»ŸçŠ¶æ€å¼‚å¸¸: {str(e)}")
                    lg_system_running = False
                    tts_playing = False

                # æ£€æŸ¥LGç³»ç»Ÿæ˜¯å¦è¿˜åœ¨è¿è¡Œæˆ–TTSæ˜¯å¦è¿˜åœ¨æ’­æ”¾
                if lg_system_running or tts_playing:
                    # LGç³»ç»Ÿè¿˜åœ¨è¿è¡Œæˆ–TTSè¿˜åœ¨æ’­æ”¾ï¼Œç­‰å¾…å®Œå…¨ç»“æŸåå»¶è¿Ÿå‘é€
                    logger.info(f"[BaiLianTool] æ£€æµ‹åˆ°LGç³»ç»Ÿè¿è¡Œæˆ–TTSæ’­æ”¾ä¸­ï¼Œç­‰å¾…å®Œå…¨ç»“æŸ")
                    wait_for_lg_close_and_delay()
                else:
                    # LGç³»ç»Ÿå·²å…³é—­ä¸”TTSæ’­æ”¾å®Œæ¯•ï¼Œå»¶è¿Ÿ15ç§’åå‘é€
                    logger.info(f"[BaiLianTool] LGç³»ç»Ÿå·²å…³é—­ä¸”TTSæ’­æ”¾å®Œæ¯•ï¼Œå»¶è¿Ÿ15ç§’åå‘é€")

                    def delayed_send():
                        logger.info(f"[BaiLianTool] å¼€å§‹15ç§’å»¶è¿Ÿ...")
                        time.sleep(15)  # å»¶è¿Ÿ15ç§’
                        logger.info(f"[BaiLianTool] å»¶è¿Ÿå®Œæˆï¼Œå‘é€é€šçŸ¥åˆ°ä¸­è½¬ç«™")
                        res = self.transit_station.add_intermediate_state(notification, self.name, process_immediately=True)
                        if res:
                            logger.info(f"[BaiLianTool] âœ… å·²å°†æ±‡æ€»è¯„ä»·ç»“æœå‘é€åˆ°ä¸­è½¬ç«™ï¼Œå…±{len(store_names)}å®¶åº—é“º")
                        else:
                            logger.warning(f"[BaiLianTool] âŒ å‘é€åˆ°ä¸­è½¬ç«™å¤±è´¥")

                    threading.Thread(target=delayed_send, daemon=True).start()
                    logger.info(f"[BaiLianTool] å»¶è¿Ÿå‘é€çº¿ç¨‹å·²å¯åŠ¨")
            else:
                logger.warning(f"[ä¸€æ¬¡æ€§æ±‡æ€»] âŒ ä¸­è½¬ç«™æœªåˆå§‹åŒ–")
        except Exception as e:
            logger.error(f"[ä¸€æ¬¡æ€§æ±‡æ€»] å‘é€åˆå¹¶ç»“æœå¤±è´¥: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())

    async def _process_single_store(self, store):
        """å¤„ç†å•ä¸ªåº—é“ºçš„è¯„ä»· - å·²åºŸå¼ƒï¼Œå¼ºåˆ¶ä½¿ç”¨ä¸€æ¬¡æ€§æ±‡æ€»æœç´¢

        Args:
            store: å•ä¸ªåº—é“ºä¿¡æ¯
        """
        logger.warning("[å¼ºåˆ¶ä¸€æ¬¡æ€§æ±‡æ€»] _process_single_storeå·²åºŸå¼ƒï¼Œå¼ºåˆ¶ä½¿ç”¨ä¸€æ¬¡æ€§æ±‡æ€»æœç´¢")
        # å¼ºåˆ¶è°ƒç”¨æ‰¹é‡å¤„ç†æ–¹æ³•ï¼Œå®ç°ä¸€æ¬¡æ€§æ±‡æ€»æœç´¢
        await self._batch_process_store_reviews([store])

# åœ¨æ¨¡å—çº§åˆ«æ·»åŠ è‡ªåŠ¨é‡è®¢é˜…åŠŸèƒ½
_tool_instance = None

def get_tool_instance():
    """è·å–å·¥å…·å®ä¾‹å•ä¾‹"""
    global _tool_instance
    if _tool_instance is None:
        _tool_instance = BaiLianTool()
    return _tool_instance

def auto_resubscribe():
    """è‡ªåŠ¨é‡æ–°è®¢é˜…å‡½æ•°ï¼Œåœ¨ç³»ç»Ÿå¯åŠ¨æ—¶è°ƒç”¨æˆ–è¿›è¡Œæ•…éšœæ¢å¤

    è¿™ä¸ªå‡½æ•°ä¼šåœ¨åå°å¯åŠ¨ä¸€ä¸ªçº¿ç¨‹ï¼Œå°è¯•é‡æ–°è®¢é˜…ç™¾ç‚¼å·¥å…·åˆ°A2Aäº‹ä»¶ç³»ç»Ÿ
    å¦‚æœç«‹å³æˆåŠŸï¼Œè¿”å›Trueï¼›å¦‚æœéœ€è¦åå°é‡è¯•ï¼Œè¿”å›False
    """
    logger.info("[BaiLianTool] æ­£åœ¨å‡†å¤‡è‡ªåŠ¨é‡æ–°è®¢é˜…...")

    try:
        # é¦–å…ˆç¡®ä¿ç™¾ç‚¼å·¥å…·å®ä¾‹å·²åˆ›å»º
        bailian = get_tool_instance()

        # å¦‚æœå·²æœ‰è®¢é˜…IDå¹¶ä¸”æœ€è¿‘10ç§’å†…è®¢é˜…è¿‡ï¼Œè·³è¿‡é‡å¤è®¢é˜…
        if bailian.subscription_id and (time.time() - bailian.last_subscription_time < 10):
            logger.info(f"[BaiLianTool] å·²æœ‰æœ€è¿‘æœ‰æ•ˆè®¢é˜…ï¼ŒID: {bailian.subscription_id}")
            return True

        # é¦–å…ˆå°è¯•ç›´æ¥è®¢é˜…ï¼Œè¿™ä¼šè‡ªåŠ¨æ£€æŸ¥æ˜¯å¦æœ‰ç°æœ‰è®¢é˜…
        sub_id = bailian._subscribe_to_zudao_events()
        if sub_id:
            logger.info(f"[BaiLianTool] å·²æˆåŠŸæ£€æŸ¥æˆ–åˆ›å»ºè®¢é˜…: {sub_id}")
            return True

        # å¦‚æœç›´æ¥è®¢é˜…å¤±è´¥ï¼Œå®‰æ’åå°é‡è¯•
        logger.info("[BaiLianTool] ç›´æ¥è®¢é˜…å¤±è´¥ï¼Œå®‰æ’åå°é‡è¯•...")

        # åœ¨åå°çº¿ç¨‹ä¸­è¿›è¡Œé‡è¯•
        def delayed_resubscribe():
            # ğŸ”¥ ä¿®å¤ï¼šå‡å°‘é¦–æ¬¡ç­‰å¾…æ—¶é—´è‡³1ç§’ï¼Œé¿å…3åˆ†é’Ÿå»¶è¿Ÿ
            logger.info("[BaiLianTool] å·²å®‰æ’è‡ªåŠ¨é‡è®¢é˜…ï¼Œå°†åœ¨1ç§’åå†æ¬¡å°è¯•")
            time.sleep(1)  # ä»5ç§’æ”¹ä¸º1ç§’

            # é‡è¯•è®¡æ•°
            retry_count = 0
            max_retries = 5  # å¢åŠ é‡è¯•æ¬¡æ•°ï¼Œä½†å‡å°‘å»¶è¿Ÿ
            base_delay = 2  # å‡å°‘åŸºç¡€å»¶è¿Ÿ

            while retry_count < max_retries:
                try:
                    # å¢åŠ é‡è¯•å»¶è¿Ÿï¼Œé¿å…è¿‡äºé¢‘ç¹
                    retry_delay = base_delay + retry_count * 2

                    # è·å–ç™¾ç‚¼å·¥å…·å®ä¾‹
                    bailian = get_tool_instance()

                    # å°è¯•è®¢é˜…
                    sub_id = bailian._subscribe_to_zudao_events()
                    if sub_id:
                        logger.info(f"[BaiLianTool] é‡è¯•è®¢é˜…æˆåŠŸï¼ŒID: {sub_id}")
                        break

                    # å¢åŠ é‡è¯•è®¡æ•°
                    retry_count += 1
                    logger.info(f"[BaiLianTool] è®¢é˜…é‡è¯• {retry_count}/{max_retries} å¤±è´¥ï¼Œå°†åœ¨ {retry_delay} ç§’åå†æ¬¡å°è¯•")
                    time.sleep(retry_delay)

                except Exception as e:
                    retry_count += 1
                    logger.error(f"[BaiLianTool] è‡ªåŠ¨é‡è®¢é˜…å¼‚å¸¸: {str(e)}")
                    time.sleep(retry_delay)

            if retry_count >= max_retries:
                logger.error(f"[BaiLianTool] è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° {max_retries}ï¼Œè‡ªåŠ¨é‡è®¢é˜…å¤±è´¥")

        # å¯åŠ¨åå°çº¿ç¨‹
        import threading
        threading.Thread(target=delayed_resubscribe, daemon=True).start()
        return False

    except Exception as e:
        logger.error(f"[BaiLianTool] è‡ªåŠ¨é‡è®¢é˜…å‡ºé”™: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return False

# å¯åŠ¨è‡ªåŠ¨é‡è®¢é˜…
auto_resubscribe()

# ç»“å°¾æ·»åŠ åˆ›å»ºå·¥å…·å®ä¾‹çš„å‡½æ•°
def create_tool():
    """åˆ›å»ºå·¥å…·å®ä¾‹"""
    tool = get_tool_instance()
    return tool

# æ·»åŠ æ¨¡å—çº§invokeå‡½æ•°ä¾›A2AæœåŠ¡å™¨è°ƒç”¨
def invoke(params):
    """
    æ¨¡å—çº§invokeå‡½æ•°ï¼Œä¾›A2AæœåŠ¡å™¨ç›´æ¥è°ƒç”¨

    Args:
        params: è°ƒç”¨å‚æ•°ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–å­—å…¸

    Returns:
        Dict: å·¥å…·æ‰§è¡Œç»“æœ
    """
    logger.info(f"[bai_lian] æ¨¡å—çº§invokeè°ƒç”¨ï¼Œå‚æ•°: {params}")

    # æå–æŸ¥è¯¢æ–‡æœ¬
    text_query = None

    if isinstance(params, dict):
        # å¦‚æœæ˜¯JSON-RPCæ ¼å¼
        if "jsonrpc" in params and "method" in params and "params" in params:
            inner_params = params.get("params", {})
            if isinstance(inner_params, dict):
                text_query = inner_params.get("query", "")
            else:
                text_query = str(inner_params)
        else:
            # å°è¯•è·å–æŸ¥è¯¢å‚æ•°
            text_query = params.get("query", str(params))
    else:
        # å¦‚æœæ˜¯å­—ç¬¦ä¸²æˆ–å…¶ä»–ç±»å‹ï¼Œç›´æ¥ä½œä¸ºæŸ¥è¯¢
        text_query = str(params)

    try:
        # å¤„ç†å¯èƒ½æ˜¯JSONå­—ç¬¦ä¸²çš„æŸ¥è¯¢
        if isinstance(text_query, str) and text_query.strip().startswith("{"):
            try:
                query_data = json.loads(text_query)
                if isinstance(query_data, dict) and "query" in query_data:
                    text_query = query_data["query"]
            except:
                pass

        # ä½¿ç”¨å•ä¾‹æ¨¡å¼è·å–å·¥å…·å®ä¾‹
        tool = get_tool_instance()
        session_id = f"session_{int(time.time())}"

        # ä½¿ç”¨çº¿ç¨‹éš”ç¦»æ–¹å¼ä¿®å¤äº‹ä»¶å¾ªç¯åµŒå¥—é—®é¢˜
        import threading
        result_container = []

        def run_in_thread():
            """åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œå¼‚æ­¥æ“ä½œ"""
            import asyncio
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                result = loop.run_until_complete(tool._async_search(text_query, session_id=session_id, has_thoughts=True))
                result_container.append(result)
            except Exception as e:
                logger.error(f"[bai_lian] çº¿ç¨‹æ‰§è¡Œé”™è¯¯: {str(e)}")
                import traceback
                logger.error(traceback.format_exc())
                result_container.append({"error": str(e)})
            finally:
                loop.close()

        # å¯åŠ¨çº¿ç¨‹å¹¶ç­‰å¾…å®Œæˆ
        t = threading.Thread(target=run_in_thread)
        t.start()
        t.join(timeout=15)  # 15ç§’è¶…æ—¶

        # å¤„ç†ç»“æœ
        if not result_container:
            return {
                "search_result": {
                    "query": text_query,
                    "error": "å¤„ç†è¶…æ—¶æˆ–æœªè¿”å›ç»“æœ",
                    "timestamp": time.time()
                }
            }

        result = result_container[0]

        # æå–ç»“æœæ–‡æœ¬
        response_text = "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
        if "output" in result and "text" in result["output"]:
            response_text = result["output"]["text"]

        # è¿”å›æ ‡å‡†å“åº”æ ¼å¼
        return {
            "search_result": {
                "query": text_query,
                "result": response_text,
                "timestamp": time.time()
            }
        }
    except Exception as e:
        logger.error(f"[bai_lian] å¤„ç†æœç´¢è¯·æ±‚å‡ºé”™: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())

        return {
            "search_result": {
                "query": text_query,
                "error": f"æœç´¢å¤±è´¥: {str(e)}",
                "timestamp": time.time()
            }
        }