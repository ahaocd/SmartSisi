"""
æŠ–éŸ³è¯„è®ºåŒºè·å®¢æ™ºèƒ½ä½“ - è¶…çº§å®Œæ•´ç‰ˆ
ä¸€ä¸ªæ–‡ä»¶æå®šæ‰€æœ‰é€»è¾‘ï¼è‡ªåŠ¨å¯åŠ¨MCPï¼

åŠŸèƒ½ï¼š
1. è‡ªåŠ¨æ£€æµ‹å¹¶å¯åŠ¨mcp-chromeæœåŠ¡
2. å®Œæ•´çš„æµè§ˆå™¨è‡ªåŠ¨åŒ–ï¼ˆç™»å½•ã€æœç´¢ã€è¯„è®ºã€ç§ä¿¡ï¼‰
3. AIæ™ºèƒ½åˆ†æå’Œè¯„è®ºç”Ÿæˆ
4. å®Œæ•´çš„æ•°æ®åº“ç®¡ç†å’Œå»é‡
5. äººç±»è¡Œä¸ºæ¨¡æ‹Ÿå’Œé£æ§è§„é¿
6. é”™è¯¯å¤„ç†å’Œè‡ªåŠ¨é‡è¯•
7. Cookieè‡ªåŠ¨ç®¡ç†
8. ä»»åŠ¡è°ƒåº¦å’Œæ‰§è¡Œ

ä½¿ç”¨æ–¹æ³•ï¼š
    python douyin_marketing_agent_tool.py
"""

import os
import sys
import json
import time
import logging
import asyncio
import aiohttp
import sqlite3
import hashlib
import random
import subprocess
from typing import Dict, Any, List, Optional, Union
from datetime import datetime, timedelta
from difflib import SequenceMatcher
from pathlib import Path

# å¯¼å…¥è¯„è®ºæŠ“å–å™¨
try:
    from media_marketing.get_comments_with_cdp import CommentFetcher
    COMMENT_FETCHER_AVAILABLE = True
except Exception as e:
    COMMENT_FETCHER_AVAILABLE = False
    CommentFetcher = None
    print(f"âš ï¸ CommentFetcherè¯„è®ºæŠ“å–å™¨å¯¼å…¥å¤±è´¥: {e}")

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger("DouyinMarketingAgent")

# OpenAIå…¼å®¹APIå®¢æˆ·ç«¯
try:
    from openai import AsyncOpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    logger.warning("OpenAI SDKæœªå®‰è£…ï¼špip install openai")

# A2Aå·¥å…·åŸºç±»
try:
    from SmartSisi.llm.a2a.base_a2a_tool import StandardA2ATool
    A2A_AVAILABLE = True
except ImportError:
    A2A_AVAILABLE = False
    logger.warning("A2AåŸºç±»æœªæ‰¾åˆ°ï¼Œå°†ä½œä¸ºç‹¬ç«‹è„šæœ¬è¿è¡Œ")
    StandardA2ATool = object  # å ä½ç¬¦


# ==================== MCPæœåŠ¡ç®¡ç†å™¨ ====================
class MCPServiceManager:
    """MCPæœåŠ¡è‡ªåŠ¨ç®¡ç†å™¨"""
    
    def __init__(self):
        self.mcp_url = "http://127.0.0.1:12306/mcp"  # ä½ çš„MCPæ‰©å±•ç«¯å£ï¼ˆçœ‹æˆªå›¾ï¼‰
        self.chrome_extension_path = None
        self.chrome_process = None  # Chromeè¿›ç¨‹
        
    async def check_mcp_chrome_running(self) -> bool:
        """æ£€æŸ¥mcp-chromeæ˜¯å¦è¿è¡Œ"""
        try:
            # ğŸ”¥ ç»•è¿‡VPNä»£ç†
            connector = aiohttp.TCPConnector()
            async with aiohttp.ClientSession(connector=connector, trust_env=False) as session:
                # å‘é€ä¸€ä¸ªç®€å•çš„ MCP è¯·æ±‚æµ‹è¯•è¿æ¥
                payload = {
                    "jsonrpc": "2.0",
                    "method": "tools/list",
                    "params": {},
                    "id": 1
                }
                async with session.post(self.mcp_url, json=payload, timeout=3) as resp:
                    # åªè¦æœåŠ¡å“åº”å°±ç®—æˆåŠŸï¼ˆä¸ç®¡æ˜¯å¦æœ‰é”™è¯¯ï¼‰
                    return resp.status in [200, 400, 500]
        except:
            return False
    
    def find_chrome_extension(self) -> Optional[str]:
        """æŸ¥æ‰¾Chromeæ‰©å±•è·¯å¾„"""
        possible_paths = [
            Path("E:/liusisi/mcpsever/mcp-chrome/releases/chrome-extension/latest/extracted"),
            Path("mcpsever/mcp-chrome/releases/chrome-extension/latest/extracted"),
            Path.home() / "Downloads/mcp-chrome-extension",
        ]
        
        for path in possible_paths:
            if path.exists() and (path / "manifest.json").exists():
                logger.info(f"æ‰¾åˆ°Chromeæ‰©å±•: {path}")
                return str(path)
        
        logger.warning("æœªæ‰¾åˆ°Chromeæ‰©å±•")
        return None
    
    def start_chrome_with_extension(self) -> bool:
        """å¯åŠ¨Chromeæµè§ˆå™¨ï¼ˆä¼˜å…ˆä½¿ç”¨ç”¨æˆ·å·²ç™»å½•çš„é…ç½®æ–‡ä»¶ï¼›å¦‚æ‰¾åˆ°æ‰©å±•åˆ™ä¸€å¹¶åŠ è½½ï¼‰"""
        import subprocess
        import os
        import json
        from pathlib import Path
        
        try:
            # Chromeè·¯å¾„
            chrome_paths = [
                r"C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe",
                r"C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe",
                str(Path.home() / r"AppData\\Local\\Google\\Chrome\\Application\\chrome.exe"),
            ]
            chrome_exe = None
            for path in chrome_paths:
                if Path(path).exists():
                    chrome_exe = str(path)
                    break
            if not chrome_exe:
                logger.error("æœªæ‰¾åˆ°Chromeæµè§ˆå™¨")
                return False
            
            # è¯»å–Chromeç”¨æˆ·ç›®å½•ï¼›å¼ºåˆ¶ä½¿ç”¨ Default é…ç½®ï¼Œé¿å… Guest/è´¦æˆ·é€‰æ‹©å™¨
            user_data_dir = os.path.expandvars(r"%LOCALAPPDATA%\\Google\\Chrome\\User Data")
            profile_dir = "Default"
            local_state = os.path.join(user_data_dir, "Local State")
            try:
                with open(local_state, "r", encoding="utf-8") as f:
                    state = json.load(f)
                last_used = state.get("profile", {}).get("last_used") or profile_dir
                # è‹¥ä¸Šæ¬¡ä¸º Guest Profileï¼Œåˆ™æ”¹ç”¨ Defaultï¼Œé¿å…å¼¹å‡ºé€‰æ‹©ç•Œé¢
                if isinstance(last_used, str) and "guest" not in last_used.lower():
                    profile_dir = last_used
            except Exception:
                # è¯»å–å¤±è´¥åˆ™ä½¿ç”¨ Default
                profile_dir = "Default"
            
            # å¯é€‰ï¼šæŸ¥æ‰¾æ‰©å±•ï¼ˆè‹¥ç”¨æˆ·å·²æœ‰å®‰è£…ï¼Œä¹Ÿæ— éœ€æ­¤å‚æ•°ï¼‰
            extension_path = self.find_chrome_extension()
            
            logger.info(f"å¯åŠ¨Chrome: {chrome_exe}")
            logger.info(f"ä½¿ç”¨ç”¨æˆ·æ•°æ®ç›®å½•: {user_data_dir} | Profile: {profile_dir}")
            if extension_path:
                logger.info(f"åŠ è½½æ‰©å±•: {extension_path}")
            
            args = [
                chrome_exe,
                f"--user-data-dir={user_data_dir}",
                f"--profile-directory={profile_dir}",
                "--no-first-run",
                "--disable-popup-blocking",
                "--disable-infobars",
                "--disable-notifications",
                "--no-default-browser-check",
                "--disable-sync",
                "--disable-features=SignInProfileCreation,BrowserSignin,ChromeSignin",
                "--window-size=1280,800",
                "--window-position=100,100",
                "--new-window",
                "--remote-debugging-port=9222"  # ğŸ”¥ æ·»åŠ è¿œç¨‹è°ƒè¯•ç«¯å£ï¼Œè®©chrome-devtools-mcpå¯ä»¥è¿æ¥
            ]
            if extension_path:
                args.insert(1, f"--load-extension={extension_path}")
            
            self.chrome_process = subprocess.Popen(
                args,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
            )
            logger.info(f"âœ… Chromeå·²å¯åŠ¨ (PID: {self.chrome_process.pid})")
            return True
        except Exception as e:
            logger.error(f"å¯åŠ¨Chromeå¤±è´¥: {e}")
            return False
    
    def start_mcp_chrome_bridge(self) -> bool:
        """å¯åŠ¨mcp-chrome-bridge"""
        try:
            # ä½¿ç”¨npxç›´æ¥è¿è¡Œï¼ˆæ— éœ€å®‰è£…ï¼‰
            logger.info("å¯åŠ¨mcp-chrome-bridge...")
            self.bridge_process = subprocess.Popen(
                ['npx', '-y', 'mcp-chrome-bridge'],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                creationflags=subprocess.CREATE_NO_WINDOW if sys.platform == 'win32' else 0
            )
            
            time.sleep(5)  # ç­‰å¾…å¯åŠ¨
            logger.info(f"âœ… mcp-chrome-bridgeå·²å¯åŠ¨ (PID: {self.bridge_process.pid})")
            return True
            
        except Exception as e:
            logger.error(f"å¯åŠ¨mcp-chrome-bridgeå¤±è´¥: {e}")
            return False
    
    async def ensure_mcp_chrome_ready(self) -> bool:
        """ç¡®ä¿mcp-chromeæœåŠ¡å°±ç»ª - ä½¿ç”¨ç”¨æˆ·å·²æ‰“å¼€çš„Chrome"""
        logger.info("æ£€æŸ¥mcp-chromeæ‰©å±•æœåŠ¡...")
        
        # æ£€æŸ¥æœåŠ¡æ˜¯å¦å·²è¿è¡Œï¼ˆç”¨æˆ·çš„ä¸»Chromeï¼‰
        if await self.check_mcp_chrome_running():
            logger.info("âœ… mcp-chromeæ‰©å±•å·²å°±ç»ªï¼ˆè¿æ¥åˆ°ä½ çš„Chromeï¼‰")
            return True
        
        # æœåŠ¡æœªè¿è¡Œ â†’ è‡ªåŠ¨å¯åŠ¨Chrome
        logger.warning("âš ï¸  MCPæœåŠ¡æœªæ£€æµ‹åˆ°ï¼Œæ­£åœ¨å¯åŠ¨Chrome...")
        
        # å¯åŠ¨Chromeï¼ˆå¸¦æ‰©å±•ï¼‰
        if not self.start_chrome_with_extension():
            logger.error("âŒ å¯åŠ¨Chromeå¤±è´¥")
            return False
        
        # ç­‰å¾…æœåŠ¡å°±ç»ªï¼ˆæœ€å¤š30ç§’ï¼‰
        logger.info("â³ ç­‰å¾…Chromeå’Œæ‰©å±•å¯åŠ¨...")
        for i in range(30):
            await asyncio.sleep(1)
            if await self.check_mcp_chrome_running():
                logger.info("âœ… mcp-chromeæ‰©å±•å·²è¿æ¥ï¼")
                return True
        
        logger.error("âŒ ç­‰å¾…è¶…æ—¶ï¼Œæ‰©å±•æœªå¯åŠ¨")
        return False
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.chrome_process:
            try:
                self.chrome_process.terminate()
                logger.info("Chromeè¿›ç¨‹å·²åœæ­¢")
            except:
                pass


# ==================== Playwright MCPï¼ˆä»…ç”¨äºbrowser_snapshotï¼‰====================
class PlaywrightMCPClient:
    """æœ€å°Playwright MCPå®¢æˆ·ç«¯ï¼ˆstdioï¼‰- åªä¸º browser_snapshot æä¾›æ”¯æŒ"""
    def __init__(self):
        self.proc = None
        self.stdin = None
        self.stdout = None
        self._id = 0

    async def start(self) -> bool:
        if self.proc:
            return True
        try:
            import os as _os
            npx_cmd = _os.environ.get('NPX_PATH') or 'npx'
            self.proc = subprocess.Popen(
                [npx_cmd, '-y', '@playwright/mcp@latest'],
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                bufsize=1
            )
            self.stdin = self.proc.stdin
            self.stdout = self.proc.stdout
            await asyncio.sleep(2)
            logger.info(f"âœ… Playwright MCPå·²å¯åŠ¨ (PID: {self.proc.pid})")
            return True
        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨Playwright MCPå¤±è´¥: {e}")
            return False

    async def call(self, name: str, params: Dict | None = None) -> Dict:
        if not self.proc:
            ok = await self.start()
            if not ok:
                return {}

        # Type safety check: stdin/stdout must be initialized
        if self.stdin is None or self.stdout is None:
            logger.error("stdin/stdout not initialized")
            return {}
        try:
            self._id += 1
            req = {
                "jsonrpc": "2.0",
                "id": self._id,
                "method": "tools/call",
                "params": {"name": name, "arguments": params or {}}
            }
            self.stdin.write(json.dumps(req) + "\n")
            self.stdin.flush()

            # è¯»å–ä¸€è¡Œå“åº”ï¼ˆPlaywright MCPæŒ‰è¡Œè¾“å‡ºSSE/JSONï¼‰
            import time as _t
            deadline = _t.time() + 30
            buf = ""
            while _t.time() < deadline:
                line = self.stdout.readline()
                if not line:
                    await asyncio.sleep(0.05)
                    continue
                buf += line
                # å…ˆå°è¯•ç›´æ¥JSON
                try:
                    obj = json.loads(line)
                    if obj.get('id') == self._id:
                        return obj.get('result', {})
                except Exception:
                    pass
                # å†å°è¯•SSE data: {...}
                try:
                    import re
                    matches = re.findall(r'data: (\{.*?\})\n', buf, re.DOTALL)
                    if matches:
                        last = json.loads(matches[-1])
                        if last.get('id') == self._id:
                            return last.get('result', {})
                except Exception:
                    pass
            return {}
        except Exception as e:
            logger.error(f"Playwright MCPè°ƒç”¨å¤±è´¥: {e}")
            return {}

    async def navigate(self, url: str) -> bool:
        # å°è¯•å¤šç§å€™é€‰å
        for name in ["navigate", "goTo", "goto", "browser_navigate"]:
            res = await self.call(name, {"url": url})
            if isinstance(res, dict):
                return True
        return False

    async def page_down(self, times: int = 1):
        for _ in range(times):
            await self.call("keyboard", {"keys": "PageDown"})
            await asyncio.sleep(0.8)

    async def snapshot(self) -> str:
        for name in ["browser_snapshot", "getSnapshot"]:
            res = await self.call(name, {})
            if isinstance(res, dict):
                content = res.get('content', [])
                if isinstance(content, list) and content:
                    text = content[0].get('text', '')
                    return text or ""
        return ""

    async def close(self):
        try:
            if self.proc:
                self.proc.terminate()
                self.proc = None
        except Exception:
            pass

# ==================== Chrome DevTools MCP ====================
class ChromeDevToolsMCPClient:
    """Chrome DevTools MCPå®¢æˆ·ç«¯ï¼ˆstdioï¼‰- ç”¨äºè·å–ç½‘ç»œè¯·æ±‚å’Œè¯„è®º"""
    def __init__(self, browser_url: str = "http://127.0.0.1:9222"):
        self.proc = None
        self.stdin = None
        self.stdout = None
        self._id = 0
        self.browser_url = browser_url

    async def start(self) -> bool:
        if self.proc:
            return True
        try:
            import os as _os
            npx_cmd = _os.environ.get('NPX_PATH') or 'npx'
            self.proc = subprocess.Popen(
                [npx_cmd, '-y', 'chrome-devtools-mcp@latest', f'--browserUrl={self.browser_url}'],
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                bufsize=1
            )
            self.stdin = self.proc.stdin
            self.stdout = self.proc.stdout
            await asyncio.sleep(5)  # ç­‰å¾…è¿æ¥åˆ°Chrome
            logger.info(f"âœ… Chrome DevTools MCPå·²å¯åŠ¨å¹¶è¿æ¥åˆ° {self.browser_url}")
            return True
        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨Chrome DevTools MCPå¤±è´¥: {e}")
            return False

    async def call(self, name: str, params: Dict | None = None) -> Dict:
        if not self.proc:
            ok = await self.start()
            if not ok:
                return {}

        # Type safety check: stdin/stdout must be initialized
        if self.stdin is None or self.stdout is None:
            logger.error("stdin/stdout not initialized (ChromeDevTools)")
            return {}
        try:
            self._id += 1
            req = {
                "jsonrpc": "2.0",
                "id": self._id,
                "method": "tools/call",
                "params": {"name": name, "arguments": params or {}}
            }
            self.stdin.write(json.dumps(req) + "\n")
            self.stdin.flush()

            # è¯»å–å“åº”
            import time as _t
            deadline = _t.time() + 30
            while _t.time() < deadline:
                line = self.stdout.readline()
                if not line:
                    await asyncio.sleep(0.05)
                    continue

                # å¤„ç†SSEæ ¼å¼ "data: {...}"
                if line.startswith('data: '):
                    line = line[6:]

                try:
                    obj = json.loads(line)
                    if obj.get('id') == self._id:
                        return obj.get('result', {})
                except Exception:
                    pass

            return {}
        except Exception as e:
            logger.error(f"Chrome DevTools MCPè°ƒç”¨å¤±è´¥: {e}")
            return {}

    def cleanup(self):
        if self.proc:
            try:
                self.proc.terminate()
                logger.info("Chrome DevTools MCPè¿›ç¨‹å·²åœæ­¢")
            except:
                pass

# ==================== æµè§ˆå™¨è‡ªåŠ¨åŒ– ====================
class DouyinBrowserAutomation:
    """æŠ–éŸ³æµè§ˆå™¨è‡ªåŠ¨åŒ–ï¼ˆé›†æˆåœ¨ä¸»æ–‡ä»¶ä¸­ï¼‰"""
    
    def __init__(self, mcp_url: str = "http://127.0.0.1:12306/mcp"):
        self.mcp_url = mcp_url
        self.session_id = None  # MCP session ID
        self.tool_map: Dict[str, str] = {}  # é€»è¾‘åâ†’å®é™…å·¥å…·å
        
        # Cookieè·¯å¾„ - ç»Ÿä¸€ä½¿ç”¨ media_marketing ç›®å½•
        cookies_dir = Path(__file__).parent / "media_marketing" / "cookies"
        cookies_dir.mkdir(parents=True, exist_ok=True)
        self.cookie_file = cookies_dir / "douyin_cookies.json"
        
        # é…ç½®
        self.page_load_timeout = 30
        self.element_timeout = 10
        self.current_tab_id = None
        
    async def human_sleep(self, a: float, b: float):
        """äººç±»åŒ–éšæœºç­‰å¾…"""
        await asyncio.sleep(random.uniform(a, b))
        
    async def initialize_session(self):
        """åˆå§‹åŒ–MCP session"""
        if self.session_id:
            return True  # å·²åˆå§‹åŒ–

        try:
            # ğŸ”¥ ç»•è¿‡VPNä»£ç†
            connector = aiohttp.TCPConnector()
            async with aiohttp.ClientSession(connector=connector, trust_env=False) as session:
                payload = {
                    "jsonrpc": "2.0",
                    "method": "initialize",
                    "params": {
                        "protocolVersion": "2024-11-05",
                        "capabilities": {},
                        "clientInfo": {
                            "name": "DouyinMarketingAgent",
                            "version": "1.0.0"
                        }
                    },
                    "id": 1
                }
                
                # å¿…é¡»æ¥å— application/json å’Œ text/event-stream
                headers = {
                    "Accept": "application/json, text/event-stream"
                }
                
                async with session.post(self.mcp_url, json=payload, headers=headers, timeout=10) as resp:
                    # ä»å“åº”å¤´è·å– session ID
                    self.session_id = resp.headers.get('mcp-session-id')
                    
                    # å“åº”å¯èƒ½æ˜¯SSEæ ¼å¼ï¼Œä¸è§£æJSONï¼Œåªè¯»å–æ–‡æœ¬
                    text = await resp.text()
                    
                    if not self.session_id:
                        logger.error(f"æœªè·å–åˆ° session IDï¼Œå“åº”: {text[:200]}")
                        raise Exception("æœªè·å–åˆ° session ID")
                    
                    logger.info(f"âœ… MCP session initialized: {self.session_id[:8]}...")
                    return True
        except Exception as e:
            logger.error(f"MCP sessionåˆå§‹åŒ–å¤±è´¥: {e}")
            return False
        
    async def call_mcp(self, tool_name: str, args: Dict | None = None) -> Dict:
        """è°ƒç”¨MCPå·¥å…·ï¼ˆè‡ªåŠ¨æºå¸¦tabIdå¹¶æ›´æ–°ï¼‰"""
        import json as json_module  # Type safety: import at function start
        if not self.session_id:
            if not await self.initialize_session():
                raise Exception("MCP sessionæœªåˆå§‹åŒ–")
        try:
            # ğŸ”¥ ç»•è¿‡VPNä»£ç†
            connector = aiohttp.TCPConnector()
            async with aiohttp.ClientSession(connector=connector, trust_env=False) as session:
                arguments = args or {}
                # åªæœ‰å½“current_tab_idå­˜åœ¨ä¸”argumentsæ˜¯å­—å…¸æ—¶æ‰è®¾ç½®tabId
                if isinstance(arguments, dict) and self.current_tab_id:
                    arguments.setdefault("tabId", self.current_tab_id)
                payload = {
                    "jsonrpc": "2.0",
                    "method": "tools/call",
                    "params": {"name": tool_name, "arguments": arguments},
                    "id": int(time.time() * 1000)
                }
                headers = {
                    "mcp-session-id": self.session_id,
                    "Accept": "application/json, text/event-stream"
                }
                async with session.post(self.mcp_url, json=payload, headers=headers, timeout=60) as resp:
                    text = await resp.text()
                    try:
                        result = json_module.loads(text)
                        if "error" in result:
                            raise Exception(f"MCPé”™è¯¯: {result['error']}")
                        result_obj = result.get("result", {})
                        # åªæœ‰å½“result_objæ˜¯å­—å…¸ä¸”åŒ…å«tabIdæ—¶æ‰æ›´æ–°current_tab_id
                        if isinstance(result_obj, dict) and "tabId" in result_obj:
                            self.current_tab_id = result_obj.get("tabId")
                        return result_obj
                    except json_module.JSONDecodeError:
                        import re
                        # ğŸ”¥ ä¿®å¤ï¼šæ”¹è¿›SSEè§£æï¼Œæ­£ç¡®å¤„ç†å¤šè¡ŒJSONå’ŒåµŒå¥—å¯¹è±¡
                        # æ–¹æ³•1ï¼šæå–æ‰€æœ‰data:è¡Œï¼Œæ‹¼æ¥åå†è§£æ
                        lines = text.split('\n')
                        data_lines = []
                        for line in lines:
                            if line.startswith('data: '):
                                data_lines.append(line[6:])  # å»æ‰"data: "å‰ç¼€

                        if data_lines:
                            # å°è¯•è§£ææœ€åä¸€ä¸ªå®Œæ•´çš„dataå—
                            for data_json in reversed(data_lines):
                                try:
                                    last_data = json_module.loads(data_json)
                                    if "error" in last_data:
                                        raise Exception(f"MCPé”™è¯¯: {last_data['error']}")
                                    result_obj = last_data.get("result", {})
                                    # åªæœ‰å½“result_objæ˜¯å­—å…¸ä¸”åŒ…å«tabIdæ—¶æ‰æ›´æ–°current_tab_id
                                    if isinstance(result_obj, dict) and "tabId" in result_obj:
                                        self.current_tab_id = result_obj.get("tabId")
                                    return result_obj
                                except:
                                    continue
                            logger.error(f"SSEè§£æå¤±è´¥: æ‰€æœ‰dataå—éƒ½æ— æ³•è§£æ")
                            return {}
                        else:
                            logger.warning(f"MCPå“åº”ä¸æ˜¯JSONä¹Ÿä¸æ˜¯SSE: {text[:100]}")
                            return {}
        except Exception as e:
            error_msg = str(e)
            logger.error(f"MCPè°ƒç”¨å¤±è´¥ [{tool_name}]: {error_msg}")

            # ğŸ”¥ æ£€æµ‹MCPè¿æ¥æ–­å¼€ï¼Œç«‹å³æŠ›å‡ºè‡´å‘½é”™è¯¯åœæ­¢ç¨‹åº
            if "Cannot connect to host" in error_msg or "æ‹’ç»ç½‘ç»œè¿æ¥" in error_msg:
                logger.critical("âŒ MCPè¿æ¥å·²æ–­å¼€ï¼ç¨‹åºç«‹å³åœæ­¢ï¼")
                raise SystemExit("MCPè¿æ¥æ–­å¼€ï¼Œç¨‹åºç»ˆæ­¢")

            # å°è¯•é‡è¿ä¸€æ¬¡
            try:
                self.session_id = None
                await self.initialize_session()
            except Exception:
                pass
            raise

    async def list_tools(self) -> List[str]:
        """åˆ—å‡ºå¯ç”¨å·¥å…·åç§°"""
        if not self.session_id:
            if not await self.initialize_session():
                raise Exception("MCP sessionæœªåˆå§‹åŒ–")
        try:
            # ğŸ”¥ ç»•è¿‡VPNä»£ç†
            connector = aiohttp.TCPConnector()
            async with aiohttp.ClientSession(connector=connector, trust_env=False) as session:
                payload = {
                    "jsonrpc": "2.0",
                    "method": "tools/list",
                    "params": {},
                    "id": int(time.time() * 1000)
                }
                headers = {
                    "mcp-session-id": self.session_id,
                    "Accept": "application/json, text/event-stream"
                }
                async with session.post(self.mcp_url, json=payload, headers=headers, timeout=15) as resp:
                    text = await resp.text()
                    try:
                        import json as json_module
                        data = json_module.loads(text)
                        result = data.get("result", {})
                        tools = [t.get("name") for t in result.get("tools", []) if isinstance(t, dict)]
                        return [t for t in tools if t]
                    except Exception:
                        # SSE fallback
                        import re, json as json_module
                        matches = re.findall(r'data: ({.*?})\n', text, re.DOTALL)
                        if matches:
                            try:
                                obj = json_module.loads(matches[-1])
                                result = obj.get("result", {})
                                tools = [t.get("name") for t in result.get("tools", []) if isinstance(t, dict)]
                                return [t for t in tools if t]
                            except Exception:
                                return []
                        return []
        except Exception as e:
            logger.warning(f"è·å–å·¥å…·åˆ—è¡¨å¤±è´¥: {e}")
            return []

    async def resolve_tool(self, logical: str) -> str:
        """è§£æé€»è¾‘åâ†’çœŸå®å·¥å…·åï¼Œå¸¦ç¼“å­˜ä¸å€™é€‰åå°è¯•"""
        if logical in self.tool_map:
            return self.tool_map[logical]
        candidates_map = {
            "navigate": ["chrome_navigate", "navigate", "goTo", "goto"],
            "browser_snapshot": ["browser_snapshot", "getSnapshot", "chrome_snapshot", "snapshot"],
            "getWebContent": ["chrome_get_web_content", "getWebContent", "get_web_content", "getActiveTabHtml"],
            "getInteractiveElements": ["chrome_get_interactive_elements", "getInteractiveElements", "get_interactive_elements"],
            "click": ["chrome_click_element", "chrome_click", "click", "clickElement"],
            "scroll": ["chrome_scroll", "scroll"],
            "type": ["chrome_fill_or_select", "chrome_type", "type", "input", "enterText"],
            "keyboard": ["chrome_keyboard", "keyboard", "pressKeys", "keyPress"],
            "setCookie": ["chrome_set_cookie", "setCookie"],
            "closeTab": ["chrome_close_tabs", "closeTab", "closeCurrentTab"],
            "chrome_screenshot": ["chrome_screenshot", "screenshot", "takeScreenshot"],
            # æ‰§è¡ŒJSä»£ç çš„å·¥å…·ï¼šä¸åŒç‰ˆæœ¬å‘½åä¸åŒï¼Œå…¨éƒ¨å…¼å®¹
            "chrome_eval": [
                "chrome_eval",            # æ–°ç‰ˆæœ¬å¸¸ç”¨
                "chrome_inject_script",   # æœ‰äº›ç‰ˆæœ¬æš´éœ²ä¸ºinject_script
                "injectScript",
                "evaluateJavascript",
                "evaluateJS",
                "eval"
            ],
        }
        tools = await self.list_tools()
        
        # ğŸ”¥ è°ƒè¯•ï¼šé¦–æ¬¡æ˜ å°„æ—¶æ‰“å°æ‰€æœ‰å¯ç”¨å·¥å…·
        if not self.tool_map and logical in ["navigate", "chrome_snapshot"]:
            logger.info(f"ğŸ“‹ å½“å‰å¯ç”¨çš„MCPå·¥å…· ({len(tools)}ä¸ª):")
            for i, tool in enumerate(tools[:25], 1):
                logger.info(f"   {i}. {tool}")
            if len(tools) > 25:
                logger.info(f"   ... è¿˜æœ‰ {len(tools)-25} ä¸ªå·¥å…·")
        
        candidates = candidates_map.get(logical, [logical])
        for name in candidates:
            if name in tools:
                self.tool_map[logical] = name
                logger.info(f"ğŸ”§ å·¥å…·æ˜ å°„: {logical} -> {name}")
                return name
        # æœªæ‰¾åˆ°åˆ™ä¿åº•ç”¨åŸå
        self.tool_map[logical] = logical
        logger.warning(f"âš ï¸ å·¥å…·æœªåŒ¹é…ï¼Œå›é€€ä½¿ç”¨åŸå: {logical}")
        logger.warning(f"   å°è¯•çš„å€™é€‰å: {candidates[:5]}")
        return logical

    async def call_tool(self, logical: str, args: Dict | None = None) -> Dict:
        """æŒ‰é€»è¾‘åè°ƒç”¨MCPå·¥å…·ï¼Œè‡ªåŠ¨æ˜ å°„åˆ°çœŸå®å·¥å…·å"""
        args = args or {}

        # ğŸ”¥ å·¥å…·åæ˜ å°„è¡¨ï¼ˆé€»è¾‘å -> MCPçœŸå®åï¼‰
        tool_name_map = {
            "navigate": "chrome_navigate",
            "getWebContent": "chrome_get_web_content",
            "getInteractiveElements": "chrome_get_interactive_elements",
            "click": "chrome_click_element",
            "type": "chrome_fill_or_select",
            "scroll": "chrome_scroll",
            "keyboard": "chrome_keyboard",
            "setCookie": "chrome_set_cookie",
            "closeTab": "chrome_close_tabs",
            "chrome_screenshot": "chrome_screenshot",
            "chrome_keyboard": "chrome_keyboard",
            "chrome_type": "chrome_fill_or_select",
        }

        # æ˜ å°„é€»è¾‘ååˆ°çœŸå®å·¥å…·å
        real_tool_name = tool_name_map.get(logical, logical)

        return await self.call_mcp(real_tool_name, args)
    
    async def open_douyin(self, wait_login: bool = True) -> bool:
        """æ‰“å¼€æŠ–éŸ³"""
        try:
            # æ£€æŸ¥Cookie
            if self.cookie_file.exists() and not wait_login:
                try:
                    cookie_text = self.cookie_file.read_text()
                    cookies = json.loads(cookie_text)
                    if isinstance(cookies, str):
                        logger.warning("Cookieæ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œåˆ é™¤æ—§æ–‡ä»¶")
                        self.cookie_file.unlink()
                    else:
                        if isinstance(cookies, list) and self._check_cookies(cookies):
                            return await self._login_with_cookies(cookies)
                except Exception as e:
                    logger.warning(f"è¯»å–Cookieå¤±è´¥: {e}ï¼Œåˆ é™¤æ—§æ–‡ä»¶")
                    if self.cookie_file.exists():
                        self.cookie_file.unlink()
            
            # æ‰“å¼€é¡µé¢
            result = await self.call_tool("navigate", {"url": "https://www.douyin.com/?recommend=1"})
            if isinstance(result, dict):
                self.current_tab_id = result.get("tabId")
            
            # ç­‰å¾…é¡µé¢åˆå§‹åŒ–
            await self.human_sleep(1.5, 2.5)
            
            logger.info("=" * 60)
            logger.info("ğŸ’¡ å·²æ‰“å¼€æŠ–éŸ³ï¼ˆä½¿ç”¨å½“å‰Chromeç™»å½•çŠ¶æ€ï¼‰")
            logger.info("=" * 60)
            await self.human_sleep(2.0, 3.0)
            
            return True
        except Exception as e:
            logger.error(f"æ‰“å¼€æŠ–éŸ³å¤±è´¥: {e}")
            return False
    
    async def _check_login_status(self) -> bool:
        """æ£€æµ‹æŠ–éŸ³ç™»å½•çŠ¶æ€ - é€šè¿‡DOMå…ƒç´ åˆ¤æ–­"""
        try:
            logger.info("ğŸ” æ£€æµ‹ç™»å½•çŠ¶æ€...")
            
            # è·å–é¡µé¢HTMLå†…å®¹ï¼ˆmcp-chromeæ²¡æœ‰getCookieså·¥å…·ï¼ï¼‰
            result = await self.call_tool("getWebContent", {
                "contentType": "html",
                "selector": "body"
            })
            
            # è§£æMCPè¿”å›çš„HTMLå†…å®¹
            import json as json_module
            html_content = ""
            
            if isinstance(result, dict):
                content = result.get("content", [])
                if isinstance(content, list) and len(content) > 0:
                    if isinstance(content[0], dict) and 'text' in content[0]:
                        text_data = content[0]['text']
                        # å¯èƒ½æ˜¯JSONå­—ç¬¦ä¸²ï¼Œå°è¯•è§£æ
                        try:
                            parsed = json_module.loads(text_data)
                            # MCPè¿”å›æ ¼å¼ï¼š{"status": "success", "data": "HTMLå†…å®¹"}
                            if isinstance(parsed, dict) and 'data' in parsed:
                                html_content = parsed['data']
                            elif isinstance(parsed, str):
                                html_content = parsed
                            else:
                                html_content = text_data
                        except:
                            html_content = text_data
            elif isinstance(result, str):
                html_content = result
            
            if not html_content:
                logger.warning("âš ï¸ æœªè·å–åˆ°é¡µé¢å†…å®¹")
                return False
            
            logger.info(f"âœ… è·å–åˆ°HTMLå†…å®¹ï¼Œé•¿åº¦: {len(html_content)}")
            logger.info(f"   [è°ƒè¯•] HTMLå‰500å­—ç¬¦: {html_content[:500]}")
            
            # æ£€æŸ¥ç™»å½•çŠ¶æ€æ ‡å¿—ï¼ˆDOMå…ƒç´ æ£€æµ‹ï¼‰
            # å·²ç™»å½•æ ‡å¿—ï¼šç”¨æˆ·å¤´åƒã€æ˜µç§°ã€"æˆ‘çš„"ç­‰
            logged_in_indicators = [
                'class="avatar"',  # å¤´åƒå…ƒç´ 
                'class="user-info"',  # ç”¨æˆ·ä¿¡æ¯
                'data-e2e="user-info"',  # ç”¨æˆ·ä¿¡æ¯ï¼ˆæŠ–éŸ³ç‰¹æœ‰ï¼‰
                '"isLogin":true',  # JSå˜é‡
                'class="login-guide-bar__avatar"',  # ç™»å½•å¼•å¯¼æ çš„å¤´åƒ
            ]
            
            # æœªç™»å½•æ ‡å¿—ï¼š"ç™»å½•"æŒ‰é’®
            logged_out_indicators = [
                '>ç™»å½•<',
                'class="login-button"',
                'data-e2e="login-button"',
                '"isLogin":false',
            ]
            
            # ç»Ÿè®¡å‘½ä¸­æ•°
            login_score = sum(1 for indicator in logged_in_indicators if indicator in html_content)
            logout_score = sum(1 for indicator in logged_out_indicators if indicator in html_content)
            
            logger.info(f"   [ç™»å½•æ£€æµ‹] å·²ç™»å½•æ ‡å¿—å‘½ä¸­: {login_score}, æœªç™»å½•æ ‡å¿—å‘½ä¸­: {logout_score}")
            
            if login_score > logout_score:
                logger.info("âœ… æ£€æµ‹åˆ°å·²ç™»å½•çŠ¶æ€ï¼ˆé€šè¿‡DOMå…ƒç´ ï¼‰")
                return True
            else:
                logger.warning("âš ï¸ æœªæ£€æµ‹åˆ°ç™»å½•çŠ¶æ€")
                return False
            
        except Exception as e:
            logger.warning(f"æ£€æµ‹ç™»å½•çŠ¶æ€å¤±è´¥: {e}")
            return False
    
    def _check_cookies(self, cookies: List) -> bool:
        """æ£€æŸ¥Cookieæœ‰æ•ˆæ€§"""
        # ç±»å‹æ£€æŸ¥ï¼šå¿…é¡»æ˜¯åˆ—è¡¨
        if not isinstance(cookies, list) or not cookies:
            logger.warning(f"Cookieç±»å‹é”™è¯¯: {type(cookies)}")
            return False
        
        # æ£€æŸ¥åˆ—è¡¨å…ƒç´ æ˜¯å¦æ˜¯å­—å…¸
        if not all(isinstance(c, dict) for c in cookies):
            logger.warning("Cookieå…ƒç´ ä¸æ˜¯å­—å…¸")
            return False
            
        has_session = any(c.get('name') == 'sessionid' for c in cookies)
        now = datetime.now().timestamp()
        not_expired = all(c.get('expirationDate', now+1) > now for c in cookies)
        return has_session and not_expired
    
    async def _login_with_cookies(self, cookies: List) -> bool:
        """Cookieç™»å½•"""
        try:
            await self.call_tool("navigate", {"url": "https://www.douyin.com/?recommend=1"})
            await self.human_sleep(1.5, 2.5)
            
            for cookie in cookies:
                try:
                    await self.call_tool("setCookie", {"cookie": cookie})
                except:
                    pass
            
            await self.call_tool("navigate", {"url": "https://www.douyin.com/?recommend=1"})
            await self.human_sleep(2.5, 3.5)
            logger.info("âœ… Cookieç™»å½•æˆåŠŸ")
            return True
        except:
            return False
    
    async def _save_cookies(self):
        """ä¿å­˜Cookieï¼ˆæ³¨ï¼šmcp-chromeæ²¡æœ‰Cookieå·¥å…·ï¼Œæ­¤æ–¹æ³•å·²ç¦ç”¨ï¼‰"""
        logger.warning("âš ï¸  mcp-chromeä¸æ”¯æŒCookieæ“ä½œï¼Œè·³è¿‡ä¿å­˜")
        return
        
        try:
            # ä»¥ä¸‹ä»£ç å·²åºŸå¼ƒï¼ˆmcp-chromeæ²¡æœ‰getCookieså·¥å…·ï¼‰
            result = await self.call_mcp("getCookies", {"url": "https://www.douyin.com/?recommend=1"})
            
            # å¤„ç†SSEå“åº”ï¼ˆå¯èƒ½åŒ…è£¹åœ¨event:messageä¸­ï¼‰
            cookies = []
            if isinstance(result, dict):
                content = result.get("content", [])
                # å¦‚æœcontentæ˜¯åˆ—è¡¨ä¸”ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯dictï¼Œæå–text
                if isinstance(content, list) and len(content) > 0:
                    if isinstance(content[0], dict) and 'text' in content[0]:
                        try:
                            cookies = json.loads(content[0]['text'])
                        except:
                            cookies = content
                    else:
                        cookies = content
                else:
                    cookies = content
            
            # ç¡®ä¿cookiesæ˜¯åˆ—è¡¨
            if not isinstance(cookies, list):
                logger.warning(f"Cookieæ ¼å¼é”™è¯¯: {type(cookies)}")
                return
                
            if cookies:
                self.cookie_file.write_text(json.dumps(cookies, ensure_ascii=False, indent=2))
                logger.info(f"Cookieå·²ä¿å­˜: {len(cookies)}æ¡")
        except Exception as e:
            logger.error(f"ä¿å­˜Cookieå¤±è´¥: {e}")
    
    async def post_comment(self, video_url: str, comment: str) -> bool:
        """å‘è¡¨è¯„è®º"""
        try:
            await self.call_tool("navigate", {"url": video_url})
            await self.human_sleep(3.5, 5.5)
            
            # ç‚¹å‡»è¯„è®ºæ¡†
            await self.call_tool("click", {"selector": "textarea[placeholder*='è¯„è®º']"})
            await self.human_sleep(0.8, 1.2)
            
            # è¾“å…¥è¯„è®ºï¼ˆæ¨¡æ‹Ÿäººç±»ï¼‰
            for char in comment:
                await self.call_tool("type", {"text": char})
                await asyncio.sleep(random.uniform(0.05, 0.15))
            
            await self.human_sleep(1.0, 3.0)
            
            # å‘é€
            await self.call_tool("click", {"selector": "button:has-text('å‘å¸ƒ')"})
            logger.info(f"âœ… è¯„è®ºæˆåŠŸ: {comment[:20]}...")
            return True
        except Exception as e:
            logger.error(f"è¯„è®ºå¤±è´¥: {e}")
            return False
    
    async def get_user_profile_data(self, profile_url: str) -> Dict:
        """è®¿é—®ç”¨æˆ·ä¸»é¡µå¹¶æŠ“å–è¯¦ç»†ä¿¡æ¯ï¼ˆé€šè¿‡JSç²¾å‡†æŠ“å–ï¼‰"""
        try:
            logger.info(f"ğŸ” æ‰“å¼€ç”¨æˆ·ä¸»é¡µ: {profile_url}")
            
            # æ‰“å¼€ä¸»é¡µ
            await self.call_tool("navigate", {"url": profile_url})
            await self.human_sleep(2.5, 4.0)
            
            # æ»šåŠ¨åŠ è½½è§†é¢‘å’Œè¯„è®º
            logger.info("   æ»šåŠ¨åŠ è½½å†…å®¹...")
            for i in range(3):  # æ»šåŠ¨3æ¬¡
                await self.call_tool("chrome_keyboard", {"keys": "PageDown"})
                await self.human_sleep(0.8, 1.3)
            
            # æ‰§è¡ŒJSæŠ“å–ç”¨æˆ·ä¸»é¡µæ•°æ®ï¼ˆæ¯”HTMLè§£æå‡†ç¡®100å€ï¼ï¼‰
            logger.info("   æ‰§è¡ŒJSæŠ“å–ä¸»é¡µæ•°æ®...")
            
            js_code = """
            (async () => {
                const profile = {
                    nickname: '',
                    signature: '',
                    cover_url: null,
                    video_titles: [],
                    location: null,
                    comments_about_user: []
                };
                
                // 1. æå–æ˜µç§°ï¼ˆä»titleæˆ–DOMï¼‰
                profile.nickname = document.title.replace('çš„ä¸»é¡µ', '').replace('æŠ–éŸ³', '').trim();
                if (!profile.nickname || profile.nickname.length < 2) {
                    const nicknameElem = document.querySelector('[data-e2e="user-info-nickname"]') ||
                                        document.querySelector('.nickname') ||
                                        document.querySelector('h1');
                    if (nicknameElem) profile.nickname = nicknameElem.textContent.trim();
                }
                
                // 2. æå–ç­¾å/ç®€ä»‹
                const signatureElem = document.querySelector('[data-e2e="user-info-signature"]') ||
                                     document.querySelector('.signature') ||
                                     document.querySelector('.user-bio');
                if (signatureElem) profile.signature = signatureElem.textContent.trim();
                
                // 3. æå–å¤´åƒ
                const avatarElem = document.querySelector('[data-e2e="user-info-avatar"]') ||
                                  document.querySelector('.avatar img') ||
                                  document.querySelector('img[src*="avatar"]');
                if (avatarElem) profile.cover_url = avatarElem.src;
                
                // 4. æå–è§†é¢‘æ ‡é¢˜ï¼ˆå‰5ä¸ªï¼‰
                const videoItems = document.querySelectorAll('[data-e2e="user-post-item"]');
                for (const item of Array.from(videoItems).slice(0, 5)) {
                    const titleElem = item.querySelector('.desc') ||
                                     item.querySelector('.video-desc') ||
                                     item.querySelector('span[title]');
                    if (titleElem) {
                        const title = titleElem.textContent.trim() || titleElem.getAttribute('title');
                        if (title && title.length > 3) {
                            profile.video_titles.push(title);
                        }
                    }
                }
                
                // 5. æå–è¯„è®ºåŒºç§°å‘¼ï¼ˆå…³é”®ï¼ï¼‰
                const commentElements = document.querySelectorAll('[data-e2e="comment-item"]');
                const keywords = ['è€æ¿', 'æ€»', 'åº—é•¿', 'é¦†é•¿', 'å“¥', 'å§', 'å¸ˆå‚…'];
                
                for (const elem of Array.from(commentElements).slice(0, 20)) {
                    const commentText = elem.querySelector('[data-e2e="comment-text"]') ||
                                       elem.querySelector('.comment-text');
                    if (commentText) {
                        const text = commentText.textContent.trim();
                        if (text && keywords.some(kw => text.includes(kw))) {
                            profile.comments_about_user.push(text);
                        }
                    }
                }
                
                // å»é‡
                profile.comments_about_user = [...new Set(profile.comments_about_user)].slice(0, 10);
                
                return {
                    success: true,
                    profile: profile
                };
            })()
            """


            
            result = await self.call_mcp("chrome_inject_script", {"type": "MAIN", "jsScript": js_code})
            
            # è§£æJSæ‰§è¡Œç»“æœ
            profile_data = {
                "nickname": "æœªçŸ¥ç”¨æˆ·",
                "signature": "",
                "cover_url": None,
                "video_titles": [],
                "location": None,
                "comments_about_user": [],
                "profile_url": profile_url
            }
            
            try:
                if isinstance(result, dict):
                    content_list = result.get('content', [])
                    if isinstance(content_list, list) and len(content_list) > 0:
                        text_str = content_list[0].get('text', '{}')
                        data = json.loads(text_str) if isinstance(text_str, str) else text_str
                        if isinstance(data, dict) and 'profile' in data:
                            profile_data.update(data['profile'])
                            profile_data['profile_url'] = profile_url
                
                logger.info(f"   âœ… é€šè¿‡JSæŠ“å–åˆ°ä¸»é¡µæ•°æ®")
                
            except Exception as e:
                logger.error(f"   è§£æJSç»“æœå¤±è´¥: {e}")
            
            # æ‰“å°æŠ“å–ç»“æœ
            logger.info(f"   âœ… æ˜µç§°: {profile_data['nickname']}")
            logger.info(f"   âœ… ç®€ä»‹: {profile_data['signature'][:30]}..." if profile_data['signature'] else "   âš ï¸  æ— ç®€ä»‹")
            logger.info(f"   âœ… è§†é¢‘æ•°: {len(profile_data['video_titles'])}")
            logger.info(f"   âœ… è¯„è®ºæ•°: {len(profile_data['comments_about_user'])} æ¡ï¼ˆå«ç§°å‘¼ï¼‰")
            
            return profile_data
            
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·ä¸»é¡µæ•°æ®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {}
    
    async def follow_user(self, profile_url: str) -> bool:
        """å…³æ³¨ç”¨æˆ·"""
        try:
            logger.info(f"ğŸ‘ å…³æ³¨ç”¨æˆ·...")
            
            # ç¡®ä¿åœ¨ç”¨æˆ·ä¸»é¡µ
            await self.call_tool("navigate", {"url": profile_url})
            await self.human_sleep(1.0, 2.0)
            
            # å°è¯•ç‚¹å‡»å…³æ³¨æŒ‰é’®ï¼ˆå¤šç§å¯èƒ½çš„é€‰æ‹©å™¨ï¼‰
            follow_selectors = [
                'button:contains("å…³æ³¨")',
                'div[class*="follow"]',
                'button[class*="follow"]',
                '.follow-button'
            ]
            
            for selector in follow_selectors:
                try:
                    await self.call_tool("click", {"selector": selector})
                    await self.human_sleep(0.6, 1.2)
                    logger.info("   âœ… å…³æ³¨æˆåŠŸ")
                    return True
                except:
                    continue
            
            logger.warning("   âš ï¸  æœªæ‰¾åˆ°å…³æ³¨æŒ‰é’®")
            return False
            
        except Exception as e:
            logger.error(f"å…³æ³¨å¤±è´¥: {e}")
            return False
    
    async def send_private_message(self, profile_url: str, message: str) -> bool:
        """å‘é€ç§ä¿¡"""
        try:
            logger.info(f"ğŸ’¬ å‘é€ç§ä¿¡...")
            
            # ç¡®ä¿åœ¨ç”¨æˆ·ä¸»é¡µ
            await self.call_tool("navigate", {"url": profile_url})
            await self.human_sleep(1.0, 2.0)
            
            # ç‚¹å‡»ç§ä¿¡æŒ‰é’®
            message_selectors = [
                'button:contains("ç§ä¿¡")',
                'div[class*="message"]',
                'button[class*="message"]',
                '.message-button'
            ]
            
            clicked = False
            for selector in message_selectors:
                try:
                    await self.call_tool("click", {"selector": selector})
                    await self.human_sleep(1.0, 2.0)
                    clicked = True
                    break
                except:
                    continue
            
            if not clicked:
                logger.warning("   âš ï¸  æœªæ‰¾åˆ°ç§ä¿¡æŒ‰é’®")
                return False
            
            # è¾“å…¥æ¶ˆæ¯
            input_selectors = [
                'textarea',
                'input[type="text"]',
                'div[contenteditable="true"]'
            ]
            
            for selector in input_selectors:
                try:
                    await self.call_tool("type", {
                        "selector": selector,
                        "text": message
                    })
                    await self.human_sleep(0.6, 1.0)
                    
                    # ç‚¹å‡»å‘é€
                    send_selectors = ['button:contains("å‘é€")', 'button[class*="send"]']
                    for send_sel in send_selectors:
                        try:
                            await self.call_tool("click", {"selector": send_sel})
                            logger.info("   âœ… ç§ä¿¡å·²å‘é€")
                            return True
                        except:
                            continue
                except:
                    continue
            
            logger.warning("   âš ï¸  ç§ä¿¡å‘é€å¤±è´¥")
            return False
        except Exception as e:
            logger.error(f"ç§ä¿¡å¤±è´¥: {e}")
            return False


    async def reply_to_comment(self, video_url: str, nickname: str, reply_text: str) -> bool:
        """åœ¨æŒ‡å®šè§†é¢‘ä¸‹ï¼Œå›å¤æŸä¸ªè¯„è®ºè€…ï¼ˆé€šè¿‡JSç²¾å‡†å®šä½ï¼‰"""
        try:
            logger.info(f"ğŸ’¬ å‡†å¤‡å›å¤ {nickname} çš„è¯„è®º...")
            
            # æ‰“å¼€è§†é¢‘
            await self.call_tool("navigate", {"url": video_url})
            await self.human_sleep(2.0, 3.2)

            # æ»šåŠ¨åŠ è½½è¯„è®º
            for _ in range(6):
                await self.call_tool("chrome_keyboard", {"keys": "PageDown"})
                await self.human_sleep(0.8, 1.2)

            # ä½¿ç”¨JSç²¾å‡†å®šä½å¹¶ç‚¹å‡»å›å¤æŒ‰é’®
            js_find_reply_button = f"""
            (() => {{
                // æŸ¥æ‰¾æ‰€æœ‰è¯„è®º
                const commentElements = document.querySelectorAll('[data-e2e="comment-item"]');
                
                for (const elem of commentElements) {{
                    // æ£€æŸ¥æ˜µç§°æ˜¯å¦åŒ¹é…
                    const nicknameElem = elem.querySelector('[data-e2e="comment-user-nickname"]') ||
                                        elem.querySelector('.nickname');
                    const nickname = nicknameElem?.textContent?.trim();
                    
                    if (nickname === "{nickname}") {{
                        // æ‰¾åˆ°äº†ç›®æ ‡è¯„è®ºï¼Œç‚¹å‡»å›å¤æŒ‰é’®
                        const replyBtn = elem.querySelector('[data-e2e="comment-reply"]') ||
                                        elem.querySelector('button:has-text("å›å¤")') ||
                                        elem.querySelector('.reply-button');
                        
                        if (replyBtn) {{
                            replyBtn.click();
                            return {{ success: true, message: 'æ‰¾åˆ°å¹¶ç‚¹å‡»äº†å›å¤æŒ‰é’®' }};
                        }}
                    }}
                }}
                
                return {{ success: false, message: 'æœªæ‰¾åˆ°ç›®æ ‡è¯„è®ºæˆ–å›å¤æŒ‰é’®' }};
            }})()
            """
            
            result = await self.call_mcp("chrome_inject_script", {"type": "MAIN", "jsScript": js_find_reply_button})
            
            # è§£æç»“æœ
            success = False
            try:
                if isinstance(result, dict):
                    content_list = result.get('content', [])
                    if isinstance(content_list, list) and len(content_list) > 0:
                        text_str = content_list[0].get('text', '{}')
                        data = json.loads(text_str) if isinstance(text_str, str) else text_str
                        success = data.get('success', False)
            except:
                pass
            
            if not success:
                logger.warning(f"   âš ï¸ æœªæ‰¾åˆ° {nickname} çš„è¯„è®ºæˆ–å›å¤æŒ‰é’®")
                return False
            
            logger.info(f"   âœ… å·²å®šä½åˆ° {nickname} çš„è¯„è®º")
            await self.human_sleep(0.8, 1.2)

            # è¾“å…¥å›å¤æ–‡æœ¬ï¼ˆMCPçš„typeå·¥å…·ï¼‰
            await self.call_tool("chrome_type", {"text": reply_text})
            await self.human_sleep(1.0, 2.0)

            # ç‚¹å‡»å‘é€æŒ‰é’®ï¼ˆç”¨JSå®šä½æœ€å‡†ç¡®çš„å‘é€æŒ‰é’®ï¼‰
            js_click_send = """
            (() => {
                const sendBtn = document.querySelector('[data-e2e="comment-send"]') ||
                               document.querySelector('button:has-text("å‘é€")') ||
                               document.querySelector('button[class*="send"]');
                if (sendBtn) {
                    sendBtn.click();
                    return { success: true };
                }
                return { success: false };
            })()
            """
            
            await self.call_mcp("chrome_inject_script", {"type": "MAIN", "jsScript": js_click_send})
            logger.info(f"   âœ… å›å¤å·²å‘é€: {reply_text[:30]}...")
            return True
            
        except Exception as e:
            logger.error(f"å›å¤è¯„è®ºå¤±è´¥: {e}")
            return False

        
    
    async def close_current_tab(self):
        """å…³é—­å½“å‰æ ‡ç­¾é¡µï¼ˆä½¿ç”¨MCPçš„chrome_close_tabsï¼‰"""
        if not self.current_tab_id:
            logger.warning("   æ— æ³•å…³é—­ï¼šå½“å‰æ²¡æœ‰tabId")
            return False
        
        try:
            logger.info(f"ğŸ”™ å…³é—­æ ‡ç­¾é¡µ (tabId: {self.current_tab_id})...")
            # ä½¿ç”¨MCPçš„chrome_close_tabså·¥å…·ï¼ˆæ³¨æ„ï¼štabIdsæ˜¯æ•°ç»„ï¼ï¼‰
            result = await self.call_mcp("chrome_close_tabs", {
                "tabIds": [self.current_tab_id]  # â† å¿…é¡»æ˜¯æ•°ç»„ï¼
            })
            logger.info(f"   âœ… æ ‡ç­¾é¡µå·²å…³é—­")
            self.current_tab_id = None  # æ¸…é™¤å½“å‰tabId
            return True
        except Exception as e:
            logger.warning(f"   âš ï¸ å…³é—­æ ‡ç­¾é¡µå¤±è´¥: {e}")
            return False


# ==================== æ•°æ®åº“ç®¡ç† ====================
class DouyinMarketingDatabase:
    """å®Œæ•´çš„æ•°æ®åº“ç®¡ç†"""
    
    def __init__(self, db_path: str = None):
        if not db_path:
            # ç»Ÿä¸€ä½¿ç”¨ media_marketing ç›®å½•
            db_dir = Path(__file__).parent / "media_marketing"
            db_dir.mkdir(exist_ok=True)
            db_path = str(db_dir / "douyin_marketing.db")
        
        self.db_path = db_path
        self.init_database()
        logger.info(f"æ•°æ®åº“åˆå§‹åŒ–: {db_path}")
    
    def get_conn(self):
        return sqlite3.connect(self.db_path)
    
    def init_database(self):
        """åˆ›å»ºæ‰€æœ‰è¡¨"""
        conn = self.get_conn()
        c = conn.cursor()
        
        # ç›®æ ‡è´¦å·
        c.execute("""CREATE TABLE IF NOT EXISTS target_accounts (
            id INTEGER PRIMARY KEY,
            douyin_id TEXT UNIQUE,
            nickname TEXT,
            category TEXT,
            priority INTEGER DEFAULT 1,
            last_checked DATETIME,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )""")
        
        # å·²è¯„è®ºè§†é¢‘
        c.execute("""CREATE TABLE IF NOT EXISTS commented_videos (
            id INTEGER PRIMARY KEY,
            video_id TEXT UNIQUE,
            video_url TEXT,
            comment_text TEXT,
            commented_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )""")
        
        # å·²åˆ†æç”¨æˆ·
        c.execute("""CREATE TABLE IF NOT EXISTS analyzed_users (
            id INTEGER PRIMARY KEY,
            user_id TEXT,
            analyzed_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            is_target BOOLEAN,
            confidence REAL
        )""")
        c.execute("CREATE INDEX IF NOT EXISTS idx_user_analyzed ON analyzed_users(user_id, analyzed_at)")
        
        # æ½œåœ¨å®¢æˆ·
        c.execute("""CREATE TABLE IF NOT EXISTS potential_clients (
            id INTEGER PRIMARY KEY,
            douyin_id TEXT UNIQUE,
            nickname TEXT,
            confidence REAL,
            venue_type TEXT,
            tags TEXT,
            status TEXT DEFAULT 'discovered',
            messaged BOOLEAN DEFAULT 0,
            messaged_at DATETIME,
            first_found DATETIME DEFAULT CURRENT_TIMESTAMP
        )""")
        
        # å·²ç§ä¿¡ç”¨æˆ·ï¼ˆè®°å½•æ‰€æœ‰ç§ä¿¡ï¼ŒåŒ…æ‹¬éå®¢æˆ·ï¼‰
        c.execute("""CREATE TABLE IF NOT EXISTS messaged_users (
            id INTEGER PRIMARY KEY,
            user_id TEXT,
            message_text TEXT,
            messaged_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            account_source TEXT
        )""")
        c.execute("CREATE INDEX IF NOT EXISTS idx_messaged_user ON messaged_users(user_id, messaged_at)")
        
        # å·²ä½¿ç”¨è¯„è®º
        c.execute("""CREATE TABLE IF NOT EXISTS used_comments (
            id INTEGER PRIMARY KEY,
            comment_text TEXT,
            comment_hash TEXT UNIQUE,
            used_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )""")
        
        conn.commit()
        conn.close()
    
    def already_commented(self, video_id: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦å·²è¯„è®º"""
        conn = self.get_conn()
        c = conn.cursor()
        c.execute("SELECT COUNT(*) FROM commented_videos WHERE video_id=?", (video_id,))
        count = c.fetchone()[0]
        conn.close()
        return count > 0
    
    def user_analyzed(self, user_id: str, days: int = 30) -> bool:
        """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²åˆ†æ"""
        conn = self.get_conn()
        c = conn.cursor()
        cutoff = (datetime.now() - timedelta(days=days)).isoformat()
        c.execute("SELECT COUNT(*) FROM analyzed_users WHERE user_id=? AND analyzed_at>?", (user_id, cutoff))
        count = c.fetchone()[0]
        conn.close()
        return count > 0
    
    def is_similar_comment(self, comment: str, threshold: float = 0.8) -> bool:
        """æ£€æŸ¥ç›¸ä¼¼è¯„è®º"""
        hash_val = hashlib.md5(comment.encode()).hexdigest()
        conn = self.get_conn()
        c = conn.cursor()
        
        # å®Œå…¨ç›¸åŒ
        c.execute("SELECT COUNT(*) FROM used_comments WHERE comment_hash=?", (hash_val,))
        if c.fetchone()[0] > 0:
            conn.close()
            return True
        
        # ç›¸ä¼¼åº¦æ£€æŸ¥
        cutoff = (datetime.now() - timedelta(days=30)).isoformat()
        c.execute("SELECT comment_text FROM used_comments WHERE used_at>?", (cutoff,))
        for (existing,) in c.fetchall():
            if SequenceMatcher(None, comment, existing).ratio() >= threshold:
                conn.close()
                return True
        
        conn.close()
        return False
    
    def save_comment(self, comment: str):
        """ä¿å­˜è¯„è®º"""
        hash_val = hashlib.md5(comment.encode()).hexdigest()
        conn = self.get_conn()
        c = conn.cursor()
        try:
            c.execute("INSERT INTO used_comments (comment_text, comment_hash) VALUES (?,?)", (comment, hash_val))
            conn.commit()
        except:
            pass
        finally:
            conn.close()
    
    def record_video_comment(self, video_id: str, video_url: str, comment_text: str):
        """è®°å½•å·²è¯„è®ºçš„è§†é¢‘"""
        conn = self.get_conn()
        c = conn.cursor()
        try:
            c.execute("""INSERT INTO commented_videos (video_id, video_url, comment_text) 
                        VALUES (?,?,?)""", (video_id, video_url, comment_text))
            conn.commit()
            logger.info(f"è®°å½•è¯„è®ºï¼šè§†é¢‘{video_id[:8]}...")
        except sqlite3.IntegrityError:
            logger.warning(f"è§†é¢‘{video_id}å·²è¯„è®ºè¿‡ï¼Œè·³è¿‡è®°å½•")
        except Exception as e:
            logger.warning(f"è®°å½•è¯„è®ºå¤±è´¥: {e}")
        finally:
            conn.close()
    
    def already_messaged(self, user_id: str, days: int = 30) -> bool:
        """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²ç§ä¿¡è¿‡ï¼ˆ30å¤©å†…ï¼‰"""
        conn = self.get_conn()
        c = conn.cursor()
        cutoff = (datetime.now() - timedelta(days=days)).isoformat()
        c.execute("SELECT COUNT(*) FROM messaged_users WHERE user_id=? AND messaged_at>?", 
                 (user_id, cutoff))
        count = c.fetchone()[0]
        conn.close()
        return count > 0
    
    def record_message(self, user_id: str, message_text: str, account_source: str | None = None):
        """è®°å½•ç§ä¿¡"""
        conn = self.get_conn()
        c = conn.cursor()
        try:
            c.execute("""INSERT INTO messaged_users (user_id, message_text, account_source) 
                        VALUES (?,?,?)""", (user_id, message_text, account_source))
            conn.commit()
            logger.info(f"è®°å½•ç§ä¿¡ï¼šç”¨æˆ·{user_id[:8]}...")
        except Exception as e:
            logger.warning(f"è®°å½•ç§ä¿¡å¤±è´¥: {e}")
        finally:
            conn.close()
    
    def update_account_checked(self, douyin_id: str):
        """æ›´æ–°è´¦å·æ£€æŸ¥æ—¶é—´"""
        conn = self.get_conn()
        c = conn.cursor()
        try:
            c.execute("UPDATE target_accounts SET last_checked=? WHERE douyin_id=?",
                     (datetime.now().isoformat(), douyin_id))
            conn.commit()
        except Exception as e:
            logger.warning(f"æ›´æ–°è´¦å·æ£€æŸ¥æ—¶é—´å¤±è´¥: {e}")
        finally:
            conn.close()
    
    def record_user_analysis(self, user_id: str, is_target: bool, confidence: float):
        """è®°å½•ç”¨æˆ·åˆ†æç»“æœ"""
        conn = self.get_conn()
        c = conn.cursor()
        try:
            c.execute("""INSERT INTO analyzed_users (user_id, is_target, confidence) 
                        VALUES (?,?,?)""", (user_id, is_target, confidence))
            conn.commit()
        except Exception as e:
            logger.warning(f"è®°å½•åˆ†æç»“æœå¤±è´¥: {e}")
        finally:
            conn.close()
    
    def save_client(self, data: Dict):
        """ä¿å­˜æ½œåœ¨å®¢æˆ·"""
        conn = self.get_conn()
        c = conn.cursor()
        try:
            c.execute("""INSERT INTO potential_clients (douyin_id, nickname, confidence, venue_type, tags)
                        VALUES (?,?,?,?,?)""",
                     (data['douyin_id'], data['nickname'], data['confidence'], 
                      data.get('venue_type'), json.dumps(data.get('tags', []))))
            conn.commit()
            logger.info(f"ä¿å­˜å®¢æˆ·: {data['nickname']} (ç½®ä¿¡åº¦{data['confidence']})")
        except:
            pass
        finally:
            conn.close()
    
    def add_target_account(self, douyin_id: str, nickname: str | None = None, category: str | None = None):
        """æ·»åŠ ç›®æ ‡è´¦å·"""
        conn = self.get_conn()
        c = conn.cursor()
        try:
            c.execute("INSERT INTO target_accounts (douyin_id, nickname, category) VALUES (?,?,?)",
                     (douyin_id, nickname or f"ä¸»æ’­_{douyin_id[:8]}", category))
            conn.commit()
            logger.info(f"æ·»åŠ ç›®æ ‡: {nickname or douyin_id[:8]}")
        except:
            logger.warning(f"ç›®æ ‡å·²å­˜åœ¨: {douyin_id}")
        finally:
            conn.close()
    
    def batch_import_from_json(self, json_path: str) -> int:
        """æ‰¹é‡å¯¼å…¥ç›®æ ‡è´¦å·ï¼ˆä»JSONé…ç½®æ–‡ä»¶ï¼‰"""
        if not Path(json_path).exists():
            logger.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {json_path}")
            return 0
        
        try:
            config = json.loads(Path(json_path).read_text(encoding='utf-8'))
            categories = config.get('categories', {})
            
            count = 0
            for category_name, category_data in categories.items():
                accounts = category_data.get('accounts', [])
                priority = category_data.get('priority', 1)
                
                for account in accounts:
                    douyin_id = account.get('douyin_id')
                    nickname = account.get('nickname') or None
                    
                    if douyin_id and len(douyin_id) > 10:
                        self.add_target_account(
                            douyin_id, 
                            nickname=nickname, 
                            category=category_name
                        )
                        count += 1
            
            logger.info(f"âœ… æ‰¹é‡å¯¼å…¥å®Œæˆ: {count} ä¸ªè´¦å·")
            return count
            
        except Exception as e:
            logger.error(f"å¯¼å…¥å¤±è´¥: {e}")
            return 0
    
    def cleanup_old_data(self, config_path: str | None = None):
        """è‡ªåŠ¨æ¸…ç†è¿‡æœŸæ•°æ®"""
        try:
            # è¯»å–æ¸…ç†è§„åˆ™
            if config_path and Path(config_path).exists():
                config = json.loads(Path(config_path).read_text(encoding='utf-8'))
                rules = config.get('cleanup_rules', {}).get('rules', {})
            else:
                # é»˜è®¤è§„åˆ™
                rules = {
                    'analyzed_users': {'keep_days': 30},
                    'commented_videos': {'keep_days': 90},
                    'used_comments': {'keep_days': 30}
                }
            
            conn = self.get_conn()
            c = conn.cursor()
            
            # æ¸…ç†åˆ†æè¿‡çš„ç”¨æˆ·è®°å½•
            if 'analyzed_users' in rules:
                days = rules['analyzed_users'].get('keep_days', 30)
                cutoff = (datetime.now() - timedelta(days=days)).isoformat()
                c.execute("DELETE FROM analyzed_users WHERE analyzed_at < ?", (cutoff,))
                deleted_users = c.rowcount
                logger.info(f"æ¸…ç†ç”¨æˆ·åˆ†æè®°å½•: {deleted_users} æ¡ï¼ˆ{days}å¤©å‰ï¼‰")
            
            # æ¸…ç†è¯„è®ºè®°å½•
            if 'commented_videos' in rules:
                days = rules['commented_videos'].get('keep_days', 90)
                cutoff = (datetime.now() - timedelta(days=days)).isoformat()
                c.execute("DELETE FROM commented_videos WHERE commented_at < ?", (cutoff,))
                deleted_videos = c.rowcount
                logger.info(f"æ¸…ç†è¯„è®ºè®°å½•: {deleted_videos} æ¡ï¼ˆ{days}å¤©å‰ï¼‰")
            
            # æ¸…ç†è¯„è®ºæ–‡æœ¬è®°å½•
            if 'used_comments' in rules:
                days = rules['used_comments'].get('keep_days', 30)
                cutoff = (datetime.now() - timedelta(days=days)).isoformat()
                c.execute("DELETE FROM used_comments WHERE used_at < ?", (cutoff,))
                deleted_comments = c.rowcount
                logger.info(f"æ¸…ç†è¯„è®ºæ–‡æœ¬è®°å½•: {deleted_comments} æ¡ï¼ˆ{days}å¤©å‰ï¼‰")
            
            conn.commit()
            conn.close()
            
            logger.info("âœ… æ•°æ®æ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logger.error(f"æ•°æ®æ¸…ç†å¤±è´¥: {e}")
    
    def get_target_accounts(self, limit: int = 10) -> List[Dict]:
        """è·å–ç›®æ ‡è´¦å·"""
        conn = self.get_conn()
        c = conn.cursor()
        c.execute("SELECT * FROM target_accounts ORDER BY priority DESC, last_checked ASC LIMIT ?", (limit,))
        cols = [d[0] for d in c.description]
        accounts = [dict(zip(cols, row)) for row in c.fetchall()]
        conn.close()
        return accounts



# ==================== AIåˆ†æå¼•æ“ï¼ˆå·²ç§»è‡³ç‹¬ç«‹æ–‡ä»¶ï¼‰ ====================
try:
    # ç»å¯¹å¯¼å…¥ï¼ˆæ”¯æŒç›´æ¥è¿è¡Œè„šæœ¬ï¼‰
    import sys
    from pathlib import Path
    media_marketing_dir = Path(__file__).parent / "media_marketing"
    if str(media_marketing_dir) not in sys.path:
        sys.path.insert(0, str(media_marketing_dir))

    from ai_engine import AIAnalysisEngine
    from prompts import FALLBACK_COMMENTS, NO_COMMENT_EMOJIS
    logger.info("âœ… AIå¼•æ“æ¨¡å—åŠ è½½æˆåŠŸ")
except Exception as e:
    logger.warning(f"âš ï¸  AIå¼•æ“æ¨¡å—åŠ è½½å¤±è´¥: {e}")
    AIAnalysisEngine = None
    FALLBACK_COMMENTS = ["é—®é¢˜ä¸å¤§", "å·®ä¸å¤šå§", "è¿˜å¥½"]
    NO_COMMENT_EMOJIS = ['ğŸ’†â€â™€ï¸', 'ğŸ’†', 'ğŸ‘', 'ğŸ”¥']


# ==================== ä¸»æ™ºèƒ½ä½“ ====================
class DouyinMarketingAgent:
    """æŠ–éŸ³è¥é”€æ™ºèƒ½ä½“ - è¶…çº§å®Œæ•´ç‰ˆ"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ==================== è‡ªåŠ¨æ¸…ç†æœºåˆ¶ ====================
        # å¯åŠ¨æ—¶è‡ªåŠ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆå¯é€šè¿‡configæ§åˆ¶ï¼‰
        auto_cleanup = self.config.get('auto_cleanup', True)
        chrome_keep_days = self.config.get('chrome_keep_days', 0)  # 0=æ¯æ¬¡å¯åŠ¨æ¸…ç©ºChromeç¼“å­˜
        log_keep_days = self.config.get('log_keep_days', 30)  # ä¿ç•™30å¤©æ—¥å¿—
        
        if auto_cleanup:
            try:
                from .media_marketing.cleanup_utils import MediaMarketingCleaner
                cleaner = MediaMarketingCleaner()
                
                logger.info("ğŸ§¹ å¯åŠ¨æ¸…ç†...")
                # æŸ¥çœ‹æ¸…ç†å‰å¤§å°
                sizes_before = cleaner.get_folder_sizes()
                chrome_before = sizes_before.get('chrome_data', 0)
                
                # æ‰§è¡Œæ¸…ç†
                cleaner.run_full_cleanup(
                    chrome_keep_days=chrome_keep_days,
                    log_keep_days=log_keep_days
                )
                
                # æŸ¥çœ‹æ¸…ç†åå¤§å°
                sizes_after = cleaner.get_folder_sizes()
                chrome_after = sizes_after.get('chrome_data', 0)
                
                if chrome_before > 0:
                    logger.info(f"   ğŸ’¾ Chromeç¼“å­˜: {chrome_before:.2f}MB â†’ {chrome_after:.2f}MB")
            
            except Exception as e:
                logger.warning(f"âš ï¸  è‡ªåŠ¨æ¸…ç†å¤±è´¥ï¼ˆä¸å½±å“è¿è¡Œï¼‰: {e}")
        # ====================================================
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.mcp_manager = MCPServiceManager()
        self.db = DouyinMarketingDatabase(self.config.get('db_path'))
        self.browser = None
        
        # AIå¼•æ“ï¼ˆä»system.confè‡ªåŠ¨åŠ è½½é…ç½®ï¼‰
        if AIAnalysisEngine is not None and OPENAI_AVAILABLE:
            self.ai = AIAnalysisEngine(config=self.config if self.config else None)
        else:
            self.ai = None
            if not OPENAI_AVAILABLE:
                logger.warning("âš ï¸  OpenAI SDKæœªå®‰è£…ï¼ŒAIåŠŸèƒ½ä¸å¯ç”¨")
            else:
                logger.warning("âš ï¸  AIå¼•æ“æ¨¡å—åŠ è½½å¤±è´¥ï¼ŒAIåŠŸèƒ½ä¸å¯ç”¨")
        
        logger.info(f"æŠ–éŸ³è¥é”€æ™ºèƒ½ä½“åˆå§‹åŒ– - ä¼šè¯ID: {self.session_id}")
    
    async def random_sleep(self, a: float, b: float):
        """å¸¦æŠ–åŠ¨çš„äººç±»åŒ–ç­‰å¾…"""
        await asyncio.sleep(random.uniform(a, b))

    def read_broadcaster_urls(self, max_count: int = 20) -> List[str]:
        """è¯»å–ä¸»æ’­URLåˆ—è¡¨ï¼ˆè¶³æµ´/çƒæˆ¿ï¼‰ï¼Œå»é‡åéšæœºå–Nä¸ª"""
        import random
        
        base_dir = Path(__file__).parent / "media_marketing"
        files = [
            base_dir / "è¶³æµ´è¿è¥ä¸»æ’­.txt",
            base_dir / "çƒæˆ¿è¿è¥ä¸»æ’­.txt",
        ]
        urls: List[str] = []
        for f in files:
            if f.exists():
                try:
                    for line in f.read_text(encoding="utf-8").splitlines():
                        u = line.strip()
                        if u and u.startswith("http"):
                            urls.append(u)
                except Exception as e:
                    logger.warning(f"è¯»å–æ–‡ä»¶å¤±è´¥ {f}: {e}")
            else:
                logger.warning(f"æœªæ‰¾åˆ°ä¸»æ’­åˆ—è¡¨: {f}")
        
        # å»é‡
        seen = set()
        deduped: List[str] = []
        for u in urls:
            if u not in seen:
                seen.add(u)
                deduped.append(u)
        
        # å¦‚æœå¤–éƒ¨åˆ—è¡¨ä¸ºç©ºï¼Œä½¿ç”¨å†…ç½®ç§å­ï¼ˆé¿å…ä»»ä½•äº¤äº’ï¼Œç›´æ¥å¼€æ’­ä¸»ä¸»é¡µï¼‰
        if not deduped:
            logger.info("ğŸ“‹ å¤–éƒ¨åˆ—è¡¨ä¸ºç©ºï¼Œä½¿ç”¨å†…ç½®ç§å­ä¸»æ’­URLï¼ˆéšæœºï¼‰")
            seed_urls = [
                # ç¤ºä¾‹/å ä½ï¼ˆå¯åœ¨è¿è¡Œæ—¶ä»é¡µé¢æ¨èé¡µéšæœºè¿›å…¥åšä¸»ï¼‰
                "https://www.douyin.com/user/MS4wLjABAAAAxxxxxxxxxxxxxxxxxxxxxxxxxxxx1",
                "https://www.douyin.com/user/MS4wLjABAAAAxxxxxxxxxxxxxxxxxxxxxxxxxxxx2",
                "https://www.douyin.com/user/MS4wLjABAAAAxxxxxxxxxxxxxxxxxxxxxxxxxxxx3",
            ]
            random.shuffle(seed_urls)
            deduped = seed_urls

        # ========== éšæœºæ‰“ä¹±é¡ºåºï¼ˆæ¯æ¬¡è¿è¡Œéƒ½ä¸åŒï¼‰==========
        random.shuffle(deduped)
        logger.info(f"ğŸ“ƒ å·²è¯»å–ä¸»æ’­URL {len(deduped)} æ¡ï¼Œéšæœºæ‰“ä¹±åå–å‰ {max_count} ä¸ª")
        
        # å–å‰Nä¸ª
        return deduped[:max_count]
    
    async def initialize(self) -> bool:
        """åˆå§‹åŒ–ï¼ˆæ£€æŸ¥MCPæœåŠ¡å¹¶æ‰“å¼€æµè§ˆå™¨ï¼‰"""
        logger.info("=" * 60)
        logger.info("æŠ–éŸ³è¥é”€æ™ºèƒ½ä½“å¯åŠ¨ä¸­...")
        logger.info("=" * 60)
        
        # æ£€æŸ¥MCPæœåŠ¡ï¼ˆä½ å·²åœ¨ mcp-config.json é…ç½®ï¼‰
        if not await self.mcp_manager.ensure_mcp_chrome_ready():
            logger.error("âŒ MCP chrome æœåŠ¡æœªå°±ç»ª")
            logger.error("è¯·ç¡®ä¿æ‰§è¡Œ: npx -y mcp-chrome-bridge")
            return False
        
        # åˆå§‹åŒ–æµè§ˆå™¨è‡ªåŠ¨åŒ–
        self.browser = DouyinBrowserAutomation(self.mcp_manager.mcp_url)
        logger.info("âœ… æµè§ˆå™¨è‡ªåŠ¨åŒ–å·²åˆå§‹åŒ–")
        
        # æ‰“å¼€æŠ–éŸ³ï¼ˆCookieç™»å½•æˆ–æ‰‹åŠ¨ç™»å½•ï¼‰
        cookie_exists = self.browser.cookie_file.exists()
        logger.info(f"Cookieæ–‡ä»¶: {'å­˜åœ¨' if cookie_exists else 'ä¸å­˜åœ¨'}")
        if not await self.browser.open_douyin(wait_login=not cookie_exists):
            logger.error("âŒ æ‰“å¼€æŠ–éŸ³å¤±è´¥")
            return False

        logger.info("âœ… æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆï¼")
        return True
    
    async def get_videos_with_time_from_homepage(self, max_videos: int = 10) -> List[Dict]:
        """âœ… [MCPæˆªå›¾+deepseek-vl2 OCR] ä»ä¸»æ’­ä¸»é¡µæå–ï¼šè§†é¢‘é“¾æ¥+æ˜¯å¦ç½®é¡¶

        ç­–ç•¥ï¼š
        1. MCPæˆªå›¾ä¸»æ’­ä¸»é¡µ
        2. deepseek-vl2 OCRè¯†åˆ«"ç½®é¡¶"æ ‡è®°
        3. ä»HTMLæå–è§†é¢‘é“¾æ¥
        4. ç»“åˆOCRå’ŒHTMLï¼Œæ ‡è®°ç½®é¡¶è§†é¢‘

        Returns:
            List[Dict]: [
                {'video_url': 'xxx', 'video_id': 'xxx', 'is_pinned': False},
                ...
            ]
        """
        try:
            logger.info(f"ğŸ“ [OCRæ–¹æ¡ˆ] æå–ä¸»é¡µè§†é¢‘ä¿¡æ¯ï¼ˆæœ€å¤š{max_videos}ä¸ªï¼‰...")

            # ========== ğŸ”¥ æ­¥éª¤0ï¼šç®€å•ç­‰å¾…é¡µé¢åŠ è½½ï¼ˆ2-3ç§’è¶³å¤Ÿï¼‰ ==========
            logger.info("   â³ ç­‰å¾…é¡µé¢åŠ è½½...")
            await asyncio.sleep(3)  # æŠ–éŸ³SPAé¡µé¢3ç§’åŸºæœ¬åŠ è½½å®Œæˆ

            # ========== äººç±»åŒ–è¡Œä¸ºï¼šæ»šåŠ¨é¡µé¢ ==========
            logger.info("   ğŸ“œ æ»šåŠ¨ä¸»æ’­ä¸»é¡µ...")
            try:
                await self.browser.call_mcp("chrome_keyboard", {"keys": ["PageDown"]})
                await self.random_sleep(1.5, 2.0)
                await self.browser.call_mcp("chrome_keyboard", {"keys": ["Home"]})
                await self.random_sleep(1.0, 1.5)
            except Exception as e:
                logger.warning(f"   âš ï¸ æ»šåŠ¨å¤±è´¥: {e}ï¼Œç»§ç»­æ‰§è¡Œ")

            # ========== Step 1: MCPæˆªå›¾ä¸»æ’­ä¸»é¡µ ==========
            logger.info("   ğŸ“¸ æˆªå›¾ä¸»æ’­ä¸»é¡µ...")
            screenshot_result = await self.browser.call_tool("chrome_screenshot", {
                "tabId": self.browser.current_tab_id,
                "fullPage": False,
                "storeBase64": True,
                "width": 1920,
                "height": 1080
            })

            # è§£ææˆªå›¾base64æ•°æ®
            import json as json_module
            import re
            import base64
            import io
            from PIL import Image


            screenshot_data = None
            if isinstance(screenshot_result, dict):
                if "content" in screenshot_result:
                    content = screenshot_result["content"]
                    if isinstance(content, list) and len(content) > 0:
                        text_item = content[0]
                        if isinstance(text_item, dict) and "text" in text_item:
                            try:
                                # âœ… ç›´æ¥è§£æ text å­—æ®µï¼Œå¾—åˆ° {"base64Data": "...", "mimeType": "..."}
                                data_obj = json_module.loads(text_item["text"])

                                # âœ… ç›´æ¥æå– base64Data
                                screenshot_data = data_obj.get("base64Data") or data_obj.get("base64")

                                if screenshot_data:
                                    logger.info(f"   âœ… æˆªå›¾æˆåŠŸæå–ï¼Œbase64é•¿åº¦: {len(screenshot_data)}")
                                else:
                                    logger.error(f"   âŒ æ•°æ®å¯¹è±¡ä¸­æ²¡æœ‰ base64Data å­—æ®µ: {list(data_obj.keys())}")

                            except json_module.JSONDecodeError as e:
                                logger.error(f"   âŒ JSONè§£æå¤±è´¥: {e}")
                            except Exception as e:
                                logger.error(f"   âŒ è§£ææˆªå›¾å¼‚å¸¸: {e}")
                                import traceback
                                traceback.print_exc()

            if not screenshot_data:
                logger.error("   âŒ MCPæˆªå›¾å¤±è´¥ï¼Œæ— æ³•æå–base64æ•°æ®")
                return []
            
            logger.info(f"   âœ… æˆªå›¾æˆåŠŸï¼Œå¤§å°: {len(screenshot_data) // 1024}KB (base64)")
            
            # ========== Step 2: å‹ç¼©å›¾ç‰‡åˆ°80KB ==========
            logger.info("   ğŸ—œï¸  å‹ç¼©å›¾ç‰‡...")
            try:
                img_bytes = base64.b64decode(screenshot_data)
                img = Image.open(io.BytesIO(img_bytes))
                
                # é™ä½åˆ†è¾¨ç‡
                width, height = img.size
                if width > 1024 or height > 1024:
                    ratio = min(1024/width, 1024/height)
                    new_size = (int(width*ratio), int(height*ratio))
                    img = img.resize(new_size, Image.Resampling.LANCZOS)
                
                # å‹ç¼©ä¸ºJPEG
                output = io.BytesIO()
                quality = 95
                max_size_kb = 200
                
                while quality > 20:
                    output.seek(0)
                    output.truncate()
                    img.convert('RGB').save(output, format='JPEG', quality=quality, optimize=True)
                    size_kb = len(output.getvalue()) / 1024
                    
                    if size_kb <= max_size_kb:
                        break
                    quality -= 5
                
                compressed_image_b64 = base64.b64encode(output.getvalue()).decode('utf-8')
                logger.info(f"   âœ… å‹ç¼©å®Œæˆ: {size_kb:.1f}KB, quality={quality}")

                # ğŸ”¥ ä¿å­˜æˆªå›¾åˆ°æ–‡ä»¶ä¾›è°ƒè¯•æŸ¥çœ‹
                try:
                    debug_dir = Path(__file__).parent / "media_marketing" / "debug_screenshots"
                    debug_dir.mkdir(parents=True, exist_ok=True)
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    screenshot_path = debug_dir / f"ocr_screenshot_{timestamp}.jpg"
                    screenshot_path.write_bytes(output.getvalue())
                    logger.info(f"   ğŸ’¾ æˆªå›¾å·²ä¿å­˜: {screenshot_path}")
                except Exception as save_error:
                    logger.warning(f"   âš ï¸ ä¿å­˜æˆªå›¾å¤±è´¥(ä¸å½±å“OCR): {save_error}")
                
            except Exception as e:
                logger.error(f"   âŒ å‹ç¼©å›¾ç‰‡å¤±è´¥: {e}ï¼ŒOCRä¸ºå”¯ä¸€æ–¹æ³•ï¼Œæ— æ³•ç»§ç»­")
                return []
            
            # ========== Step 3: è°ƒç”¨deepseek-vl2 OCRè¯†åˆ«"ç½®é¡¶"ï¼ˆä¸¥æ ¼JSONï¼‰ ==========
            logger.info("   ğŸ” OCRè¯†åˆ«ç½®é¡¶æ ‡è®°ï¼ˆJSONï¼‰...")
            ocr_result = await self._call_deepseek_vl2_ocr(compressed_image_b64)
            ocr_videos = []  # [{title,is_pinned,position}]
            if ocr_result.get("success"):
                ocr_content = ocr_result.get("content", "").strip()
                logger.info(f"   âœ… OCRè¯†åˆ«æˆåŠŸï¼Œå†…å®¹é•¿åº¦: {len(ocr_content)}")

                # ğŸ”¥ è°ƒè¯•ï¼šæ‰“å°OCRåŸå§‹è¿”å›
                logger.info(f"   [OCRåŸå§‹è¾“å‡º] {ocr_content[:500]}...")

                try:
                    # å»é™¤å¯èƒ½çš„markdownåŒ…è£¹
                    if ocr_content.startswith('```'):
                        import re as _re
                        ocr_content = _re.sub(r'^```(?:json)?\n', '', ocr_content)
                        ocr_content = _re.sub(r'\n```$', '', ocr_content)
                    import json as _json
                    data = _json.loads(ocr_content)
                    ocr_videos = data.get('videos', []) if isinstance(data, dict) else []
                    logger.info(f"   ğŸ“Š OCRè§£æè§†é¢‘æ¡ç›®: {len(ocr_videos)}")

                    # ğŸ”¥ è°ƒè¯•ï¼šæ‰“å°æ¯ä¸ªè§†é¢‘çš„ç½®é¡¶çŠ¶æ€
                    for idx, v in enumerate(ocr_videos[:5], 1):
                        pinned_mark = "ğŸ“Œç½®é¡¶" if v.get('is_pinned') else "âšªæ­£å¸¸"
                        logger.info(f"      [{idx}] {pinned_mark} | {v.get('title', '')[:20]}")

                except Exception as e:
                    logger.error(f"   âŒ OCR JSONè§£æå¤±è´¥: {e}")
            else:
                logger.warning(f"   âš ï¸  OCRå¤±è´¥: {ocr_result.get('error')}")
            
            # ========== Step 4: è·å–HTMLå¹¶æå–è§†é¢‘é“¾æ¥ ==========
            logger.info("   ğŸ“„ æå–HTMLè§†é¢‘é“¾æ¥...")
            html_result = await self.browser.call_tool("getWebContent", {
                "selector": "body",
                "htmlContent": True
            })
            
            html_content = ""
            try:
                if isinstance(html_result, dict):
                    content_list = html_result.get('content', [])
                    if isinstance(content_list, list) and len(content_list) > 0:
                        first_item = content_list[0]
                        if isinstance(first_item, dict) and 'text' in first_item:
                            text_json_str = first_item.get('text', '')
                            try:
                                parsed_data = json_module.loads(text_json_str)
                                
                                if isinstance(parsed_data, dict):
                                    if 'htmlContent' in parsed_data:
                                        html_content = parsed_data['htmlContent']
                                    elif 'data' in parsed_data and isinstance(parsed_data['data'], dict):
                                        if 'htmlContent' in parsed_data['data']:
                                            html_content = parsed_data['data']['htmlContent']
                                        elif 'content' in parsed_data['data']:
                                            inner_content = parsed_data['data']['content']
                                            if isinstance(inner_content, list) and len(inner_content) > 0:
                                                if isinstance(inner_content[0], dict) and 'text' in inner_content[0]:
                                                    inner_json = json_module.loads(inner_content[0]['text'])
                                                    if isinstance(inner_json, dict) and 'htmlContent' in inner_json:
                                                        html_content = inner_json['htmlContent']
                            except json_module.JSONDecodeError:
                                logger.warning("   âš ï¸  JSONè§£æå¤±è´¥")
                
                if not isinstance(html_content, str):
                    html_content = str(html_content)

                if not html_content:
                    logger.warning("   âŒ æœªæå–åˆ°HTMLå†…å®¹")
                    return []

                logger.info(f"   âœ… æå–åˆ°HTMLï¼Œé•¿åº¦: {len(html_content)} å­—ç¬¦")
                
                # ========== Step 5: ä»HTMLæå–è§†é¢‘é“¾æ¥ ==========
                videos = []
                
                # æå–æ‰€æœ‰è§†é¢‘é“¾æ¥
                video_links = re.findall(r'href="(/video/\d+)"', html_content)
                if not video_links:
                    video_links = re.findall(r'href=\\\\"(/video/\d+)\\\\"', html_content)
                
                logger.info(f"   ğŸ“Š æå–åˆ° {len(video_links)} ä¸ªè§†é¢‘é“¾æ¥")
                
                # å»é‡å¹¶é™åˆ¶æ•°é‡
                seen = set()
                for i, video_link in enumerate(video_links):
                    if len(videos) >= max_videos:
                        break
                    
                    vid_match = re.search(r'/video/(\d+)', video_link)
                    if not vid_match:
                        continue
                    
                    video_id = vid_match.group(1)
                    if video_id in seen:
                        continue
                    seen.add(video_id)
                    
                    video_url = f'https://www.douyin.com/video/{video_id}'
                    
                    # ========== Step 6: ä½¿ç”¨OCRç»“æœåˆ¤æ–­æ˜¯å¦ç½®é¡¶ ==========
                    # âš ï¸ HTMLä¸­ä¸åŒ…å«"ç½®é¡¶"æ–‡å­—ï¼Œåªèƒ½é OCRè¯†åˆ«ï¼
                    is_pinned = False

                    if ocr_videos:
                        # ä»…ç”±OCRå†³å®šç½®é¡¶ï¼ˆHTMLä¸å‚ä¸ç½®é¡¶åˆ¤æ–­ï¼‰
                        if i < len(ocr_videos):
                            ov = ocr_videos[i]
                            is_pinned = bool(ov.get('is_pinned'))

                    videos.append({
                        'video_url': video_url,
                        'video_id': video_id,
                        'is_pinned': is_pinned
                    })
                    
                    logger.info(f"   {'ğŸ“Œ' if is_pinned else 'ğŸ“¹'} è§†é¢‘{i+1}: {video_id[:12]}... {'[ç½®é¡¶]' if is_pinned else ''}")
                
                logger.info(f"   âœ… æˆåŠŸæå– {len(videos)} ä¸ªè§†é¢‘ï¼ˆOCRæ ‡è®°ç½®é¡¶ï¼‰")
                return videos
                
            except Exception as e:
                logger.error(f"   âŒ è§£æHTMLå¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                return []
            
        except Exception as e:
            logger.error(f"   âŒ æå–è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []
            
    async def _call_deepseek_vl2_ocr(self, image_base64: str) -> Dict:
        """è°ƒç”¨deepseek-vl2 OCRè¯†åˆ«å›¾ç‰‡æ–‡å­—ï¼ˆå‹ç¼©å›¾ç‰‡+ä¾¿å®œæ¨¡å‹ï¼‰
        
        Args:
            image_base64: å‹ç¼©åçš„base64å›¾ç‰‡æ•°æ®
        
        Returns:
            {"success": True/False, "content": "OCRæ–‡æœ¬", "error": "é”™è¯¯ä¿¡æ¯"}
        """
        try:
            # ğŸ”¥ ç›´æ¥è¯»å–é…ç½®æ–‡ä»¶ï¼ˆç»•è¿‡config_utilï¼Œå› ä¸ºVPNç¯å¢ƒä¸‹å¯¼å…¥å¯èƒ½å¤±è´¥ï¼‰
            project_root = Path(__file__).parent.parent.parent.parent
            config_path = project_root / "system.conf"
            config_dict = {}
            with open(config_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if '=' in line and not line.startswith('#'):
                        key, value = line.split('=', 1)
                        config_dict[key.strip()] = value.strip()
            
            logger.info(f"   âœ… ç›´æ¥è¯»å–system.confé…ç½®")
            
            # è¯»å–OCRé…ç½®ï¼ˆå…è®¸ç¯å¢ƒå˜é‡è¦†ç›–key/base_urlä¾¿äºå¿«é€Ÿæ’æŸ¥401ï¼‰
            ocr_model = os.environ.get('DOUYIN_MARKETING_OCR_MODEL') or config_dict.get('douyin_marketing_ocr_model', 'Pro/Qwen/Qwen2.5-VL-7B-Instruct')
            ocr_api_key = os.environ.get('DOUYIN_MARKETING_OCR_API_KEY') or config_dict.get('douyin_marketing_ocr_api_key', '')
            ocr_base_url = os.environ.get('DOUYIN_MARKETING_OCR_BASE_URL') or config_dict.get('douyin_marketing_ocr_base_url', 'https://api.siliconflow.cn/v1')
            ocr_temperature = float(config_dict.get('douyin_marketing_ocr_temperature', '0.1'))
            ocr_max_tokens = int(config_dict.get('douyin_marketing_ocr_max_tokens', '2000'))
            # å…³é”®é…ç½®æ©ç æ—¥å¿—ï¼ˆä¾¿äºæ ¸å¯¹ä¸å•æµ‹ä¸€è‡´ï¼‰
            try:
                mk = (ocr_api_key[:4] + '...' + ocr_api_key[-4:]) if isinstance(ocr_api_key, str) and len(ocr_api_key) > 8 else 'N/A'
                logger.info(f"   ğŸ§­ OCRé…ç½®æ ¡éªŒ: model={ocr_model}, base_url={ocr_base_url}, key={mk}")
            except Exception:
                pass
            
            prompt = """
ä½ æ˜¯ä¸€ä¸ªç²¾ç¡®çš„OCRè¯†åˆ«åŠ©æ‰‹ã€‚è¯·è¯†åˆ«æŠ–éŸ³ä¸»é¡µæˆªå›¾ä¸­çš„è§†é¢‘ï¼Œå¹¶åˆ¤æ–­æ˜¯å¦æœ‰"ç½®é¡¶"æ ‡ç­¾ã€‚

ã€ç½®é¡¶æ ‡ç­¾çš„è¯†åˆ«è§„åˆ™ã€‘
1. **ä½ç½®**ï¼šè§†é¢‘ç¼©ç•¥å›¾çš„å·¦ä¸Šè§’
2. **å¤–è§‚**ï¼šä¸€ä¸ªç‹¬ç«‹çš„å°çŸ©å½¢æ ‡ç­¾ï¼ˆä¸æ˜¯è§†é¢‘å°é¢æœ¬èº«çš„é¢œè‰²ï¼‰
3. **é¢œè‰²**ï¼šé»„è‰²æˆ–æ©™è‰²èƒŒæ™¯
4. **æ–‡å­—**ï¼šæ ‡ç­¾ä¸Šå¿…é¡»æœ‰"ç½®é¡¶"ä¸¤ä¸ªæ¸…æ™°çš„ä¸­æ–‡å­—

ã€âš ï¸ ä¸¥æ ¼è§„åˆ™ - é˜²æ­¢è¯¯åˆ¤ã€‘
- âŒ å¦‚æœåªæ˜¯è§†é¢‘å°é¢æœ¬èº«æ˜¯é»„è‰²/æ©™è‰² â†’ ä¸æ˜¯ç½®é¡¶
- âŒ å¦‚æœçœ‹ä¸åˆ°"ç½®é¡¶"ä¸¤ä¸ªå­— â†’ ä¸æ˜¯ç½®é¡¶
- âŒ å¦‚æœä¸ç¡®å®š â†’ æ ‡è®°ä¸º false
- âœ… åªæœ‰åŒæ—¶æ»¡è¶³ï¼šç‹¬ç«‹æ ‡ç­¾ + é»„/æ©™è‰² + "ç½®é¡¶"æ–‡å­— â†’ æ‰æ˜¯ç½®é¡¶

ã€è¾“å‡ºæ ¼å¼ã€‘ä¸¥æ ¼JSONï¼ŒæŒ‰ä»ä¸Šåˆ°ä¸‹ã€ä»å·¦åˆ°å³çš„é¡ºåº
{
  "videos": [
    {"title": "è§†é¢‘æ ‡é¢˜æˆ–æè¿°", "is_pinned": false, "position": 1},
    {"title": "è§†é¢‘æ ‡é¢˜æˆ–æè¿°", "is_pinned": false, "position": 2}
  ]
}

ã€ç¤ºä¾‹ã€‘
// æœ‰ç½®é¡¶çš„æƒ…å†µï¼ˆèƒ½æ¸…æ¥šçœ‹åˆ°å·¦ä¸Šè§’çš„"ç½®é¡¶"æ ‡ç­¾ï¼‰
{"videos": [
  {"title": "åº—é“ºä»‹ç»", "is_pinned": true, "position": 1},
  {"title": "äº§å“å±•ç¤º", "is_pinned": true, "position": 2},
  {"title": "æ—¥å¸¸", "is_pinned": false, "position": 3}
]}

// æ²¡æœ‰ç½®é¡¶çš„æƒ…å†µï¼ˆæ‰€æœ‰è§†é¢‘éƒ½æ²¡æœ‰"ç½®é¡¶"æ ‡ç­¾ï¼‰
{"videos": [
  {"title": "è§†é¢‘1", "is_pinned": false, "position": 1},
  {"title": "è§†é¢‘2", "is_pinned": false, "position": 2},
  {"title": "è§†é¢‘3", "is_pinned": false, "position": 3}
]}

ã€é‡è¦æé†’ã€‘
- åªè¾“å‡ºJSONï¼Œä¸è¦ä»»ä½•å…¶ä»–æ–‡å­—
- è¯†åˆ«è‡³å°‘10ä¸ªè§†é¢‘ï¼ˆå¦‚æœé¡µé¢æœ‰çš„è¯ï¼‰
- is_pinned åªèƒ½æ˜¯ true æˆ– false
- ğŸ”¥ å¦‚æœä¸ç¡®å®šæ˜¯å¦ç½®é¡¶ï¼Œå¿…é¡»æ ‡è®°ä¸º falseï¼ˆå®å¯æ¼æ‰ä¹Ÿä¸è¦è¯¯åˆ¤ï¼‰
- ğŸ”¥ å¤§éƒ¨åˆ†ä¸»æ’­éƒ½æ²¡æœ‰ç½®é¡¶è§†é¢‘ï¼Œè¿™æ˜¯æ­£å¸¸çš„ï¼
"""
            
            payload = {
                "model": ocr_model,
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "image_url",
                                "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                            },
                            {
                                "type": "text",
                                "text": prompt
                            }
                        ]
                    }
                ],
                "max_tokens": ocr_max_tokens,
                "temperature": ocr_temperature,
                "top_p": 0.7
            }
            
            headers = {
                "Authorization": f"Bearer {ocr_api_key}",
                "Content-Type": "application/json"
            }
            
            # ğŸ”¥ åˆ›å»ºClientSessionæ—¶ç¦ç”¨ä»£ç†
            connector = aiohttp.TCPConnector()
            async with aiohttp.ClientSession(connector=connector, trust_env=False) as session:
                async with session.post(
                    f"{ocr_base_url}/chat/completions",
                    json=payload,
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=120)  # å¢åŠ åˆ°120ç§’
                ) as resp:
                    if resp.status == 200:
                        result = await resp.json()
                        content = result.get('choices', [{}])[0].get('message', {}).get('content', '')
                        usage = result.get('usage', {})
                        logger.info(f"   âœ… OCRæˆåŠŸ: tokens={usage.get('total_tokens', 0)}, model={ocr_model}")
                        return {"success": True, "content": content}
                    else:
                        error_text = await resp.text()
                        logger.error(f"   âŒ OCR APIé”™è¯¯: {resp.status} - {error_text}")
                        return {"success": False, "error": f"APIé”™è¯¯: {resp.status}"}
        
        except Exception as e:
            logger.error(f"   âŒ OCRè°ƒç”¨å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {"success": False, "error": str(e)}
    
    
    async def run_daily_task(self):
        """æ¯æ—¥è¥é”€ä»»åŠ¡ï¼ˆä¸»é€»è¾‘ï¼‰"""
        import re
        import json as json_module
        
        logger.info("ğŸš€ å¯åŠ¨æ¯æ—¥è¥é”€ä»»åŠ¡...")
        
        stats = {
            'start_time': datetime.now().isoformat(),
            'accounts_processed': 0,
            'comments_posted': 0,
            'users_analyzed': 0,
            'targets_found': 0,
            'success': False
        }
        
        try:
            # ==================== æ­£ç¡®çš„ä¸šåŠ¡æµç¨‹ ====================
            # ä½ çš„ä¸šåŠ¡ï¼šå¨±ä¹åœºæ‰€äººåŠ›èµ„æºæœåŠ¡å•†ï¼ˆè¶³æµ´/KTV/æŒ‰æ‘©/å°çƒå…ç­‰ï¼‰
            # ç›®æ ‡ï¼šæ‰¾è¿™äº›è¡Œä¸šçš„è€æ¿ã€ç®¡ç†è€…ã€ä»ä¸šè€…
            
            # è¯»å–ä¸»æ’­åˆ—è¡¨å¹¶é€ä¸ªå¤„ç†
            broadcasters = self.read_broadcaster_urls(max_count=20)
            if not broadcasters:
                logger.warning("æœªè¯»å–åˆ°ä¸»æ’­URLï¼Œå°è¯•ä½¿ç”¨å½“å‰é¡µ")
                broadcasters = ["https://www.douyin.com/?recommend=1"]

            video_comment_count: Dict[str, int] = {}

            for idx, profile_url in enumerate(broadcasters, start=1):
                logger.info(f"\n{'='*60}")
                logger.info(f"ğŸ“Œ æ‰“å¼€ä¸»æ’­ä¸»é¡µ[{idx}/{len(broadcasters)}]: {profile_url}")
                logger.info(f"{'='*60}")

                # ========== æ­¥éª¤1ï¼šæ‰“å¼€ä¸»æ’­ä¸»é¡µ ==========
                nav_result = await self.browser.call_tool("navigate", {"url": profile_url})
                homepage_tab_id = None  # ä¸»æ’­ä¸»é¡µçš„tabIdï¼ˆéœ€è¦ä¿ç•™ï¼‰
                
                try:
                    if isinstance(nav_result, dict):
                        if 'tabId' in nav_result:
                            homepage_tab_id = nav_result['tabId']
                        elif 'content' in nav_result and isinstance(nav_result['content'], list):
                            if len(nav_result['content']) > 0:
                                text_str = nav_result['content'][0].get('text', '')
                                import json as json_module
                                parsed1 = json_module.loads(text_str)
                                if 'data' in parsed1 and 'content' in parsed1['data']:
                                    inner_content = parsed1['data']['content']
                                    if isinstance(inner_content, list) and len(inner_content) > 0:
                                        inner_text = inner_content[0].get('text', '')
                                        parsed2 = json_module.loads(inner_text)
                                        homepage_tab_id = parsed2.get('tabId')
                    
                    if homepage_tab_id:
                        self.browser.current_tab_id = homepage_tab_id
                        logger.info(f"   [ä¸»æ’­ä¸»é¡µtabId] å·²ä¿å­˜: {homepage_tab_id}")
                except Exception as e:
                    logger.error(f"   [tabId] è§£æå¤±è´¥: {e}")
                
                # ========== äººç±»åŒ–ç­‰å¾…ï¼ˆæ‰“å¼€ä¸»é¡µåï¼‰ ==========
                await self.random_sleep(2.5, 4.0)

                # ========== æ­¥éª¤2+3ï¼šâœ… ä»ä¸»é¡µä¸€æ¬¡æ€§æå–è§†é¢‘ä¿¡æ¯ï¼ˆé“¾æ¥+æ—¶é—´+ç½®é¡¶æ ‡è®°ï¼‰ ==========
                all_videos = await self.get_videos_with_time_from_homepage(max_videos=10)
                if not all_videos:
                    logger.warning("è¯¥ä¸»æ’­ä¸»é¡µæœªæ‰¾åˆ°è§†é¢‘ä¿¡æ¯ï¼Œè·³è¿‡")
                    # å…³é—­ä¸»æ’­ä¸»é¡µ
                    await self.browser.close_current_tab()
                    await self.random_sleep(0.5, 1.0)
                    continue
                                
                # ========== è¿‡æ»¤è§†é¢‘ï¼šè·³è¿‡ç½®é¡¶ï¼Œé€‰æ‹©å‰2ä¸ªéç½®é¡¶è§†é¢‘ ==========
                videos_to_process = []
                for video in all_videos:
                    # è·³è¿‡ç½®é¡¶è§†é¢‘
                    if video.get('is_pinned'):
                        logger.info(f"   ğŸ“Œ è·³è¿‡ç½®é¡¶è§†é¢‘: {video['video_id']}")
                        continue

                    # é€‰æ‹©å‰2ä¸ªéç½®é¡¶è§†é¢‘
                    if len(videos_to_process) < 2:
                        videos_to_process.append(video)
                        logger.info(f"   âœ… é€‰ä¸­è§†é¢‘: {video['video_id']} (å½“å‰{len(videos_to_process)}/2ä¸ª)")
                    else:
                        logger.info(f"   â›” å·²æ»¡2ä¸ªï¼Œè·³è¿‡: {video['video_id']}")
                        break  # å·²ç»æ»¡äº†ï¼Œä¸å†æ£€æŸ¥
                
                # ========== æ­¥éª¤4ï¼šå¤„ç†ç­›é€‰å‡ºçš„è§†é¢‘ ==========
                if not videos_to_process:
                    logger.warning("è¯¥ä¸»æ’­æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„è§†é¢‘ï¼Œå…³é—­ä¸»é¡µ")
                    # æ¢å¤åˆ°ä¸»æ’­ä¸»é¡µçš„tabIdå¹¶å…³é—­
                    self.browser.current_tab_id = homepage_tab_id
                    await self.browser.close_current_tab()
                    await self.random_sleep(0.5, 1.0)
                    continue
                
                logger.info(f"\n{'='*60}")
                logger.info(f"ğŸ¯ å¼€å§‹å¤„ç† {len(videos_to_process)} ä¸ªè§†é¢‘")
                logger.info(f"{'='*60}")
                
                for video_idx, video in enumerate(videos_to_process, start=1):
                    try:
                        video_url = video['video_url']
                        video_id = re.search(r'/video/(\d+)', video_url).group(1) if re.search(r'/video/(\d+)', video_url) else ''
                        
                        logger.info(f"\n{'â”€'*60}")
                        logger.info(f"ğŸ¬ å¤„ç†è§†é¢‘ [{video_idx}/{len(videos_to_process)}]")
                        logger.info(f"   è§†é¢‘ID: {video_id}")
                        logger.info(f"   å‘å¸ƒæ—¶é—´: {video.get('time_text', 'æœªçŸ¥')}")
                        logger.info(f"{'â”€'*60}")
                        
                        # ========== æ‰“å¼€è§†é¢‘è¯¦æƒ…é¡µ ==========
                        logger.info("   ğŸ“º æ‰“å¼€è§†é¢‘è¯¦æƒ…é¡µ...")
                        nav_result = await self.browser.call_tool("navigate", {"url": video_url})
                        
                        # ä¿å­˜è§†é¢‘é¡µçš„tabId
                        video_tab_id = None
                        try:
                            # ğŸ”¥ è°ƒè¯•ï¼šæ‰“å°navigateè¿”å›çš„åŸå§‹ç»“æœ
                            logger.info(f"   [è°ƒè¯•] navigateè¿”å›ç±»å‹: {type(nav_result)}")

                            if isinstance(nav_result, dict):
                                # æ–¹æ³•1ï¼šç›´æ¥è¿”å›tabId
                                if 'tabId' in nav_result:
                                    video_tab_id = nav_result['tabId']
                                    logger.info(f"   [tabId] æ–¹æ³•1æˆåŠŸ: {video_tab_id}")
                                # æ–¹æ³•2ï¼šåµŒå¥—åœ¨contenté‡Œ
                                elif 'content' in nav_result:
                                    text_str = nav_result['content'][0].get('text', '')
                                    import json as json_module
                                    parsed1 = json_module.loads(text_str)
                                    if 'data' in parsed1 and 'content' in parsed1['data']:
                                        inner_text = parsed1['data']['content'][0].get('text', '')
                                        parsed2 = json_module.loads(inner_text)
                                        video_tab_id = parsed2.get('tabId')
                                        logger.info(f"   [tabId] æ–¹æ³•2æˆåŠŸ: {video_tab_id}")
                                # æ–¹æ³•3ï¼šç›´æ¥åœ¨é¡¶å±‚
                                elif 'data' in nav_result:
                                    video_tab_id = nav_result.get('data', {}).get('tabId')
                                    logger.info(f"   [tabId] æ–¹æ³•3æˆåŠŸ: {video_tab_id}")

                            if video_tab_id:
                                self.browser.current_tab_id = video_tab_id
                                logger.info(f"   âœ… è§†é¢‘tabIdå·²æ›´æ–°: {video_tab_id}")
                            else:
                                logger.warning(f"   âš ï¸ æœªèƒ½è§£æå‡ºtabIdï¼Œå°†ä½¿ç”¨å½“å‰tabId: {self.browser.current_tab_id}")
                        except Exception as e:
                            logger.warning(f"   [è§†é¢‘tabId] è§£æå¤±è´¥: {e}")
                            logger.warning(f"   å°†ä½¿ç”¨å½“å‰tabId: {self.browser.current_tab_id}")

                        # ========== ğŸ”¥ ç­‰å¾…è§†é¢‘è¯¦æƒ…é¡µåŠ è½½å¹¶æ»šåŠ¨åŠ è½½è¯„è®º ==========
                        logger.info("   â³ ç­‰å¾…è§†é¢‘è¯¦æƒ…é¡µåŠ è½½...")
                        await asyncio.sleep(3)  # å…ˆç­‰3ç§’åŸºç¡€åŠ è½½

                        # æ»šåŠ¨é¡µé¢åŠ è½½è¯„è®ºåŒº
                        logger.info("   ğŸ“œ æ»šåŠ¨åŠ è½½è¯„è®ºåŒº...")
                        try:
                            for _ in range(3):  # æ»šåŠ¨3æ¬¡
                                await self.browser.call_mcp("chrome_keyboard", {"keys": ["PageDown"]})
                                await asyncio.sleep(1.5)
                            # æ»šå›é¡¶éƒ¨æŸ¥çœ‹è¯„è®º
                            await self.browser.call_mcp("chrome_keyboard", {"keys": ["Home"]})
                            await asyncio.sleep(2)
                        except Exception as e:
                            logger.warning(f"   âš ï¸ æ»šåŠ¨å¤±è´¥: {e}")

                        logger.info("   âœ… è§†é¢‘è¯¦æƒ…é¡µå·²åŠ è½½")
                        video_page_loaded = True

                        # ========== äººç±»åŒ–ç­‰å¾…ï¼ˆè§†é¢‘è¯¦æƒ…é¡µåŠ è½½å®Œæˆåï¼‰ ==========
                        await self.random_sleep(1.0, 2.0)

                        # 1. è·å–è§†é¢‘è¯„è®ºåŒºï¼ˆä½¿ç”¨ç‹¬ç«‹CommentFetcherï¼‰
                        logger.info(f"   ğŸ“Š å¼€å§‹æŠ“å–è¯„è®º...")

                        # ğŸ”¥ è°ƒè¯•ï¼šå…ˆç”¨JSæ£€æŸ¥DOMç»“æ„
                        try:
                            check_dom_js = """
                            (() => {
                                const allDataE2e = new Set();
                                document.querySelectorAll('[data-e2e]').forEach(el => {
                                    allDataE2e.add(el.getAttribute('data-e2e'));
                                });
                                return {
                                    allDataE2eAttrs: Array.from(allDataE2e),
                                    hasCommentItem: !!document.querySelector('[data-e2e="comment-item"]'),
                                    commentRelated: Array.from(allDataE2e).filter(attr => attr.includes('comment'))
                                };
                            })()
                            """
                            dom_result = await self.browser.call_mcp("chrome_inject_script", {"script": check_dom_js})
                            if isinstance(dom_result, dict) and 'content' in dom_result:
                                try:
                                    import json as json_mod
                                    text_str = dom_result['content'][0].get('text', '{}')
                                    dom_info = json_mod.loads(text_str)
                                    logger.info(f"   [è°ƒè¯•] DOMæ£€æŸ¥ç»“æœ: {dom_info}")
                                except:
                                    pass
                        except Exception as e:
                            logger.warning(f"   [è°ƒè¯•] DOMæ£€æŸ¥å¤±è´¥: {e}")

                        if COMMENT_FETCHER_AVAILABLE and CommentFetcher:
                            fetcher = CommentFetcher(
                                mcp_chrome_url=self.browser.mcp_url,
                                chrome_debug_port=9222
                            )
                            # ä¼ å…¥sessionå’Œtabï¼ˆmcp-chromeæ–¹æ¡ˆéœ€è¦ï¼‰
                            fetcher.session_id = self.browser.session_id
                            fetcher.current_tab_id = self.browser.current_tab_id

                            # è°ƒç”¨get_commentsï¼Œè·å–æœ€å¤š500æ¡è¯„è®º
                            video_comments = await fetcher.get_comments(
                                video_url=video_url,
                                limit=500,
                                method="auto"  # è‡ªåŠ¨åˆ‡æ¢ï¼šchrome-devtools-mcp -> mcp-chrome
                            )
                            fetcher.cleanup()
                        else:
                            logger.error("âŒ CommentFetcherä¸å¯ç”¨")
                            video_comments = []

                        logger.info(f"   âœ… è¯„è®ºæŠ“å–å®Œæˆ: å…± {len(video_comments)} æ¡")
                        if video_comments:
                            logger.info(f"      ğŸ“ é¢„è§ˆå‰3æ¡è¯„è®º:")
                            for i, c in enumerate(video_comments[:3], 1):
                                nick = c.get('nickname', 'N/A')[:15]
                                text = c.get('comment_text', 'N/A')[:40]
                                logger.info(f"         [{i}] {nick}: {text}")
                        else:
                            logger.info("   âš ï¸ æ— è¯„è®ºï¼Œæ‰§è¡Œä¿åº•ï¼šå‘å¸ƒ1æ¡åŸºç¡€è¯„è®ºï¼Œç„¶åè·³è¿‡å›å¤ä¸AIåˆ†æ")
                            # ç”Ÿæˆä¿åº•è¯„è®ºï¼ˆä¼˜å…ˆAIï¼Œå¤±è´¥ç”¨å›ºå®šæ–‡æ¡ˆï¼‰
                            fallback_comment = "è·¯è¿‡æ‰“ä¸ªæ‹›å‘¼ï¼Œç¥ç”Ÿæ„å…´éš†ï¼"
                            try:
                                if self.ai:
                                    gen = await self.ai.generate_comment(
                                        video_info=video,
                                        my_name="äºšæ´²ä¹‹å¤œ",
                                        video_comments=[]
                                    )
                                    if isinstance(gen, dict):
                                        fallback_comment = str(gen.get('comment') or fallback_comment)
                                    elif isinstance(gen, str) and gen.strip():
                                        fallback_comment = gen.strip()
                            except Exception:
                                pass
                            # å‘å¸ƒä¸€æ¡è¯„è®º
                            try:
                                if await self.browser.post_comment(video_url, fallback_comment):
                                    video_comment_count[video_id] = 1
                                    stats['comments_posted'] += 1
                                    self.db.save_comment(fallback_comment)
                                    if video_id:
                                        self.db.record_video_comment(video_id, video_url, fallback_comment)
                                    logger.info("   âœ… ä¿åº•è¯„è®ºå·²å‘å¸ƒ")
                                else:
                                    logger.warning("   âš ï¸ ä¿åº•è¯„è®ºå‘å¸ƒå¤±è´¥")
                            except Exception:
                                logger.warning("   âš ï¸ ä¿åº•è¯„è®ºæµç¨‹å¼‚å¸¸")
                            # å…³é—­è§†é¢‘é¡µåç»§ç»­ä¸‹ä¸€ä¸ªï¼ˆä¸åšå›å¤/åˆ†æï¼‰
                            await self.browser.close_current_tab()
                            await self.random_sleep(1, 2)
                            continue

                        # 2. ä½¿ç”¨AIå¼•æ“ç”Ÿæˆè¯„è®º
                        # Type safety: check AI engine
                        if self.ai is None:
                            logger.warning("AI engine not initialized, using fallback comment")
                            comment_text = "Great content, keep it up!"
                        else:
                            comment_text = await self.ai.generate_comment(
                            video_info=video,
                            my_name="äºšæ´²ä¹‹å¤œ",
                            video_comments=video_comments
                        )

                        # 3. å‘è¡¨è¯„è®ºï¼ˆä½¿ç”¨åŸæœ‰æ–¹æ³•ï¼‰
                        current_cnt = video_comment_count.get(video_id, 0)
                        if current_cnt < 2:
                            if not self.db.is_similar_comment(comment_text):
                                if await self.browser.post_comment(video_url, comment_text):
                                    video_comment_count[video_id] = current_cnt + 1
                                    stats['comments_posted'] += 1
                                    self.db.save_comment(comment_text)
                                    if video_id:
                                        self.db.record_video_comment(video_id, video_url, comment_text)
                                    logger.info(f"   âœ… è¯„è®ºæˆåŠŸ: {comment_text}")
                                    await self.random_sleep(2.5, 4.0)
                            else:
                                logger.info("   âš ï¸ è¯„è®ºä¸å†å²è¿‡äºç›¸ä¼¼ï¼Œè·³è¿‡æœ¬æ¬¡")
                        else:
                            logger.info("   â›” å·²è¾¾åˆ°è¯¥è§†é¢‘2æ¡è¯„è®ºä¸Šé™ï¼Œè·³è¿‡è¯„è®º")

                        # ========== äººç±»åŒ–ç­‰å¾…ï¼ˆè¯„è®ºå’Œå›å¤ä¹‹é—´ï¼‰ ==========
                        await self.random_sleep(2.0, 3.5)

                        # 4a. ç­–ç•¥2ï¼šåœ¨è¯„è®ºè€…çš„è¯„è®ºä¸‹å›å¤ï¼ˆæœ€å¤š3ä¸ªï¼‰
                        for comment in video_comments[:3]:
                            try:
                                nick = comment.get('nickname', '')
                                if not nick:
                                    continue
                                # âœ… ä½¿ç”¨å›å¤æ¨¡å¼ç”Ÿæˆè¯„è®º
                                # Type safety: check AI engine
                                if self.ai is None:
                                    logger.warning("AI engine not initialized, using fallback reply")
                                    reply_text = "Thanks for sharing!"
                                else:
                                    reply_text = await self.ai.generate_comment(
                                    video_info=video,
                                    my_name="äºšæ´²ä¹‹å¤œ",
                                    is_reply=True,  # æ ‡è®°ä¸ºå›å¤æ¨¡å¼
                                    target_comment=comment  # ä¼ å…¥è¦å›å¤çš„è¯„è®º
                                )
                                reply_text = f"@{nick} " + reply_text[:80]
                                await self.browser.reply_to_comment(video_url, nick, reply_text)
                                await self.random_sleep(1.5, 2.5)
                            except Exception as e:
                                logger.warning(f"   å›å¤è¯„è®ºå¤±è´¥: {e}")
                                continue
                                        
                        # 4b. åˆ†æè¯„è®ºåŒºç”¨æˆ·ï¼ˆæ·±åº¦åˆ†æï¼‰
                        logger.info(f"\n   ğŸ§  å¼€å§‹AIåˆ†æè¯„è®ºç”¨æˆ·ï¼ˆå‰10ä¸ªï¼‰...")
                        analyzed_count = 0
                        high_intent_count = 0
                        medium_intent_count = 0
                        low_intent_count = 0
                        
                        for idx, comment in enumerate(video_comments[:10], 1):
                            try:
                                user = {
                                    'nickname': comment.get('nickname', ''),
                                    'signature': comment.get('signature', ''),
                                    'comment_text': comment.get('comment_text', '')
                                }
                                logger.info(f"   [{idx}/10] é¢„ç­›é€‰: {user['nickname'][:15]}...")
                                
                                # Type safety: check AI engine
                                if self.ai is None:
                                    logger.warning("AI engine not initialized, skipping profile check")
                                    should_visit = {"should_visit": False}
                                else:
                                    should_visit = await self.ai.should_visit_profile(user, context={
                                    'video': video,
                                    'account': {'nickname': 'ä¸»æ’­', 'industry': 'å¨±ä¹æœåŠ¡'}
                                })
                                
                                if should_visit.get('should_visit'):
                                    logger.info(f"      âœ… é€šè¿‡åˆç­›ï¼Œå¼€å§‹æ·±åº¦åˆ†æ...")
                                    profile_url = comment.get('profile_url', '')
                                    user_id = comment.get('user_id', '')
                                    if profile_url:
                                        profile_data = await self.browser.get_user_profile_data(profile_url)
                                        analyzed_count += 1
                                        stats['users_analyzed'] += 1
                                        
                                        # Type safety: check AI engine
                                        if self.ai is None:
                                            logger.warning("AI engine not initialized, skipping analysis")
                                            analysis = {"is_target": False, "confidence": 0.0, "reason": "AI not available"}
                                        else:
                                            analysis = await self.ai.analyze_user_profile(
                                            user_comment_data=comment,
                                            profile_data=profile_data,
                                            target_category="å¨±ä¹è¡Œä¸š"
                                        )
                                        
                                        is_target = bool(analysis.get('is_target'))
                                        confidence = float(analysis.get('confidence', 0.0))
                                        reason = analysis.get('reason', 'æ— ')
                                        
                                        # ç»Ÿè®¡æ„å‘åº¦
                                        if confidence >= 0.7:
                                            high_intent_count += 1
                                            intent_label = "ğŸ”¥ é«˜æ„å‘"
                                        elif confidence >= 0.4:
                                            medium_intent_count += 1
                                            intent_label = "âš¡ ä¸­æ„å‘"
                                        else:
                                            low_intent_count += 1
                                            intent_label = "â„ï¸ ä½æ„å‘"
                                        
                                        logger.info(f"      {intent_label} | ç½®ä¿¡åº¦: {confidence:.2f} | åŸå› : {reason[:30]}")
                                        
                                        if user_id:
                                            self.db.record_user_analysis(user_id, is_target, confidence)
                                        
                                        if is_target and not self.db.already_messaged(user_id or profile_url):
                                            logger.info(f"      ğŸ’¬ å‡†å¤‡ç§ä¿¡...")
                                            message = (
                                                "è€æ¿æ‚¨å¥½ï¼æˆ‘ä»¬ä¸“åšå¨±ä¹åœºæ‰€äººåŠ›èµ„æºæœåŠ¡ï¼ˆæ‹›è˜/åŸ¹è®­/ç®¡ç†ï¼‰ã€‚"
                                                "è‹¥æ‚¨è¿‘æœŸæœ‰äººæ‰éœ€æ±‚æˆ–ç®¡ç†å‡çº§ï¼Œæ¬¢è¿èŠèŠï¼Œæˆ‘ä»¬æœ‰æˆç†Ÿæ–¹æ¡ˆã€‚"
                                            )
                                            if await self.browser.send_private_message(profile_url, message):
                                                stats['targets_found'] += 1
                                                self.db.record_message(user_id or profile_url, message, account_source=profile_url)
                                                logger.info(f"      âœ… ç§ä¿¡å‘é€æˆåŠŸ")
                                                if user_id:
                                                    self.db.save_client({
                                                        'douyin_id': user_id,
                                                        'nickname': user.get('nickname') or profile_data.get('nickname', ''),
                                                        'confidence': confidence,
                                                        'venue_type': None,
                                                        'tags': ['å¨±ä¹è¡Œä¸š']
                                                    })
                                        else:
                                            logger.info(f"      â­ï¸ è·³è¿‡ç§ä¿¡ï¼ˆä½æ„å‘æˆ–å·²è”ç³»ï¼‰")
                                else:
                                    logger.info(f"      â­ï¸ æœªé€šè¿‡åˆç­›ï¼Œè·³è¿‡")
                                    
                            except Exception as e:
                                logger.error(f"   âŒ åˆ†æç”¨æˆ·å¤±è´¥: {e}")
                                continue
                        
                        # è¾“å‡ºæœ¬è§†é¢‘çš„åˆ†æç»Ÿè®¡
                        logger.info(f"\n   ğŸ“Š æœ¬è§†é¢‘åˆ†æç»Ÿè®¡:")
                        logger.info(f"      - æ€»è¯„è®ºæ•°: {len(video_comments)}")
                        logger.info(f"      - æ·±åº¦åˆ†æ: {analyzed_count} ä¸ªç”¨æˆ·")
                        logger.info(f"      - ğŸ”¥ é«˜æ„å‘: {high_intent_count} ä¸ª (â‰¥0.7)")
                        logger.info(f"      - âš¡ ä¸­æ„å‘: {medium_intent_count} ä¸ª (0.4-0.7)")
                        logger.info(f"      - â„ï¸ ä½æ„å‘: {low_intent_count} ä¸ª (<0.4)")
                        logger.info(f"      - ğŸ’¬ å‘é€ç§ä¿¡: {stats['targets_found']} ä¸ª\n")
                                    
                        stats['accounts_processed'] += 1
                        
                        # ========== å¤„ç†å®Œæˆï¼Œå…³é—­è§†é¢‘è¯¦æƒ…é¡µ ==========
                        logger.info(f"   ğŸ”™ è§†é¢‘å¤„ç†å®Œæˆï¼Œå…³é—­è§†é¢‘é¡µ...")
                        await self.browser.close_current_tab()
                        await self.random_sleep(1, 2)
                        
                    except Exception as e:
                        logger.error(f"å¤„ç†è§†é¢‘å¤±è´¥: {e}")
                        # å³ä½¿å‡ºé”™ä¹Ÿè¦å…³é—­è§†é¢‘é¡µ
                        try:
                            await self.browser.close_current_tab()
                        except:
                            pass
                        continue
                
                # ========== æ‰€æœ‰è§†é¢‘å¤„ç†å®Œæˆï¼Œå…³é—­ä¸»æ’­ä¸»é¡µ ==========
                logger.info(f"\nâœ… ä¸»æ’­ [{idx}/{len(broadcasters)}] æ‰€æœ‰è§†é¢‘å¤„ç†å®Œæˆï¼Œå…³é—­ä¸»æ’­ä¸»é¡µ")
                self.browser.current_tab_id = homepage_tab_id
                await self.browser.close_current_tab()
                await self.random_sleep(1, 2)
            
            stats['end_time'] = datetime.now().isoformat()
            stats['success'] = True
            
            logger.info(f"\n=== ä»»åŠ¡å®Œæˆ ===")
            logger.info(json.dumps(stats, ensure_ascii=False, indent=2))
            return stats
            
        except Exception as e:
            stats['error'] = str(e)
            logger.error(f"ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
            return stats
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.mcp_manager.cleanup()


# ==================== A2Aå·¥å…·æ¥å£ ====================
def a2a_tool_douyin_marketing(query: str, **kwargs) -> str:
    """A2Aå·¥å…·æ¥å£"""
    import asyncio
    
    try:
        if isinstance(query, str):
            params = json.loads(query) if query.startswith('{') else {"action": "get_stats"}
        else:
            params = query
        
        action = params.get('action', 'run_daily_task')
        
    except Exception as e:
        return json.dumps({"error": f"å‚æ•°é”™è¯¯: {e}"}, ensure_ascii=False)
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    agent = DouyinMarketingAgent()
    
    # æ‰§è¡Œ
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        # åˆå§‹åŒ–
        if not loop.run_until_complete(agent.initialize()):
            return json.dumps({"error": "åˆå§‹åŒ–å¤±è´¥"}, ensure_ascii=False)
        
        # æ‰§è¡Œä»»åŠ¡
        if action == "run_daily_task":
            result = loop.run_until_complete(agent.run_daily_task())
        else:
            result = {"error": f"æœªçŸ¥æ“ä½œ: {action}"}
        
        agent.cleanup()
        return json.dumps(result, ensure_ascii=False, indent=2)
        
    finally:
        loop.close()


# ==================== å‘½ä»¤è¡Œå¯åŠ¨ ====================
if __name__ == "__main__":
    async def main():
        """ä¸»å‡½æ•° - ä¸€é”®å¯åŠ¨å®Œæ•´ç³»ç»Ÿ"""
        print("\n" + "=" * 80)
        print("â•‘" + " " * 78 + "â•‘")
        print("â•‘" + "    ğŸš€ æŠ–éŸ³è¯„è®ºåŒºè·å®¢æ™ºèƒ½ä½“ - è‡ªåª’ä½“è¥é”€è‡ªåŠ¨åŒ–ç³»ç»Ÿ".center(76) + "â•‘")
        print("â•‘" + " " * 78 + "â•‘")
        print("â•‘" + "    ToBæœåŠ¡å•†ä¸“ç”¨ | å¨±ä¹è¡Œä¸šè·å®¢ | å¤šå¹³å°æ‰©å±•".center(76) + "â•‘")
        print("â•‘" + " " * 78 + "â•‘")
        print("=" * 80)
        
        # æ£€æŸ¥ç¯å¢ƒ
        print("\nğŸ“¦ ç¯å¢ƒæ£€æŸ¥...")
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        base_dir = Path(__file__).parent / "media_marketing"
        from utils import util
        logs_dir = Path(util.ensure_log_dir("tools", "douyin_marketing"))
        cookies_dir = base_dir / "cookies"
        
        base_dir.mkdir(exist_ok=True)
        logs_dir.mkdir(parents=True, exist_ok=True)
        cookies_dir.mkdir(exist_ok=True)
        
        print(f"âœ… æ•°æ®ç›®å½•: {base_dir}")
        print(f"âœ… æ—¥å¿—ç›®å½•: {logs_dir}")
        print(f"âœ… Cookieç›®å½•: {cookies_dir}")
        
        # ç®€åŒ–æç¤º
        print("\nğŸ’¡ æ™ºèƒ½ä½“å°†è‡ªåŠ¨å¯åŠ¨Chromeï¼ˆæœ€å°åŒ–çª—å£ï¼‰å¹¶åŠ è½½mcp-chromeæ‰©å±•")
        
        # ä»system.confåŠ è½½é…ç½®
        try:
            from SmartSisi.utils import config_util as cfg
            cfg.load_config()
            config = {
                'api_key': cfg.douyin_marketing_text_api_key,
                'base_url': cfg.douyin_marketing_text_base_url,
                'text_model': cfg.douyin_marketing_text_model,
                'vision_api_key': cfg.douyin_marketing_vision_api_key,
                'vision_base_url': cfg.douyin_marketing_vision_base_url,
                'vision_model': cfg.douyin_marketing_vision_model,
                'db_path': str(base_dir / "douyin_marketing.db")
            }
            print(f"âœ… é…ç½®å·²ä»system.confåŠ è½½")
        except ImportError as ie:
            # å°è¯•æ·»åŠ é¡¹ç›®æ ¹è·¯å¾„
            # è·¯å¾„: douyin_marketing_agent_tool.py -> tools -> a2a -> llm -> SmartSisi -> liusisi
            project_root = Path(__file__).parent.parent.parent.parent.parent
            if str(project_root) not in sys.path:
                sys.path.insert(0, str(project_root))
            
            try:
                from SmartSisi.utils import config_util as cfg
                cfg.load_config()
                config = {
                    'api_key': cfg.douyin_marketing_text_api_key,
                    'base_url': cfg.douyin_marketing_text_base_url,
                    'text_model': cfg.douyin_marketing_text_model,
                    'vision_api_key': cfg.douyin_marketing_vision_api_key,
                    'vision_base_url': cfg.douyin_marketing_vision_base_url,
                    'vision_model': cfg.douyin_marketing_vision_model,
                    'db_path': str(base_dir / "douyin_marketing.db")
                }
                print(f"âœ… é…ç½®å·²ä»system.confåŠ è½½ï¼ˆé¡¹ç›®æ ¹: {project_root}ï¼‰")
            except Exception as e:
                print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
                print(f"   é¡¹ç›®æ ¹è·¯å¾„: {project_root}")
                print(f"   sys.path: {sys.path[:3]}...")
                raise
        
        agent = DouyinMarketingAgent(config)
        
        # æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡
        print("\nğŸ“Š æ•°æ®åº“ç»Ÿè®¡:")
        conn = agent.db.get_conn()
        c = conn.cursor()
        c.execute("SELECT COUNT(*) FROM target_accounts")
        target_count = c.fetchone()[0]
        c.execute("SELECT COUNT(*) FROM potential_clients")
        client_count = c.fetchone()[0]
        conn.close()
        
        print(f"   ç›®æ ‡è´¦å·: {target_count} ä¸ª")
        print(f"   æ½œåœ¨å®¢æˆ·: {client_count} ä¸ª")
        
        # è‡ªåŠ¨æ¸…ç†è¿‡æœŸæ•°æ®
        json_config_path = Path(__file__).parent / "media_marketing" / "ç›®æ ‡ä¸»æ’­é…ç½®.json"
        if json_config_path.exists():
            print("\nğŸ—‘ï¸  æ‰§è¡Œæ•°æ®æ¸…ç†...")
            agent.db.cleanup_old_data(str(json_config_path))
        
        # å¦‚æœæ²¡æœ‰ç›®æ ‡è´¦å·ï¼Œæ‰¹é‡å¯¼å…¥
        if target_count == 0:
            print("\nâš ï¸  æ²¡æœ‰ç›®æ ‡è´¦å·ï¼Œå¼€å§‹æ‰¹é‡å¯¼å…¥...")
            
            # å¯¼å…¥JSONé…ç½®
            if json_config_path.exists():
                count = agent.db.batch_import_from_json(str(json_config_path))
                print(f"âœ… å·²å¯¼å…¥ {count} ä¸ªä¸»æ’­è´¦å·")
            else:
                # æ‰‹åŠ¨æ·»åŠ å‡ ä¸ªæµ‹è¯•è´¦å·
                agent.db.add_target_account(
                    "MS4wLjABAAAAKAg9TZkPCXyWVSWpcAE6SUnEfvOqbjvu7FH5HoHcqmE",
                    category="æµ‹è¯•"
                )
                print("âœ… å·²æ·»åŠ 1ä¸ªæµ‹è¯•è´¦å·")
        
        # åˆå§‹åŒ–ï¼ˆå¯åŠ¨MCPå’Œæµè§ˆå™¨ï¼‰
        print("\nğŸŒ åˆå§‹åŒ–MCPæœåŠ¡å’Œæµè§ˆå™¨...")
        if not await agent.initialize():
            print("\nâŒ åˆå§‹åŒ–å¤±è´¥")
            return
        
        # æ‰§è¡Œæ¯æ—¥ä»»åŠ¡
        print("\n" + "=" * 80)
        print("â–¶ï¸  å¼€å§‹æ‰§è¡Œæ¯æ—¥è¥é”€ä»»åŠ¡...")
        print("=" * 80)
        
        result = await agent.run_daily_task()
        
        # æ˜¾ç¤ºç»“æœ
        print("\n" + "=" * 80)
        print("ğŸ“ˆ ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼")
        print("=" * 80)
        print(f"âœ… æ£€æŸ¥è´¦å·æ•°: {result.get('accounts_checked', 0)}")
        print(f"âœ… æŸ¥çœ‹è§†é¢‘æ•°: {result.get('videos_viewed', 0)}")
        print(f"âœ… å‘è¡¨è¯„è®ºæ•°: {result.get('comments_posted', 0)}")
        print(f"âœ… åˆ†æç”¨æˆ·æ•°: {result.get('users_analyzed', 0)}")
        print(f"âœ… å‘ç°ç›®æ ‡æ•°: {result.get('targets_found', 0)}")
        print("=" * 80)
        
        # æ¸…ç†
        agent.cleanup()
        
        print("\nç¨‹åºç»“æŸ")
    
    # è®¾ç½®UTF-8ç¼–ç ï¼ˆWindowså…¼å®¹ï¼‰
    if sys.platform == 'win32':
        try:
            import codecs
            sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
            sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')
        except:
            pass
    
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\né”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

