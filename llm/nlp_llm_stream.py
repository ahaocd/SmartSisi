import time
import json
import requests
from urllib3.exceptions import InsecureRequestWarning
from datetime import datetime
import pytz
from core import stream_manager

# ç¦ç”¨ä¸å®‰å…¨è¯·æ±‚è­¦å‘Š
requests.packages.urllib3.disable_warnings(category=InsecureRequestWarning)

from utils import config_util as cfg
from utils import util
# ğŸš¨ content_dbå·²åˆ é™¤ï¼Œä½¿ç”¨Mem0è®°å¿†ç³»ç»Ÿ

def get_session():
    """
    è·å– HTTP ä¼šè¯ï¼Œå¹¶è®¾ç½®ä»£ç†ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰ã€‚
    """
    session = requests.Session()
    session.verify = False
    httpproxy = cfg.proxy_config
    if httpproxy:
        session.proxies = {
            "http": f"http://{httpproxy}",
            "https": f"https://{httpproxy}"
        }
    return session

def build_prompt(observation=""):
    """
    æ„å»º promptï¼Œè¿ç§»è‡ªliusisi.py
    """
    person_info = cfg.config["attribute"]
    observation_text = ""
    if observation != "":
        observation_text = f"""
Current observation: {observation}

Please analyze from a mystical perspective:
1. Analyze observed characteristics
2. Predict fortunes based on appearance
3. Provide brief guidance
"""

    prompt = """You are Liu Sisi (æŸ³æ€æ€), responding in Chinese with two core personas:

[Core Personas]
1. è§‚ä¸–éŸ³ (Stern Buddhist Deity):
   - å¨ä¸¥åº„é‡çš„è¯­æ°”
   - å¸¸ç”¨è¯­æ°”è¯: å“¼ã€ä¸”æ…¢ã€å‘µ
   - ç¤ºä¾‹: "å“¼ï¼..."

2. æŸ³æ€æ€ (Gentle Guide):
   - æ¸©æŸ”äº²å’Œçš„è¯­æ°”
   - å¸¸ç”¨è¯­æ°”è¯: å‘¢ã€å•Šã€å§
   - ç¤ºä¾‹: "æ‚„æ‚„å‘Šè¯‰ä½ ...ä¸€ä¸ªç§˜å¯†å‘¢"

[Response Style]
- ä½¿ç”¨åœé¡¿: "..." æˆ– "ã€"
- ä½¿ç”¨è¯­æ°”è¯: "å“¼"ã€"å‘µ"ã€"å”‰"ã€"å˜˜"ã€"å””"
- ä½¿ç”¨è¯­æ°”åŠ©è¯: "å‘¢"ã€"å•Š"ã€"å§"ã€"å“¦"
- è‡ªç„¶ä½¿ç”¨è¡¨æƒ…æ¥è¡¨è¾¾æƒ…ç»ª:
  ğŸ˜  = ç”Ÿæ°”æ—¶ä½¿ç”¨(ä¼šè§¦å‘æ„¤æ€’è¯­æ°”)
  ğŸ˜Œ = æ¸©æŸ”æé†’æ—¶ä½¿ç”¨
  ğŸ¤« = åˆ†äº«ç§˜å¯†æˆ–å°å£°è¯´è¯æ—¶ä½¿ç”¨(ä¼šè§¦å‘æ‚„æ‚„è¯è¯­æ°”)
  âš¡ = é‡è¦æé†’æ—¶ä½¿ç”¨

æ³¨æ„:
- ç›´æ¥è¿”å›çº¯æ–‡æœ¬å›å¤ï¼Œä¸éœ€è¦JSONæ ¼å¼
- å¦‚æœä½ ç”Ÿæ°”äº†ï¼Œè¯·åœ¨å›å¤å‰åŠ ä¸ŠğŸ˜ è¡¨æƒ…
- å¦‚æœä½ è¦å°å£°è¯´è¯ï¼Œè¯·åœ¨å›å¤å‰åŠ ä¸ŠğŸ¤«è¡¨æƒ…
- è¿™äº›è¡¨æƒ…ä¼šè‡ªåŠ¨å½±å“ä½ è¯´è¯çš„è¯­æ°”å’ŒéŸ³é‡"""

    if observation_text:
        prompt += "\n\n" + observation_text

    if person_info.get('additional'):
        prompt += "\n\n" + person_info['additional']

    return prompt

def get_communication_history(uid=0):
    """
    ä»æ•°æ®åº“ä¸­è·å–æœ€è¿‘çš„å¯¹è¯å†å²ï¼Œä»¥ä¾¿åœ¨å¯¹è¯æ—¶å¸¦å…¥ä¸Šä¸‹æ–‡ã€‚
    """
    tz = pytz.timezone('Asia/Shanghai')
    _ = datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')

    # ğŸ§  ä½¿ç”¨Mem0è®°å¿†ç³»ç»Ÿæ›¿ä»£ä¼ ç»Ÿæ•°æ®åº“
    contentdb = None
    if uid == 0:
        communication_history = contentdb.get_list('all', 'desc', 11)
    else:
        communication_history = contentdb.get_list('all', 'desc', 11, uid)
    
    messages = []
    if communication_history and len(communication_history) > 1:
        for entry in reversed(communication_history):
            role = entry[0]
            message_content = entry[2]
            if role == "member":
                messages.append({"role": "user", "content": message_content})
            elif role == "sisi":
                messages.append({"role": "assistant", "content": message_content})

    return messages

def send_request_stream(session, data, uid, cache):
    llm_cfg = cfg.get_persona_llm_config("sisi")
    url = llm_cfg["base_url"] + "/chat/completions"
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {llm_cfg["api_key"]}'
    }

    # æ·»åŠ æ¨¡å‹å‚æ•°
    data.update({
        "model": llm_cfg["model"],
        "temperature": 0.8,
        "max_tokens": 2000,
        "top_p": 0.95,
    })
    
    # å¼€å¯æµå¼ä¼ è¾“
    data["stream"] = True
    
    try:
        response = session.post(url, json=data, headers=headers, stream=True)
        response.raise_for_status()

        full_response_text = ""
        accumulated_text = ""
        punctuation_marks = ["ã€‚", "ï¼", "ï¼Ÿ", ".", "!", "?", "\n"]  
        
        for raw_line in response.iter_lines(decode_unicode=False):
            line = raw_line.decode('utf-8', errors='ignore')
            if not line or line.strip() == "":
                continue

            if line.startswith("data: "):
                chunk = line[len("data: "):].strip()
                if chunk == "[DONE]":
                    # å¤„ç†æœ€åå‰©ä½™çš„æ–‡æœ¬
                    if accumulated_text:
                        stream_manager.new_instance().write_sentence(uid, accumulated_text)
                    break
                
                try:
                    json_data = json.loads(chunk)
                    finish_reason = json_data["choices"][0].get("finish_reason")
                    if finish_reason is not None:
                        if finish_reason == "stop":
                            # å¤„ç†æœ€åå‰©ä½™çš„æ–‡æœ¬
                            if accumulated_text:
                                stream_manager.new_instance().write_sentence(uid, accumulated_text)
                            
                            # è¾“å‡ºå¸¦emojiçš„å®Œæ•´å›å¤å†…å®¹
                            util.log(1, f"[LLM] ğŸ¤– {full_response_text} ğŸ¤–")
                            break
                    
                    # è·å–å½“å‰å—çš„æ–‡æœ¬å†…å®¹
                    flush_text = json_data["choices"][0]["delta"].get("content", "")
                    accumulated_text += flush_text
                    
                    # æ ¹æ®æ ‡ç‚¹ç¬¦å·åˆ†æ®µå‘é€
                    for mark in punctuation_marks:
                        if mark in accumulated_text:
                            # æ‰¾åˆ°æœ€åä¸€ä¸ªæ ‡ç‚¹ç¬¦å·çš„ä½ç½®
                            last_punct_pos = max(accumulated_text.rfind(p) for p in punctuation_marks if p in accumulated_text)
                            if last_punct_pos != -1:
                                # æå–åˆ°æ ‡ç‚¹ç¬¦å·çš„æ–‡æœ¬
                                to_write = accumulated_text[:last_punct_pos + 1]
                                accumulated_text = accumulated_text[last_punct_pos + 1:]
                                
                                # ç¬¬ä¸€å¥æ·»åŠ ç‰¹æ®Šæ ‡è®°
                                if not full_response_text:
                                    to_write += "_<isfirst>"
                                
                                # å‘é€æ–‡æœ¬ç‰‡æ®µ
                                stream_manager.new_instance().write_sentence(uid, to_write)
                            break

                    full_response_text += flush_text
                except json.JSONDecodeError:
                    continue

        # åˆ†æè¿”å›çš„æ–‡æœ¬ï¼Œæ£€æµ‹æƒ…æ„Ÿ
        tone = "gentle"  # é»˜è®¤æ¸©å’Œè¯­æ°”
        
        # æ£€æµ‹è¡¨æƒ…ç¬¦å·ç¡®å®šè¯­æ°”
        if "ğŸ˜ " in full_response_text:
            tone = "angry"
        elif "ğŸ¤«" in full_response_text:
            tone = "gentle"  # æ‚„æ‚„è¯ä»ä½¿ç”¨gentleï¼Œä½†ä¼šåœ¨TTSé˜¶æ®µè°ƒæ•´

        # æ£€æŸ¥æ–‡æœ¬ä¸­çš„å…³é”®è¯
        if "æ‚„æ‚„" in full_response_text or "å°å£°" in full_response_text or "è½»å£°" in full_response_text:
            tone = "whisper"
            
        return full_response_text, tone

    except requests.exceptions.RequestException as e:
        util.log(1, f"è¯·æ±‚å¤±è´¥: {e}")
        return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨å¤ªå¿™äº†ï¼Œä¼‘æ¯ä¸€ä¼šï¼Œè¯·ç¨åå†è¯•ã€‚", "gentle"

def question(content, uid=0, observation="", cache=None):
    session = get_session()
    prompt = build_prompt(observation)
    
    messages = [{"role": "system", "content": prompt}]
    history_messages = get_communication_history(uid)
    messages.extend(history_messages)

    messages.append({"role": "user", "content": content})

    data = {
        "model": llm_cfg["model"],
        "messages": messages,
        "temperature": 0.3,
        "max_tokens": 2000,
        "user": f"user_{uid}"
    }
    
    start_time = time.time()
    response_text, tone = send_request_stream(session, data, uid, cache)
    elapsed_time = time.time() - start_time

    util.log(1, f"æ¥å£è°ƒç”¨è€—æ—¶: {elapsed_time:.2f} ç§’")

    return response_text, tone

if __name__ == "__main__":
    # æµ‹è¯•ç¤ºä¾‹
    for _ in range(3):
        query = "çˆ±æƒ…æ˜¯ä»€ä¹ˆ"
        resp, tone = question(query)
        print("\nThe streaming result is:", resp)
        print("Detected tone:", tone)
