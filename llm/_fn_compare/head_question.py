def question(content, uid=0, observation="", audio_context=None, brain_prompts=None, speaker_info=None, mode_switched: bool = False):
    """æé—®æ–¹æ³•ï¼Œå¤„ç†è¡¨æƒ…å¹¶è·å–å›åº”

    Args:
        content: ç”¨æˆ·è¾“å…¥å†…å®¹
        uid: ç”¨æˆ·ID
        observation: è§‚å¯Ÿä¿¡æ¯
        audio_context: éŸ³é¢‘ä¸Šä¸‹æ–‡æ•°æ®ï¼ˆæ–°å¢ï¼‰
        brain_prompts: å‰è„‘ç³»ç»Ÿç”Ÿæˆçš„åŠ¨æ€æç¤ºè¯ï¼ˆæ–°å¢ï¼‰
    Returns:
        Tuple[str, str]: (å›ç­”æ–‡æœ¬, è¯­éŸ³é£æ ¼)
    """

    # ğŸŒ¿ æ£€æµ‹æŸ³å¶è°ƒç”¨éœ€æ±‚ï¼Œä½†ä¸åœ¨æ­¤å¤„ç†åˆ‡æ¢
    # æŸ³å¶ç›¸å…³éœ€æ±‚å°†ç”±è·¯ç”±ç³»ç»Ÿå¤„ç†
    liuye_keywords = ["å«æŸ³å¶", "æŸ³å¶", "åŒ»ç–—åŒ…", "ç³»ç»Ÿè¯Šæ–­", "ä»£ç ä¼˜åŒ–", "AIåä½œ"]
    if any(word in content for word in liuye_keywords):
        util.log(1, f"[NLP] æ£€æµ‹åˆ°æŸ³å¶éœ€æ±‚å…³é”®è¯ï¼Œå°†è·¯ç”±åˆ°åŒ»ç–—åŒ…ç³»ç»Ÿ")
        # è¿™é‡Œåº”è¯¥è°ƒç”¨è·¯ç”±ç³»ç»Ÿï¼Œè€Œä¸æ˜¯ç›´æ¥åˆ‡æ¢æ¨¡å¼
        # TODO: é›†æˆæŸ³å¶è·¯ç”±ç³»ç»Ÿ
    util.log(1, f"[NLP] questionå‡½æ•°è¾“å…¥: {content}")

    # === çœŸæ­£çš„LLMæµå¼ï¼ˆSSEï¼‰è¾“å‡ºä¸æ®µå†…å³æ—¶TTS ===
    def _stream_llm_and_tts(messages: list, style_hint: str = "gentle") -> tuple:
        """è°ƒç”¨OpenAIå…¼å®¹SSEæµå¼ï¼Œè¾¹æ”¶tokenè¾¹åˆ†æ®µå¹¶TTSã€‚è¿”å›(å®Œæ•´æ–‡æœ¬, style)ã€‚

## ???????????##
1. ?????????? {??????}
2. ?????????? {??}
3. ?????????? {??} ? {??}
4. ???????????????{}

## ????????????##
- ???????????????/??/??/??/??/??/??/??/???/??????/?????
- ??????????????????? {??????}?
- ??????????????? {??????}??????????

???
?????????
???{??????}

"""
        try:
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šåœ¨tryå—å†…æœ€å¼€å§‹å®šä¹‰skip_flag_set
            skip_flag_set = [False]  # ä½¿ç”¨åˆ—è¡¨é¿å…nonlocalé—®é¢˜
            
            session = get_session()
            llm_cfg = get_llm_cfg()
            url = llm_cfg["base_url"] + "/chat/completions"
            headers = {
                'Content-Type': 'application/json',
                'Authorization': f"Bearer {llm_cfg['api_key']}",
                'Accept-Charset': 'utf-8'
            }
            data = {
                "model": llm_cfg["model"],
                "messages": messages,
                "temperature": 0.7,
                "max_tokens": 2000,
                "top_p": 0.9,
                "stream": True,
                "stop": ["ASSISTANT:", "USER:", "åŠ©æ‰‹ï¼š", "ç”¨æˆ·ï¼š", "ç³»ç»Ÿï¼š"]
            }
            # å»ºç«‹æµå¼è¯·æ±‚ï¼ˆç¦ç”¨è‡ªåŠ¨unicodeè§£ç ï¼Œå¼ºåˆ¶UTF-8è§£æï¼‰
            resp = session.post(url, json=data, headers=headers, stream=True, timeout=(1, 30))
            # ğŸ”§ å‹å¥½é”™è¯¯ï¼šé‰´æƒ/æƒé™é—®é¢˜åˆ«åªæŠ›å¼‚å¸¸ï¼Œç›´æ¥ç»™å‡ºå¯æ“ä½œçš„æç¤º
            if resp.status_code in (401, 403):
                persona = get_current_system_mode()
                hint = (
                    f"AIæ¥å£é‰´æƒå¤±è´¥(HTTP {resp.status_code})ï¼š"
                    f"è¯·æ£€æŸ¥ `SmartSisi/system.conf` çš„ `{persona}_llm_api_key` å’Œ `{persona}_llm_base_url` æ˜¯å¦æ­£ç¡®ã€‚"
                )
                util.log(2, f"[NLP-Stream] âŒ {hint}")
                return "", style_hint

            try:
                resp.raise_for_status()
            except Exception as _http_e:
                # å°½é‡æŠŠæœåŠ¡ç«¯è¿”å›ä½“æ‰“å‡ºæ¥ï¼ˆæˆªæ–­ï¼‰ï¼Œæ–¹ä¾¿å®šä½æ˜¯æ¨¡å‹å/å‚æ•°/ä»£ç†çš„é—®é¢˜
                try:
                    body_preview = (resp.text or "")[:500]
                except Exception:
                    body_preview = ""
                util.log(2, f"[NLP-Stream] âŒ HTTPå¼‚å¸¸: {str(_http_e)}; body[:500]={body_preview}")
                raise

            # æ’­æ”¾ç›¸å…³
            try:
                from core import sisi_booter
                feifei = getattr(sisi_booter, 'feiFei', None)
            except Exception as e:
                feifei = None

            full_text = ""
            seg_buf = ""
            last_emit = time.time()
            brace_depth = 0  # ç”¨äºé¿å…æˆªæ–­æœªé—­åˆçš„{...}
            min_interval = 0.4
            max_len = 28
            emitted_any = False  # ä»…å½“å®é™…æ’­å‡ºè¿‡å†…å®¹æ—¶ï¼Œæ‰åœ¨ç»“æŸæ—¶è®¾ç½®è·³è¿‡æ ‡è®°

            from utils.emotion_trigger import detect_and_trigger_emotions
            import re

            def _esp32_connected() -> bool:
                try:
                    import sys
                    adapter = None
                    if "sisi_adapter" in sys.modules:
                        mod = sys.modules["sisi_adapter"]
                        if hasattr(mod, "get_adapter_instance"):
                            adapter = mod.get_adapter_instance()
                        elif hasattr(mod, "_ADAPTER_INSTANCE"):
                            adapter = mod._ADAPTER_INSTANCE
                    if not adapter:
                        return False
                    clients = getattr(adapter, "clients", None) or {}
                    if isinstance(clients, dict):
                        for ws in clients.values():
                            if ws and not getattr(ws, "closed", False):
                                return True
                        return bool(clients)
                    return False
                except Exception:
                    return False

            def _enqueue_pc_audio(file_path: str, label: str) -> bool:
                try:
                    from utils.pc_stream_queue import get_pc_stream_queue
                    import threading as _threading
                    pc_queue = get_pc_stream_queue()
                    sink = pc_queue.enqueue_stream(label=label)
                    _threading.Thread(
                        target=pc_queue.stream_wav_file_to_sink,
                        args=(file_path, sink),
                        daemon=True,
                    ).start()
                    return True
                except Exception as _qe:
                    util.log(2, f"[NLP-Stream] PCé˜Ÿåˆ—æ’å…¥å¤±è´¥: {_qe}")
                    return False

            def try_emit(force=False):
                nonlocal seg_buf, last_emit, brace_depth, emitted_any
                now = time.time()
                # ğŸ”¥ ä¿®å¤ï¼šåªæŒ‰æ ‡ç‚¹åˆ†æ®µï¼Œä¸æŒ‰æ—¶é—´/é•¿åº¦å¼ºåˆ¶åˆ†æ®µï¼Œé¿å…ä¸€å¥è¯è¢«æ‹†æˆä¸¤æ®µå¯¼è‡´æƒ…æ„Ÿä¸ä¸€è‡´
                ready_by_punct = bool(seg_buf and re.search(r'[ã€‚ï¼ï¼Ÿ!?ï½~]$', seg_buf))
                # è‹¥åŒ…å«effectï¼Œå°½é‡ç­‰åˆ°å³ä¾§å¥æœ«å†åæ®µï¼Œä»¥å¯¹é½æ’å…¥ç‚¹
                contains_effect = bool(re.search(r'\{([A-Za-z0-9_\u4e00-\u9fff]+)\}', seg_buf))
                if contains_effect and not force and not ready_by_punct:
                    return
                if (force or ready_by_punct) and seg_buf and brace_depth == 0:
                    # æŒ‰å‡ºç°é¡ºåºå¤„ç†{text,effect}åºåˆ—
                    sequence = []
                    s = seg_buf
                    # æ¸…ç†ç‰¹æ®Šæ§åˆ¶ç¬¦
                    s = s.replace('<|endofprompt|>', '')
                    display_text = s
                    pos = 0
                    for m in re.finditer(r'\{([A-Za-z0-9_\u4e00-\u9fff]+)\}', s):
                        if m.start() > pos:
                            text_part = s[pos:m.start()]
                            sequence.append(("text", text_part))
                        effect_name = m.group(1)
                        sequence.append(("effect", effect_name))
                        pos = m.end()
                    if pos < len(s):
                        sequence.append(("text", s[pos:]))

                    try:
                        from esp32_liusisi.sisi_audio_output import AudioOutputManager
                        aom = AudioOutputManager.get_instance()
                    except Exception:
                        aom = None

                    # é¡ºåºæ‰§è¡Œï¼štext -> effect -> text ...
                    has_text_part = False
                    for item_type, payload in sequence:
                        if item_type == "text":
                            cleaned_text = (payload or "").strip()
                            if not cleaned_text:
                                continue
                            has_text_part = True
                            if feifei:
                                try:
                                    # æŸ³å¶æ¨¡å¼éœ€è¦åˆ›å»ºå¸¦interleaveræ ‡è¯†çš„interactå¯¹è±¡
                                    from llm.liusisi import get_current_system_mode
                                    current_mode = get_current_system_mode()
                                    if current_mode == "liuye":
                                        from core.interact import Interact
                                        interact_obj = Interact(interleaver="liuye", interact_type=2, data={"user": "User", "text": cleaned_text})
                                    else:
                                        interact_obj = None
                                    
                                    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä¿æŒæµå¼TTSæ’­æ”¾
                                    feifei.process_audio_response(
                                        text=cleaned_text,
                                        username="User",
                                        interact=interact_obj,
                                        priority=5,
                                        style=style_hint,
                                        is_agent=False,
                                        display_text=display_text
                                    )
                                    emitted_any = True
                                    
                                except Exception as _e:
                                    util.log(2, f"[NLP-Stream] æ®µæ’­æŠ¥å¤±è´¥: {_e}")
                        else:
                            # å¸§çº§æ’å…¥ï¼šå°†æ•ˆæœéŸ³è½¬ä¸ºOPUSå¸§å¹¶ç›´æ¥å…¥é˜Ÿï¼Œä¸æš‚åœæµ
                            try:
                                from utils import emotion_trigger as et
                                trig = et.EMOTION_TRIGGER_MAP.get(payload)
                                if not trig:
                                    continue
                                ttype = trig.get('type')
                                if ttype in ['sound_effect', 'music_play']:
                                    import os
                                    fpath = trig.get('audio_file')
                                    if fpath and not os.path.isabs(fpath):
                                        fpath = os.path.abspath(fpath)
                                    if not os.path.exists(fpath):
                                        util.log(2, f"[NLP-Stream] âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {fpath}")
                                        continue

                                    # PCè·¯å¾„ï¼šä¸è¦èµ°pygameå¹¶è¡Œæ’­æ”¾ï¼Œæ”¹ä¸ºæ’é˜Ÿä¸²è¡Œæ’å…¥
                                    if not _esp32_connected():
                                        ok = _enqueue_pc_audio(fpath, label=f"{ttype}:{payload}")
                                        if ok:
                                            emitted_any = True
                                            util.log(1, f"[NLP-Stream] PCé˜Ÿåˆ—æ’å…¥éŸ³é¢‘: {payload}")
                                        else:
                                            util.log(2, f"[NLP-Stream] PCé˜Ÿåˆ—æ’å…¥å¤±è´¥: {payload}")
                                        continue

                                    # ESP32è·¯å¾„ï¼šæŒ‰ç±»å‹èµ°è®¾å¤‡æ’å…¥
                                    util.log(1, f"[NLP-Stream] è®¾å¤‡æ’å…¥éŸ³é¢‘: {payload}")
                                    try:
                                        if ttype == 'sound_effect':
                                            et._execute_sound_effect(payload, trig)
                                        else:
                                            et._execute_music_play(payload, trig)
                                        emitted_any = True
                                    except Exception as _pe:
                                        util.log(2, f"[NLP-Stream] è®¾å¤‡æ’å…¥å¤±è´¥: {_pe}")
                                elif ttype == 'system_switch':
                                    # å³æ—¶è§¦å‘ç³»ç»Ÿåˆ‡æ¢ï¼ˆä¾‹å¦‚ {å¦¹å¦¹} / {æŸ³å¶} ï¼‰
                                    try:
                                        et.detect_and_trigger_emotions("{" + payload + "}", is_ai_response=True)
                                        # åˆ‡æ¢ä¸ä»£è¡¨æœ‰éŸ³é¢‘æ’­å‡ºï¼Œä¸æ ‡è®°emitted_any
                                    except Exception as _se:
                                        util.log(2, f"[NLP-Stream] ç³»ç»Ÿåˆ‡æ¢è§¦å‘å¤±è´¥: {_se}")
                            except Exception as _e:
                                util.log(2, f"[NLP-Stream] å¸§çº§æ’å…¥å¤±è´¥: {_e}")

                    # è‹¥æœ¬æ®µåªæœ‰æ ‡è®°æ— æ­£æ–‡ï¼Œä¹Ÿè¦æ¨é€å‰ç«¯æ˜¾ç¤º
                    if not has_text_part and display_text.strip():
                        try:
                            if feifei and hasattr(feifei, "send_panel_reply"):
                                feifei.send_panel_reply(display_text, username="User", is_intermediate=True, phase="stream")
                        except Exception as _se:
                            util.log(2, f"[NLP-Stream] ä»…å‰ç«¯æ˜¾ç¤ºå¤±è´¥: {_se}")

                    seg_buf = ""
                    last_emit = now

            # å¼ºåˆ¶æŒ‰UTF-8è§£æSSE
            chunk_count = 0  # ğŸ”¥ è°ƒè¯•ï¼šç»Ÿè®¡æ”¶åˆ°çš„chunkæ•°é‡
            music_status_sent = set()  # ğŸµ è®°å½•å·²å‘é€çš„éŸ³ä¹çŠ¶æ€ï¼Œé¿å…é‡å¤
            # ğŸ”¥ è°ƒè¯•ï¼šæ‰“å°è¯·æ±‚å‚æ•°
            try:
                system_blob = "\n\n".join(
                    [m.get("content", "") for m in messages if m.get("role") == "system"]
                ).strip()
                last_user = ""
                for m in reversed(messages):
                    if m.get("role") == "user":
                        last_user = (m.get("content") or "")
                        break
                util.log(
                    1,
                    f"[NLP-Streamè°ƒè¯•] ğŸ“¤ APIè¯·æ±‚: model={data.get('model')}, max_tokens={data.get('max_tokens')}, system_prompté•¿åº¦={len(system_blob)}, user_msgé•¿åº¦={len(last_user)}",
                )
            except Exception:
                util.log(1, f"[NLP-Streamè°ƒè¯•] ğŸ“¤ APIè¯·æ±‚: model={data.get('model')}, max_tokens={data.get('max_tokens')}")
            for raw_line in resp.iter_lines(decode_unicode=False):
                if not raw_line:
                    continue
                try:
                    line = raw_line.decode('utf-8', errors='ignore')
                except Exception:
                    continue
                if not line:
                    continue
                if line.startswith('data: '):
                    payload = line[6:].strip()
                    if payload == "[DONE]":
                        util.log(1, f"[NLP-Streamè°ƒè¯•] ğŸ æ”¶åˆ°[DONE]ï¼Œæµå¼ç»“æŸï¼Œå·²æ”¶åˆ°{chunk_count}ä¸ªchunkï¼Œå…¨æ–‡: {full_text}")
                        break
                    try:
                        obj = json.loads(payload)
                        delta = obj.get('choices', [{}])[0].get('delta', {})
                        token = delta.get('content', '')
                        # ğŸ”¥ è°ƒè¯•ï¼šæ‰“å°æ¯ä¸ªchunkçš„å†…å®¹
                        util.log(1, f"[NLP-Streamè°ƒè¯•] ğŸ“¦ æ”¶åˆ°chunk: tokené•¿åº¦={len(token) if token else 0}, tokenå†…å®¹={'æœ‰å†…å®¹' if token else 'ç©º'}")
                        # ğŸ”¥ è°ƒè¯•ï¼šæ£€æŸ¥finish_reasonå’Œusage
                        finish_reason = obj.get('choices', [{}])[0].get('finish_reason')
                        usage = obj.get('usage')
                        if finish_reason:
                            util.log(1, f"[NLP-Streamè°ƒè¯•] âš ï¸ finish_reason={finish_reason}ï¼Œusage={usage}ï¼Œå½“å‰å…¨æ–‡: {full_text}")
                    except Exception as e:
                        util.log(2, f"[NLP-Streamè°ƒè¯•] âŒ JSONè§£æå¤±è´¥: {e}")
                        token = ""
                    if not token:
                        util.log(1, f"[NLP-Streamè°ƒè¯•] â­ï¸ è·³è¿‡ç©ºtoken")
                        continue
                    chunk_count += 1
                    full_text += token
                    
                    # brace æ·±åº¦è¿½è¸ª
                    for ch in token:
                        if ch == '{':
                            brace_depth += 1
                        elif ch == '}':
                            brace_depth = max(0, brace_depth - 1)
                    seg_buf += token
                    try_emit(force=False)
            # æœ€åflush
            if seg_buf:
                try_emit(force=True)
            
            # æµå¼æ’­æ”¾ç»“æŸï¼šå¦‚å·²æ’­å‡ºè¿‡å†…å®¹ï¼Œè®¾ç½®è·³è¿‡æ ‡å¿—é˜²æ­¢CoreäºŒæ¬¡æ’­æŠ¥
            util.log(1, f"[NLP-Streamè°ƒè¯•] ğŸ¯ æµå¼æ’­æ”¾ç»“æŸï¼Œemitted_any={emitted_any}, å…¨æ–‡é•¿åº¦={len(full_text)}, chunkæ•°={chunk_count}")
            try:
                from core import sisi_booter
                if hasattr(sisi_booter, 'feiFei') and sisi_booter.feiFei:
                    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæµå¼ç»“æŸåæ‰è®¾ç½®è·³è¿‡æ ‡å¿—ï¼Œé¿å…åç»­åˆ†æ®µTTSè¢«è¯¯è·³è¿‡
                    if emitted_any and not skip_flag_set[0]:
                        setattr(sisi_booter.feiFei, '_skip_next_tts', True)
                        setattr(sisi_booter.feiFei, '_skip_tts_timestamp', time.time())
                        skip_flag_set[0] = True
                        util.log(1, "[NLP-Stream] âœ… æµå¼ç»“æŸåè®¾ç½®_skip_next_ttsï¼Œé˜²æ­¢CoreäºŒæ¬¡æ’­æŠ¥")
                    else:
                        util.log(1, "[NLP-Stream] âœ… è·³è¿‡æ ‡å¿—æœªè®¾ç½®ï¼ˆæœªæ’­å‡ºæˆ–å·²è®¾ç½®ï¼‰")
            except Exception as _e:
                util.log(2, f"[NLP-Stream] æ ‡å¿—å¤„ç†å¤±è´¥: {_e}")
            return full_text.strip(), style_hint
        except Exception as e:
            util.log(2, f"[NLP-Stream] æµå¼SSEå¼‚å¸¸: {e}")
            # è¿”å›ç©ºæ–‡æœ¬ä»¥ä¾¿ä¸Šå±‚èµ°éæµå¼å…œåº•
            return "", style_hint

    try:
        # ğŸ¯ æ–°å¢ï¼šéŸ³é¢‘ä¸Šä¸‹æ–‡å¤„ç†
        audio_context_prompt = ""
        if audio_context:
            try:
                from .audio_context_processor import get_audio_context_processor
                from .audio_context_llm import get_audio_context_llm

                # å¤„ç†éŸ³é¢‘ä¸Šä¸‹æ–‡
                audio_processor = get_audio_context_processor()
                audio_llm = get_audio_context_llm()

                # ğŸ§  åå°åˆ†æï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡å¿«é€Ÿå“åº”ï¼‰
                import threading
                def background_analysis():
                    try:
                        suggestion = audio_llm.analyze_and_suggest(
                            audio_context, content,
                            audio_context.get("speaker_info")
                        )
                        if suggestion:
                            audio_llm.send_to_transit_station(suggestion)
                    except Exception as e:
                        util.log(2, f"[éŸ³é¢‘ä¸Šä¸‹æ–‡] åå°åˆ†æå¤±è´¥: {e}")

                # å¯åŠ¨åå°åˆ†æçº¿ç¨‹
                threading.Thread(target=background_analysis, daemon=True).start()

                # ğŸ¯ ç”Ÿæˆå³æ—¶ä¸Šä¸‹æ–‡æç¤ºè¯ï¼ˆä¸é˜»å¡ï¼‰
                context_prompt = audio_processor.get_context_prompt(audio_context)
                if context_prompt:
                    audio_context_prompt = f"\n{context_prompt}\n"
                    util.log(1, f"[éŸ³é¢‘ä¸Šä¸‹æ–‡] ç”Ÿæˆæç¤ºè¯: {context_prompt[:50]}...")

            except Exception as e:
                util.log(2, f"[éŸ³é¢‘ä¸Šä¸‹æ–‡] å¤„ç†å¤±è´¥: {e}")
                audio_context_prompt = ""
        # æ˜¯å¦ä½¿ç”¨æµå¼æ¨¡å¼ - å¯ç”¨åˆ†å—æµå¼
        use_stream = True

        # é¢„ç½®æƒ…æ„Ÿæ ‡è®°ï¼Œé¿å…åç»­æœªèµ‹å€¼æ—¶æŠ¥é”™
        emotion = ""

        # æ£€æŸ¥æ˜¯å¦åŒ…å«å†’çŠ¯æ€§è¯è¯­
        disrespectful_keywords = [
            "ä½ ç®—ä»€ä¹ˆ", "ä½ ä¹Ÿé…", "æ»š", "é—­å˜´", "ç¬¨è›‹", "åºŸç‰©",
            "ä»€ä¹ˆä¸œè¥¿", "åƒåœ¾", "å‚»", "è ¢", "ç™½ç—´", "ç‹—å±",
            "å»æ­»", "æ··è›‹", "è®¨åŒ", "çƒ¦äºº", "æ— èƒ½", "åºŸè¯"
        ]
        is_disrespectful = any(keyword in content.lower() for keyword in disrespectful_keywords)

        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç‰¹æ®Šè¯­æ°”æŒ‡ä»¤
        whisper_keywords = ["æ‚„æ‚„", "å°å£°", "å·å·", "è½»å£°"]
        fast_keywords = ["å¿«ç‚¹è¯´", "èµ¶ç´§è¯´", "å¿«é€Ÿ", "æŠ“ç´§"]
        slow_keywords = ["æ…¢ç‚¹è¯´", "æ…¢æ…¢è¯´", "ç¼“ç¼“"]

        session = get_session()
        history_context = get_communication_history(uid, query_text=content, include_other=False, as_text=False)

        recent_messages = []
        summary_context = ""
        older_context = ""
        if history_context:
            recent_messages = getattr(history_context, "recent_messages", []) or []
            summary_context = getattr(history_context, "summary_text", "") or ""
            older_context = getattr(history_context, "older_text", "") or ""

        # ???????????????????prompt
        brain_context = ""
        if brain_prompts:
            dynamic_prompt = (brain_prompts.get('dynamic_prompt') or '').strip()
            if dynamic_prompt:
                brain_context = dynamic_prompt

        # åŠ¨æ€è·å–å½“å‰ç”¨æˆ·èº«ä»½
        current_user_name = "ç”¨æˆ·"
        current_user_role = "guest"
        if speaker_info:
            current_user_name = speaker_info.get('real_name', 'ç”¨æˆ·')
            current_user_role = speaker_info.get('role', 'guest')

        # ğŸ§  é•¿æœŸè®°å¿†æ³¨å…¥ï¼ˆå»¶è¿Ÿæ³¨å…¥ç‰ˆï¼‰
        # çº¦æŸï¼šå‰å° question() ä¸å…è®¸å®æ—¶/åŠåŒæ­¥æ£€ç´¢ Mem0ã€‚
        # è®°å¿†æ£€ç´¢ + ç»„ç»‡ç”±â€œå‰è„‘/åŠ¨æ€ä¸­æ¢â€åå°äº§å‡ºï¼Œä¸‹ä¸€è½®é€šè¿‡ brain_prompts['memory_context'] æ³¨å…¥ã€‚
        memory_context_prompt = ""
        try:
            if brain_prompts:
                mem_ctx = (brain_prompts.get("memory_context") or "").strip()
                if mem_ctx and mem_ctx not in ("æ— ç›¸å…³è®°å¿†", "æ— ç›¸å…³Sisiè®°å¿†", "è®°å¿†ç³»ç»Ÿä¸å¯ç”¨"):
                    memory_context_prompt = mem_ctx
        except Exception:
            memory_context_prompt = ""
        base_prompt = build_prompt(observation, "")

        dynamic_parts = []
        if audio_context_prompt:
            dynamic_parts.append(audio_context_prompt.strip())
        dynamic_block = "\n".join([p for p in dynamic_parts if p]).strip()

        # æ„å»ºç”¨æˆ·æ¶ˆæ¯ï¼Œä½¿ç”¨åŠ¨æ€èº«ä»½ä¿¡æ¯
        if speaker_info and speaker_info.get('real_name'):
            speaker_name = speaker_info['real_name']
            user_message = content
        else:
            user_message = content

        # ä¸å†åœ¨ç”¨æˆ·æ¶ˆæ¯ä¸­æ³¨å…¥æ—¶é—´æˆ³ï¼Œé¿å…æ¨¡å‹å¤è¯»

        # ç»„è£… system messagesï¼ˆé‡è¦åœ¨å‰ï¼Œå‚è€ƒåœ¨åï¼‰
        system_messages = []
        if base_prompt:
            system_messages.append({"role": "system", "content": base_prompt})
        if dynamic_block:
            system_messages.append({"role": "system", "content": dynamic_block})

        ref_parts = []
        if summary_context:
            ref_parts.append(summary_context)
        if older_context:
            ref_parts.append(older_context)
        if memory_context_prompt:
            ref_parts.append(memory_context_prompt)
        if ref_parts:
            system_messages.append({"role": "system", "content": "\n\n".join(ref_parts)})

        messages = []
        messages.extend(system_messages)
        if recent_messages:
            messages.extend(recent_messages)
        if brain_context:
            messages.append({"role": "system", "content": brain_context})
        messages.append({"role": "user", "content": user_message})

        # ğŸ”¥ è°ƒè¯•ï¼šæ‰“å°å®Œæ•´çš„ä¼ é€’ç»™å¤§æ¨¡å‹çš„å†…å®¹
        util.log(1, f"[NLP-å®Œæ•´è°ƒè¯•] ==================== å¼€å§‹ ====================")
        try:
            from sisi_memory.chat_history import format_messages_as_text
            recent_text = format_messages_as_text(recent_messages or [])
        except Exception:
            recent_text = ""
        system_blob = "\n\n".join([m.get("content", "") for m in system_messages]).strip()
        util.log(1, f"[NLP-å®Œæ•´è°ƒè¯•] ğŸ“ System Prompt (å‰500å­—ç¬¦):\n{system_blob[:500]}")
        util.log(1, f"[NLP-å®Œæ•´è°ƒè¯•] ğŸ“ System Prompt (å500å­—ç¬¦):\n{system_blob[-500:]}")
        util.log(1, f"[NLP-å®Œæ•´è°ƒè¯•] ğŸ“ System Prompt æ€»é•¿åº¦: {len(system_blob)} å­—ç¬¦")
        util.log(1, f"[NLP-å®Œæ•´è°ƒè¯•] ğŸ’¬ User Message: {user_message}")
        util.log(1, f"[NLP-å®Œæ•´è°ƒè¯•] ğŸ“š å¯¹è¯å†å²:\n{recent_text[:500] if recent_text else 'æ— å†å²'}")
        util.log(1, f"[NLP-å®Œæ•´è°ƒè¯•] ğŸ§  å‰è„‘æç¤ºè¯:\n{brain_context[:300] if brain_context else 'æ— å‰è„‘æç¤º'}")
        util.log(1, f"[NLP-å®Œæ•´è°ƒè¯•] ==================== ç»“æŸ ====================")

        llm_cfg = get_llm_cfg()

        # === ä¸»è·¯å¾„ï¼šçœŸæ­£LLMæµå¼ ===
        if use_stream:
            streamed_text, style_stream = _stream_llm_and_tts(messages, style_hint="gentle")
            if streamed_text:
                # å­˜å‚¨ä¸è¿”å›
                answer = streamed_text
                style = style_stream
            else:
                # æµå¼å¤±è´¥ï¼šä¸åšå…œåº•ï¼Œä¸è¿›è¡Œéæµå¼å›é€€
                util.log(2, "[NLP-Stream] æµå¼å¤±è´¥ï¼Œå·²ç¦ç”¨å…œåº•")
                answer, style = "", style_stream
        else:
            # æ—§è·¯å¾„ï¼ˆéæµå¼ï¼‰
            response = send_llm_request(session, {"messages": messages, "stop": ["ASSISTANT:", "USER:", "åŠ©æ‰‹ï¼š", "ç”¨æˆ·ï¼š", "ç³»ç»Ÿï¼š"]}, llm_cfg)
            if response and isinstance(response, dict):
                answer = response["text"].strip() or "è®©æˆ‘æƒ³æƒ³è¯¥æ€ä¹ˆå›ç­”..."
                style = response.get("tone", "gentle")
                emotion = response.get("emotion", "")
            else:
                answer, style = "è®©æˆ‘æƒ³æƒ³è¯¥æ€ä¹ˆå›ç­”...", "gentle"

        # === æƒ…æ„Ÿ/ç³»ç»Ÿåˆ‡æ¢æ ‡è®°å¤„ç† ===
        # æµå¼æ¨¡å¼å·²åœ¨ _stream_llm_and_tts ä¸­è§¦å‘è¿‡æƒ…æ„Ÿï¼Œè¿™é‡Œä¸é‡å¤è§¦å‘ï¼›
        # éæµå¼æ¨¡å¼éœ€è¦è§¦å‘ä¸€æ¬¡ï¼Œä½†ä¸æ¸…ç†æ–‡æœ¬ï¼ˆä¿ç•™ç»™å‰ç«¯/å†å²ï¼‰ã€‚
        try:
            if not use_stream:
                from utils.emotion_trigger import detect_and_trigger_emotions
                detect_and_trigger_emotions(answer or "", is_ai_response=True)
                util.log(1, f"[NLP-LLM] éæµå¼å·²è§¦å‘æƒ…æ„Ÿæ ‡è®°")
            else:
                util.log(1, f"[NLP-LLM] æµå¼å·²å¤„ç†æƒ…æ„Ÿæ ‡è®°ï¼Œä¿ç•™åŸæ–‡")
        except Exception as _e:
            util.log(2, f"[NLP-LLM] æƒ…æ„Ÿè§¦å‘è§£æå¤±è´¥: {_e}")

        if not (answer or "").strip():
            util.log(2, "[NLP-LLM] empty_model_output (no fallback)")
            return "", style

        # ğŸ§  å¼‚æ­¥å­˜å‚¨å¯¹è¯åˆ°è®°å¿†ç³»ç»Ÿ - add_sisi_interaction_memoryå·²ç»æ˜¯å¼‚æ­¥çš„
        try:
            # ç»Ÿä¸€ user_id è§„åˆ™ï¼šä¸å†å² SoT çš„ uidâ†’user_id è§„åˆ™ä¸€è‡´ï¼Œå¹¶åŸºäº mode å‘½åç©ºé—´éš”ç¦»
            if isinstance(uid, str) and uid.startswith("user"):
                base_user_id = uid
            elif uid != 0:
                base_user_id = f"user{uid}"
            else:
                base_user_id = "default_user"

            try:
                from llm.liusisi import get_current_system_mode
                mode = get_current_system_mode()
            except Exception:
                mode = "sisi"
            try:
                from sisi_memory.context_kernel import namespaced_user_id as _namespaced_user_id, normalize_persona

                namespaced_user_id = _namespaced_user_id(normalize_persona(mode), base_user_id)
            except Exception:
                namespaced_user_id = f"{mode}::{base_user_id}"

            # ğŸš€ ç›´æ¥è°ƒç”¨å¼‚æ­¥å­˜å‚¨å‡½æ•°ï¼ˆå†…éƒ¨å·²ç»æ˜¯åå°çº¿ç¨‹ï¼‰
            success = add_sisi_interaction_memory(
                text=content,  # ç”¨æˆ·è¯´çš„è¯
                speaker_id=namespaced_user_id,  # å‘½åç©ºé—´åŒ–çš„ç”¨æˆ·ID
                response=answer,  # æŸ³æ€æ€çš„å›å¤
                speaker_info=speaker_info  # å£°çº¹èº«ä»½ä¿¡æ¯
            )
            util.log(1, f"[NLP-LLM] ğŸš€ è®°å¿†å­˜å‚¨å·²å¯åŠ¨: {namespaced_user_id}")
        except Exception as e:
            util.log(2, f"[NLP-LLM] è®°å¿†å­˜å‚¨å¼‚å¸¸: {e}")

        # å¯¹è¯äº‹ä»¶æµ SoT çš„å†™å…¥ç”± core/sisi_core.py ç»Ÿä¸€è´Ÿè´£ï¼Œè¿™é‡Œä¸é‡å¤å†™å…¥ï¼Œé¿å…åŒå†™/é‡å¤è®°å½•

        # ğŸ§  å¯¹è¯å†å²å·²é€šè¿‡â€œäº‹ä»¶æµ + æ‘˜è¦ + è®°å¿†â€ç»Ÿä¸€ç®¡ç†ï¼Œæ— éœ€æ‰‹åŠ¨ç»´æŠ¤historyåˆ—è¡¨

        # åªåœ¨æœ‰è¡¨æƒ…æ—¶æ·»åŠ è¡¨æƒ…
        return f"{emotion} {answer}" if emotion else answer, style

    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        util.log(2, f"[NLP] âŒ questionå‡½æ•°å¼‚å¸¸: {e}")
        util.log(2, f"[NLP] âŒ è¯¦ç»†é”™è¯¯: {error_detail}")

        answer = f"ç³»ç»Ÿé‡åˆ°äº†ä¸€ç‚¹é—®é¢˜: {str(e)}"
        style = 'gentle'
        util.log(1, f"[NLP] questionå‡½æ•°è¾“å‡ºæ–‡æœ¬: {answer}")
        util.log(1, f"[NLP] questionå‡½æ•°è¾“å‡ºtone: {style}")
        return answer, style
